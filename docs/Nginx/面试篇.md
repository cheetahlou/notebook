# 看完这篇还不了解Nginx，那我就哭了！

[看完这篇还不了解Nginx，那我就哭了！ (qq.com)](https://mp.weixin.qq.com/s?__biz=MzU1Nzg4NjgyMw==&mid=2247484245&idx=1&sn=cf09b6daed49b60cced77ea10a0a4726&chksm=fc2fbf5dcb58364b3619c95e1b4d11537f4e44ccd43ea9d3e0384be6262d32cc43513a9e11d9&mpshare=1&scene=23&srcid=0424TdyJtqTS25EQHTKUjwVq&sharer_sharetime=1650809925158&sharer_shareid=29b8a04db1dbd975e3bf4e9f47e7ac67#rd)

## Nginx的产生

没有听过Nginx？那么一定听过它的"同行"Apache吧！Nginx同Apache一样都是一种WEB服务器。基于REST架构风格，以统一资源描述符(Uniform Resources Identifier)URI或者统一资源定位符(Uniform Resources Locator)URL作为沟通依据，通过HTTP协议提供各种网络服务。

然而，这些服务器在设计之初受到当时环境的局限，例如当时的用户规模，网络带宽，产品特点等局限并且各自的定位和发展都不尽相同。这也使得各个WEB服务器有着各自鲜明的特点。

Apache的发展时期很长，而且是毫无争议的世界第一大服务器。它有着很多优点：稳定、开源、跨平台等等。它出现的时间太长了，它兴起的年代，互联网产业远远比不上现在。所以它被设计为一个重量级的。它不支持高并发的服务器。在Apache上运行数以万计的并发访问，会导致服务器消耗大量内存。操作系统对其进行进程或线程间的切换也消耗了大量的CPU资源，导致HTTP请求的平均响应速度降低。

这些都决定了Apache不可能成为高性能WEB服务器，轻量级高并发服务器Nginx就应运而生了。

俄罗斯的工程师Igor Sysoev，他在为Rambler Media工作期间，使用C语言开发了Nginx。Nginx作为WEB服务器一直为Rambler Media提供出色而又稳定的服务。

然后呢，Igor Sysoev将Nginx代码开源，并且赋予自由软件许可证。

由于：

- Nginx使用基于事件驱动架构，使得其可以支持数以百万级别的TCP连接
- 高度的模块化和自由软件许可证使得第三方模块层出不穷（这是个开源的时代啊~）
- Nginx是一个跨平台服务器，可以运行在Linux，Windows，FreeBSD，Solaris，AIX，Mac OS等操作系统上
- 这些优秀的设计带来的是极大的稳定性

所以，Nginx火了！

## Nginx的用武之地

Nginx是一款自由的、开源的、高性能的HTTP服务器和反向代理服务器；同时也是一个IMAP、POP3、SMTP代理服务器；Nginx可以作为一个HTTP服务器进行网站的发布处理，另外Nginx可以作为反向代理进行负载均衡的实现。

### 关于代理

说到代理，首先我们要明确一个概念，所谓代理就是一个代表、一个渠道；

此时就涉及到两个角色，一个是被代理角色，一个是目标角色，被代理角色通过这个代理访问目标角色完成一些任务的过程称为代理操作过程；如同生活中的专卖店~客人到adidas专卖店买了一双鞋，这个专卖店就是代理，被代理角色就是adidas厂家，目标角色就是用户。

### 正向代理

说反向代理之前，我们先看看正向代理，正向代理也是大家最常接触的到的代理模式，我们会从两个方面来说关于正向代理的处理模式，分别从软件方面和生活方面来解释一下什么叫正向代理。

在如今的网络环境下，我们如果由于技术需要要去访问国外的某些网站，此时你会发现位于国外的某网站我们通过浏览器是没有办法访问的，此时大家可能都会用一个操作FQ进行访问，FQ的方式主要是找到一个可以访问国外网站的代理服务器，我们将请求发送给代理服务器，代理服务器去访问国外的网站，然后将访问到的数据传递给我们！

上述这样的代理模式称为正向代理，正向代理最大的特点是客户端非常明确要访问的服务器地址；服务器只清楚请求来自哪个代理服务器，而不清楚来自哪个具体的客户端；正向代理模式屏蔽或者隐藏了真实客户端信息。来看个示意图（我把客户端和正向代理框在一块，同属于一个环境，后面我有介绍）：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204261528783.png" alt="image-20220426152824694" style="zoom:67%;" />

客户端必须设置正向代理服务器，当然前提是要知道正向代理服务器的IP地址，还有代理程序的端口。如图。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204261528227.png" alt="image-20220426152841112" style="zoom:67%;" />

总结来说：正向代理，"它代理的是客户端，代客户端发出请求"，是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。

正向代理的用途：（1）访问原来无法访问的资源，如Google （2） 可以做缓存，加速访问资源 （3）对客户端访问授权，上网进行认证 （4）代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息

### 反向代理

明白了什么是正向代理，我们继续看关于反向代理的处理方式，举例如我大天朝的某宝网站，每天同时连接到网站的访问人数已经爆表，单个服务器远远不能满足人民日益增长的购买欲望了，此时就出现了一个大家耳熟能详的名词：分布式部署；也就是通过部署多台服务器来解决访问人数限制的问题；某宝网站中大部分功能也是直接使用Nginx进行反向代理实现的，并且通过封装Nginx和其他的组件之后起了个高大上的名字：Tengine，有兴趣的童鞋可以访问Tengine的官网查看具体的信息：http://tengine.taobao.org/。那么反向代理具体是通过什么样的方式实现的分布式的集群操作呢，我们先看一个示意图（我把服务器和反向代理框在一块，同属于一个环境，后面我有介绍）：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204261529662.png" alt="image-20220426152906565" style="zoom:67%;" />

通过上述的图解大家就可以看清楚了，多个客户端给服务器发送的请求，Nginx服务器接收到之后，按照一定的规则分发给了后端的业务处理服务器进行处理了。此时~请求的来源也就是客户端是明确的，但是请求具体由哪台服务器处理的并不明确了，Nginx扮演的就是一个反向代理角色。

客户端是无感知代理的存在的，反向代理对外都是透明的，访问者并不知道自己访问的是一个代理。因为客户端不需要任何配置就可以访问。

反向代理，"它代理的是服务端，代服务端接收请求"，主要用于服务器集群分布式部署的情况下，反向代理隐藏了服务器的信息。

反向代理的作用：（1）保证内网的安全，通常将反向代理作为公网访问地址，Web服务器是内网 （2）负载均衡，通过反向代理服务器来优化网站的负载

#### 项目场景

通常情况下，我们在实际项目操作时，正向代理和反向代理很有可能会存在在一个应用场景中，正向代理代理客户端的请求去访问目标服务器，目标服务器是一个反向单利服务器，反向代理了多台真实的业务处理服务器。具体的拓扑图如下：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204261529089.png" alt="image-20220426152930989" style="zoom:67%;" />

### 二者区别

截了一张图来说明正向代理和反向代理二者之间的区别，如图。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204261530206.png" alt="image-20220426153003098" style="zoom:67%;" />

图解：

在正向代理中，Proxy和Client同属于一个LAN（图中方框内），隐藏了客户端信息；

在反向代理中，Proxy和Server同属于一个LAN（图中方框内），隐藏了服务端信息；

实际上，Proxy在两种代理中做的事情都是替服务器代为收发请求和响应，不过从结构上看正好左右互换了一下，所以把后出现的那种代理方式称为反向代理了。

### 负载均衡

我们已经明确了所谓代理服务器的概念，那么接下来，Nginx扮演了反向代理服务器的角色，它是以依据什么样的规则进行请求分发的呢？不用的项目应用场景，分发的规则是否可以控制呢？

这里提到的客户端发送的、Nginx反向代理服务器接收到的请求数量，就是我们说的负载量。

请求数量按照一定的规则进行分发到不同的服务器处理的规则，就是一种均衡规则。

所以，将服务器接收到的请求按照规则分发的过程，称为负载均衡。

负载均衡在实际项目操作过程中，有硬件负载均衡和软件负载均衡两种，硬件负载均衡也称为硬负载，如F5负载均衡，相对造价昂贵成本较高，但是数据的稳定性安全性等等有非常好的保障，如中国移动中国联通这样的公司才会选择硬负载进行操作；更多的公司考虑到成本原因，会选择使用软件负载均衡，软件负载均衡是利用现有的技术结合主机硬件实现的一种消息队列分发机制。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204261530875.png" alt="image-20220426153032769" style="zoom:67%;" />

Nginx支持的负载均衡调度算法方式如下：

1. weight轮询(默认，常用)：接收到的请求按照权重分配到不同的后端服务器，即使在使用过程中，某一台后端服务器宕机，Nginx会自动将该服务器剔除出队列，请求受理情况不会受到任何影响。这种方式下，可以给不同的后端服务器设置一个权重值(weight)，用于调整不同的服务器上请求的分配率；权重数据越大，被分配到请求的几率越大；该权重值，主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的。
2. ip_hash（常用）：每个请求按照发起客户端的ip的hash结果进行匹配，这样的算法下一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。
3. fair：智能调整调度算法，动态的根据后端服务器的请求处理到响应的时间进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高，响应时间长处理效率低的服务器分配到的请求少；结合了前两者的优点的一种调度算法。但是需要注意的是Nginx默认不支持fair算法，如果要使用这种调度算法，请安装upstream_fair模块。
4. url_hash：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在Nginx作为静态服务器的情况下提高缓存效率。同样要注意Nginx默认不支持这种调度算法，要使用的话需要安装Nginx的hash软件包。

## 几种常用web服务器对比

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204261530754.png" alt="image-20220426153054667" style="zoom:67%;" />



# Nginx 入门到实战，适合新手学习！

## Nginx是什么？

**Nginx**是一个开源且高性能、可靠的HTTP中间件、代理服务其他的HTTP服务：

- HTTPD-Apache基金会
- IIS-微软
- GWS-Google(不对外开放)

近几年，Nginx的市场占有率越来越高，一度飙升，为什么呢？接下来我们就知道了！



## 我们为什么选择Nginx？

**1. IO多路复用epoll（IO复用）**

如何理解呢？举个例子吧！有A、B、C三个老师，他们都遇到一个难题，要帮助一个班级的学生解决课堂作业。

老师A采用从第一排开始一个学生一个学生轮流解答的方式去回答问题，老师A浪费了很多时间，并且有的学生作业还没有完成呢，老师就来了，反反复复效率极慢。

老师B是一个忍者，他发现老师A的方法行不通，于是他使用了影分身术，分身出好几个自己同一时间去帮好几个同学回答问题，最后还没回答完，老师B消耗光了能量累倒了。

老师C比较精明，他告诉学生，谁完成了作业举手，有举手的同学他才去指导问题，他让学生主动发声，分开了“并发”。这个老师C就是Nginx。另外，关注公号“终码一生”，回复关键词“资料”，获取视频教程和最新的面试资料！



**2. 轻量级**

- 功能模块少 - Nginx仅保留了HTTP需要的模块，其他都用插件的方式，后天添加
- 代码模块化 - 更适合二次开发，如阿里巴巴Tengine



**3. CPU亲和**

把CPU核心和Nginx工作进程绑定，把每个worker进程固定在一个CPU上执行，减少切换CPU的cache miss，从而提高性能。





##  基本配置

```apl
#打开主配置文件，若你是用lnmp环境安装
vim /usr/local/nginx/conf/nginx.conf

----------------------------------------

user #设置nginx服务的系统使用用户
worker_processes #工作进程数 一般情况与CPU核数保持一致
error_log #nginx的错误日志
pid #nginx启动时的pid

events {
    worker_connections    #每个进程允许最大连接数
    use #nginx使用的内核模型
}
```

我们使用 nginx 的 http 服务，在配置文件 nginx.conf 中的 http 区域内，配置无数个 server ，每一个 server 对应这一个虚拟主机或者域名

```apl
http {
    ... ... #后面再详细介绍 http 配置项目

    server {
        listen 80 #监听端口;
        server_name localhost #地址

        location / { #访问首页路径
            root /xxx/xxx/index.html #默认目录
            index index.html index.htm #默认文件
        }

        error_page 500 504 /50x.html #当出现以上状态码时从新定义到50x.html
        location = /50x.html { #当访问50x.html时
            root /xxx/xxx/html #50x.html 页面所在位置
        }
    }

    server {
        ... ...
    }
}
```



一个 server 可以出现多个 location ，我们对不同的访问路径进行不同情况的配置 我们再来看看 http 的配置详情

```apl
http {
    sendfile  on                  #高效传输文件的模式 一定要开启
    keepalive_timeout 65        #客户端服务端请求超时时间
    log_format main XXX #定义日志格式 代号为main
    access_log /usr/local/access.log main #日志保存地址 格式代码 main
}
```



## 模块

查看 nginx 已开启和编联进去的模块，模块太多了，就不在这长篇大论，有需要自行百度吧~

```apl
#大写V查看所有模块，小写v查看版本
nginx -V
# 查看此配置文件 是否存在语法错误
nginx -tc /usr/local/nginx/conf/nginx.conf
```



## 静态资源 Web 服务

**1. 静态资源类型**

非服务器动态运行生成的文件，换句话说，就是可以直接在服务器上找到对应文件的请求

1. 浏览器端渲染：HTML,CSS,JS

2. 图片：JPEG,GIF,PNG

3. 视频：FLV,MPEG

4. 文件：TXT，任意下载文件



**2. 静态资源服务场景-CDN**

什么是CDN？例如一个北京用户要请求一个文件，而文件放在的新疆的资源存储中心，如果直接请求新疆距离太远，延迟久。使用nginx静态资源回源，分发给北京的资源存储中心，让用户请求的动态定位到北京的资源存储中心请求，实现传输延迟的最小化



**3. nginx静态资源配置**

配置域：http、server、location

```apl
http {
     sendfile   on;
}

http {
     sendfile   on;
     tcp_nopush on;
}

http {
     sendfile   on;
     tcp_nopush on;
     tcp_nodelay on;
}

location ~ .*\.(gif|jpg)$ {
    gzip on;
    gzip_http_version 1.1;
    gzip_comp_level 2;
    gzip_types   text/plain application/javascript application/x-javascript text/javascript text/css application/xml application/xml+rss image/jpeg image/gif image/png;
    root /opt/app/code;
}

location ~ load^/download {
    gzip_static on 
    tcp_nopush on;
    root /opt/app/code;
}
```



## 浏览器缓存

HTTP协议定义的缓存机制（如：Expires; Cache-control等 ），减少服务端的消耗，降低延迟

**1. 浏览器无缓存**

浏览器请求 -> 无缓存 -> 请求WEB服务器 -> 请求相应 -> 呈现

在呈现阶段会根据缓存的设置在浏览器中生成缓存



**2. 浏览器有缓存**

浏览器请求 -> 有缓存 -> 校验本地缓存时间是否过期 -> 没有过期 -> 呈现

若过期从新请求WEB服务器



**3. 语法配置**

```apl
location ~ .*\.(html|htm)$ {
    expires 12h;
}
```

服务器响应静态文件时，请求头信息会带上 etag 和 last_modified_since 2个标签值，浏览器下次去请求时，头信息发送这两个标签，服务器检测文件有没有发生变化，如无,直接头信息返 etag 和last_modified_since，状态码为 304 ，浏览器知道内容无改变,于是直接调用本地缓存，这个过程也请求了服务，但是传着的内容极少。另外，关注公号“终码一生”，回复关键词“资料”，获取视频教程和最新的面试资料！



## 跨站访问

开发 nginx 跨站访问设置

```apl
location ~ .*\.(html|htm)$ {
     add_header Access-Control-Allow-Origin *;
     add_header Access-Control-Allow-Methods GET,POST,PUT,DELETE,OPTIONS;
     #Access-Control-Allow-Credentials true #允许cookie跨域
}
```

在响应中指定 Access-Control-Allow-Credentials 为 true 时，Access-Control-Allow-Origin 不能指定为 *，需要指定到具体域名。

相关跨域内容可参考 Laravel 跨域功能中间件 使用代码实现跨域，原理与nginx跨域配置相同



## 防盗链

防止服务器内的静态资源被其他网站所套用，此处介绍的 nginx 防盗链为基础方式，其它更加深入的方式将在之后的文章介绍

首先，需要理解一个nginx变量

$http_referer #表示当前请求上一次页面访问的地址，换句话说，访问 www.baidu.com 主页，这是第一次访问，所以 $http_referer 为空，但是 访问此页面的时候还需要获取一张首页图片，再请求这张图片的时候 $http_referer 就为 www.baidu.com。

然后配置

```apl
location ~ .*\.(jpg|gif)$ {
    valid_referers none blocked 127.xxx.xxx.xx
    if ($invalid_referer) {
        return 403;
    }
}
```



## HTTP代理服务

Nginx可以实现多种代理方式

- HTTP
- ICMPPOPIMAP
- HTTPS
- RTMP

**1. 代理区别**

区别在于代理的对象不一样，正向代理代理的对象是客户端，反向代理代理的对象是服务端



**2. 反向代理**

```apl
语法：proxy_pass URL
默认：——
位置：loaction

server {
    listen 80;
    location / {
        proxy_pass http://127.0.0.1:8080/;
        proxy_redirect default;
        
        proxy_set_header Host $http_host;
        proxy_set_header X-Real-IP $remote_addr;
        
        proxy_connect_timeout 30;
        proxy_send_timeout 60;
        proxy_read_timeout 60;
        
        proxy_buffer_size 32k;
        proxy_buffering on;
        proxy_buffers 4 128k;
        proxy_busy_buffers_size 256k;
        proxy_max_temp_file_size 256k;
    }
}
```



# Nginx 面试 40 问与答

[Nginx 面试 40 问与答 (qq.com)](https://mp.weixin.qq.com/s?__biz=MzkzMDI1NjcyOQ==&mid=2247499360&idx=1&sn=75d294178ecc907bbce0f2128da19c7e&chksm=c27fbc56f5083540e03f519aca92dcf90978442e0ad1b31af3bda0ec72b2c5468897cfbe1170&mpshare=1&scene=23&srcid=0420zTIqqppkBtDvIakjl6C9&sharer_sharetime=1650467648326&sharer_shareid=29b8a04db1dbd975e3bf4e9f47e7ac67#rd)

## 什么是Nginx？

Nginx是一个 轻量级/高性能的反向代理Web服务器，用于 HTTP、HTTPS、SMTP、POP3 和 IMAP 协议。他实现非常高效的反向代理、负载平衡，他可以处理2-3万并发连接数，官方监测能支持5万并发，现在中国使用nginx网站用户有很多，例如：新浪、网易、 腾讯等。

## Nginx 有哪些优点？

- 跨平台、配置简单。
- 非阻塞、高并发连接：处理 2-3 万并发连接数，官方监测能支持 5 万并发。
- 内存消耗小：开启 10 个 Nginx 才占 150M 内存。
- 成本低廉，且开源。
- 稳定性高，宕机的概率非常小。
- 内置的健康检查功能：如果有一个服务器宕机，会做一个健康检查，再发送的请求就不会发送到宕机的服务器了。重新将请求提交到其他的节点上

## Nginx应用场景？

- http服务器。Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。
- 虚拟主机。可以实现在一台服务器虚拟出多个网站，例如个人网站使用的虚拟机。
- 反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用nginx做反向代理。并且多台服务器可以平均分担负载，不会应为某台服务器负载高宕机而某台服务器闲置的情况。
- nginz 中也可以配置安全管理、比如可以使用Nginx搭建API接口网关,对每个接口服务进行拦截。

## Nginx怎么处理请求的(重点)？

```apl
server {         # 第一个Server区块开始，表示一个独立的虚拟主机站点
   listen       80； # 提供服务的端口，默认80
   server_name  localhost; # 提供服务的域名主机名
   location / { # 第一个location区块开始
     root   html; # 站点的根目录，相当于Nginx的安装目录
     index  index.html index.html;  # 默认的首页文件，多个用空格分开
} # 第一个location区块结果
```

- 首先，Nginx 在启动时，会解析配置文件，得到需要监听的端口与 IP 地址，然后在 Nginx 的 Master 进程里面先初始化好这个监控的Socket(创建 S ocket，设置 addr、reuse 等选项，绑定到指定的 ip 地址端口，再 listen 监听)。
- 然后，再 fork(一个现有进程可以调用 fork 函数创建一个新进程。由 fork 创建的新进程被称为子进程 )出多个子进程出来。
- 之后，子进程会竞争 accept 新的连接。此时，客户端就可以向 nginx 发起连接了。当客户端与nginx进行三次握手，与 nginx 建立好一个连接后。此时，某一个子进程会 accept 成功，得到这个建立好的连接的 Socket ，然后创建 nginx 对连接的封装，即 ngx_connection_t 结构体。
- 接着，设置读写事件处理函数，并添加读写事件来与客户端进行数据的交换。
- 最后，Nginx 或客户端来主动关掉连接，到此，一个连接就寿终正寝了。



## Nginx 是如何实现高并发的？

如果一个 server 采用一个进程(或者线程)负责一个request的方式，那么进程数就是并发数。那么显而易见的，就是会有很多进程在等待中。等什么？最多的应该是等待网络传输。

而 Nginx 的异步非阻塞工作方式正是利用了这点等待的时间。在需要等待的时候，这些进程就空闲出来待命了。因此表现为少数几个进程就解决了大量的并发问题。

Nginx是如何利用的呢，简单来说：同样的 4 个进程，如果采用一个进程负责一个 request 的方式，那么，同时进来 4 个 request 之后，每个进程就负责其中一个，直至会话关闭。期间，如果有第 5 个request进来了。就无法及时反应了，因为 4 个进程都没干完活呢，因此，一般有个调度进程，每当新进来了一个 request ，就新开个进程来处理。

**回想下，BIO 是不是存在酱紫的问题？**

Nginx 不这样，每进来一个 request ，会有一个 worker 进程去处理。但不是全程的处理，处理到什么程度呢？处理到可能发生阻塞的地方，比如向上游（后端）服务器转发 request ，并等待请求返回。那么，这个处理的 worker 不会这么傻等着，他会在发送完请求后，注册一个事件：“如果 upstream 返回了，告诉我一声，我再接着干”。于是他就休息去了。此时，如果再有 request 进来，他就可以很快再按这种方式处理。而一旦上游服务器返回了，就会触发这个事件，worker 才会来接手，这个 request 才会接着往下走。

这就是为什么说，Nginx 基于事件模型。

由于 web server 的工作性质决定了每个 request 的大部份生命都是在网络传输中，实际上花费在 server 机器上的时间片不多。这是几个进程就解决高并发的秘密所在。即：

webserver 刚好属于网络 IO 密集型应用，不算是计算密集型。

异步，非阻塞，使用 epoll ，和大量细节处的优化。也正是 Nginx 之所以然的技术基石。

## 什么是正向代理？

一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。

客户端才能使用正向代理。正向代理总结就一句话：代理端代理的是客户端。例如说：我们使用的OpenVPN 等等。

## 什么是反向代理？

反向代理（Reverse Proxy）方式，是指以代理服务器来接受 Internet上的连接请求，然后将请求，发给内部网络上的服务器并将从服务器上得到的结果返回给 Internet 上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。

> 反向代理总结就一句话：代理端代理的是服务端。

## 反向代理服务器的优点是什么?

反向代理服务器可以隐藏源服务器的存在和特征。它充当互联网云和web服务器之间的中间层。这对于安全方面来说是很好的，特别是当您使用web托管服务时。

## Nginx目录结构有哪些(重点)？

```apl
tree /usr/local/nginx
/usr/local/nginx
├── client_body_temp
├── conf                             # Nginx所有配置文件的目录
│   ├── fastcgi.conf                 # fastcgi相关参数的配置文件
│   ├── fastcgi.conf.default         # fastcgi.conf的原始备份文件
│   ├── fastcgi_params               # fastcgi的参数文件
│   ├── fastcgi_params.default       
│   ├── koi-utf
│   ├── koi-win
│   ├── mime.types                   # 媒体类型
│   ├── mime.types.default
│   ├── nginx.conf                   # Nginx主配置文件
│   ├── nginx.conf.default
│   ├── scgi_params                  # scgi相关参数文件
│   ├── scgi_params.default  
│   ├── uwsgi_params                 # uwsgi相关参数文件
│   ├── uwsgi_params.default
│   └── win-utf
├── fastcgi_temp                     # fastcgi临时数据目录
├── html                             # Nginx默认站点目录
│   ├── 50x.html                     # 错误页面优雅替代显示文件，例如当出现502错误时会调用此页面
│   └── index.html                   # 默认的首页文件
├── logs                             # Nginx日志目录
│   ├── access.log                   # 访问日志文件
│   ├── error.log                    # 错误日志文件
│   └── nginx.pid                    # pid文件，Nginx进程启动后，会把所有进程的ID号写到此文件
├── proxy_temp                       # 临时目录
├── sbin                             # Nginx命令目录
│   └── nginx                        # Nginx的启动命令
├── scgi_temp                        # 临时目录
└── uwsgi_temp                       # 临时目录
```

## Nginx配置文件nginx.conf有哪些属性模块(重点)?

```apl
worker_processes  1；                                    # worker进程的数量
events {                                                  # 事件区块开始
    worker_connections  1024；                            # 每个worker进程支持的最大连接数
}                                                        # 事件区块结束
http {                                                   # HTTP区块开始
    include       mime.types；                           # Nginx支持的媒体类型库文件
    default_type  application/octet-stream；             # 默认的媒体类型
    sendfile        on；                                   # 开启高效传输模式
    keepalive_timeout  65；                               # 连接超时
    server {                  # 第一个Server区块开始，表示一个独立的虚拟主机站点
        listen       80；                                  # 提供服务的端口，默认80
        server_name  localhost；                           # 提供服务的域名主机名
        location / {                                    # 第一个location区块开始
            root   html；                               # 站点的根目录，相当于Nginx的安装目录
            index  index.html index.htm；                  # 默认的首页文件，多个用空格分开
        }                                                  # 第一个location区块结果
        error_page   500502503504  /50x.html；  # 出现对应的http状态码时，使用50x.html回应客户
        location = /50x.html {                          # location区块开始，访问50x.html
            root   html；                                  # 指定对应的站点目录为html
        }
    }  
    ......
}
```

## cookie和session区别？

#### 共同：

存放用户信息。存放的形式：key-value格式 变量和变量内容键值对。

#### 区别：

cookie

- 存放在客户端浏览器
- 每个域名对应一个cookie，不能跨跃域名访问其他cookie
- 用户可以查看或修改cookie
- http响应报文里面给你浏览器设置
- 钥匙（用于打开浏览器上锁头）

session:

- 存放在服务器（文件，数据库，redis）
- 存放敏感信息
- 锁头

## 为什么 Nginx 不使用多线程？

**Apache:** 创建多个进程或线程，而每个进程或线程都会为其分配 cpu 和内存（线程要比进程小的多，所以 worker 支持比 perfork 高的并发），并发过大会榨干服务器资源。

**Nginx:** 采用单线程来异步非阻塞处理请求（管理员可以配置 Nginx 主进程的工作进程的数量）(epoll)，不会为每个请求分配 cpu 和内存资源，节省了大量资源，同时也减少了大量的 CPU 的上下文切换。所以才使得 Nginx 支持更高的并发。

## nginx和apache的区别

轻量级，同样起web服务，比apache占用更少的内存和资源。

抗并发，nginx处理请求是异步非阻塞的，而apache则是阻塞性的，在高并发下nginx能保持低资源，低消耗高性能。

高度模块化的设计，编写模块相对简单。

最核心的区别在于apache是同步多进程模型，一个连接对应一个进程，nginx是异步的，多个连接可以对应一个进程。

## 什么是动态资源、静态资源分离？

动态资源、静态资源分离，是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路。

动态资源、静态资源分离简单的概括是：动态文件与静态文件的分离。

## 为什么要做动、静分离？

在我们的软件开发中，有些请求是需要后台处理的（如：.jsp,.do 等等），有些请求是不需要经过后台处理的（如：css、html、jpg、js 等等文件），这些不需要经过后台处理的文件称为静态文件，否则动态文件。

因此我们后台处理忽略静态文件。这会有人又说那我后台忽略静态文件不就完了吗？当然这是可以的，但是这样后台的请求次数就明显增多了。在我们对资源的响应速度有要求的时候，我们应该使用这种动静分离的策略去解决动、静分离将网站静态资源（HTML，JavaScript，CSS，img等文件）与后台应用分开部署，提高用户访问静态代码的速度，降低对后台应用访问

这里我们将静态资源放到 Nginx 中，动态资源转发到 Tomcat 服务器中去。

当然，因为现在七牛、阿里云等 CDN 服务已经很成熟，主流的做法，是把静态资源缓存到 CDN 服务中，从而提升访问速度。

相比本地的 Nginx 来说，CDN 服务器由于在国内有更多的节点，可以实现用户的就近访问。并且，CDN 服务可以提供更大的带宽，不像我们自己的应用服务，提供的带宽是有限的。

## 什么叫 CDN 服务？

CDN ，即内容分发网络。

其目的是，通过在现有的 Internet中 增加一层新的网络架构，将网站的内容发布到最接近用户的网络边缘，使用户可就近取得所需的内容，提高用户访问网站的速度。

一般来说，因为现在 CDN 服务比较大众，所以基本所有公司都会使用 CDN 服务。

## Nginx怎么做的动静分离？

只需要指定路径对应的目录。location/可以使用正则表达式匹配。并指定对应的硬盘中的目录。如下：（操作都是在Linux上）

```apl
location /image/ {
    root   /usr/local/static/;
    autoindex on;
}
```

步骤：

```apl
# 创建目录
mkdir /usr/local/static/image
 
# 进入目录
cd  /usr/local/static/image
 
# 上传照片
photo.jpg
 
# 重启nginx
sudo nginx -s reload
```

打开浏览器 输入 `server_name/image/1.jpg` 就可以访问该静态图片了

## Nginx负载均衡的算法怎么实现的?策略有哪些?

为了避免服务器崩溃，大家会通过负载均衡的方式来分担服务器压力。将对台服务器组成一个集群，当用户访问时，先访问到一个转发服务器，再由转发服务器将访问分发到压力更小的服务器。

Nginx负载均衡实现的策略有以下五种：

#### 1 .轮询(默认)

每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某个服务器宕机，能自动剔除故障系统。

```apl
upstream backserver { 
 server 192.168.0.12; 
 server 192.168.0.13; 
} 
```

#### 2. 权重 weight

weight的值越大，分配到的访问概率越高，主要用于后端每台服务器性能不均衡的情况下。其次是为在主从的情况下设置不同的权值，达到合理有效的地利用主机资源。

```apl
# 权重越高，在被访问的概率越大，如上例，分别是20%，80%。
upstream backserver { 
 server 192.168.0.12 weight=2; 
 server 192.168.0.13 weight=8; 
} 
```

#### 3. ip_hash( IP绑定)

每个请求按访问IP的哈希结果分配，使来自同一个IP的访客固定访问一台后端服务器，并且可以有效解决动态网页存在的session共享问题

```apl
upstream backserver { 
 ip_hash; 
 server 192.168.0.12:88; 
 server 192.168.0.13:80; 
} 
```

#### 4. fair(第三方插件)

必须安装upstream_fair模块。

对比 weight、ip_hash更加智能的负载均衡算法，fair算法可以根据页面大小和加载时间长短智能地进行负载均衡，响应时间短的优先分配。

```apl
# 哪个服务器的响应速度快，就将请求分配到那个服务器上。
upstream backserver { 
 server server1; 
 server server2; 
 fair; 
} 
```

#### 5.url_hash(第三方插件)

必须安装Nginx的hash软件包

按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率。

```apl
upstream backserver { 
 server squid1:3128; 
 server squid2:3128; 
 hash $request_uri; 
 hash_method crc32; 
}
```

## 如何用Nginx解决前端跨域问题？

使用Nginx转发请求。把跨域的接口写成调本域的接口，然后将这些接口转发到真正的请求地址。

## Nginx虚拟主机怎么配置?

1、基于域名的虚拟主机，通过域名来区分虚拟主机——应用：外部网站

2、基于端口的虚拟主机，通过端口来区分虚拟主机——应用：公司内部网站，外部网站的管理后台

3、基于ip的虚拟主机。

#### 基于虚拟主机配置域名

需要建立`/data/www /data/bbs`目录，windows本地hosts添加虚拟机ip地址对应的域名解析；对应域名网站目录下新增index.html文件；

```apl
# 当客户端访问www.lijie.com,监听端口号为80,直接跳转到data/www目录下文件
server {
    listen       80;
    server_name  www.lijie.com;
    location / {
        root   data/www;
        index  index.html index.htm;
    }
}

# 当客户端访问www.lijie.com,监听端口号为80,直接跳转到data/bbs目录下文件
 server {
    listen       80;
    server_name  bbs.lijie.com;
    location / {
        root   data/bbs;
        index  index.html index.htm;
    }
}
```

#### 基于端口的虚拟主机

使用端口来区分，浏览器使用域名或ip地址:端口号 访问

```apl
# 当客户端访问www.lijie.com,监听端口号为8080,直接跳转到data/www目录下文件
 server {
    listen       8080;
    server_name  8080.lijie.com;
    location / {
        root   data/www;
        index  index.html index.htm;
    }
}

# 当客户端访问www.lijie.com,监听端口号为80直接跳转到真实ip服务器地址 127.0.0.1:8080
server {
    listen       80;
    server_name  www.lijie.com;
    location / {
         proxy_pass http://127.0.0.1:8080;
        index  index.html index.htm;
    }
}
```

## location的作用是什么？

location指令的作用是根据用户请求的URI来执行不同的应用，也就是根据用户请求的网站URL进行匹配，匹配成功即进行相关的操作。

location的语法能说出来吗？

> 注意：~ 代表自己输入的英文字母

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204221656500.png" alt="image-20220422165608447" style="zoom:67%;" />

#### Location正则案例

```apl
# 优先级1,精确匹配，根路径
location =/ {
    return 400;
}

# 优先级2,以某个字符串开头,以av开头的，优先匹配这里，区分大小写
location ^~ /av {
   root /data/av/;
}

# 优先级3，区分大小写的正则匹配，匹配/media*****路径
location ~ /media {
      alias /data/static/;
}

# 优先级4 ，不区分大小写的正则匹配，所有的****.jpg|gif|png 都走这里
location ~* .*\.(jpg|gif|png|js|css)$ {
   root  /data/av/;
}

# 优先7，通用匹配
location / {
    return 403;
}
```

## 限流怎么做的？

Nginx限流就是限制用户请求速度，防止服务器受不了

限流有3种

- 正常限制访问频率（正常流量）
- 突发限制访问频率（突发流量）
- 限制并发连接数

Nginx的限流都是基于漏桶流算法

> 实现三种限流算法

#### 1、正常限制访问频率（正常流量）：

限制一个用户发送的请求，我Nginx多久接收一个请求。

Nginx中使用`ngx_http_limit_req_module`模块来限制的访问频率，限制的原理实质是基于漏桶算法原理来实现的。在nginx.conf配置文件中可以使用`limit_req_zone`命令及`limit_req`命令限制单个IP的请求处理频率。

```apl
# 定义限流维度，一个用户一分钟一个请求进来，多余的全部漏掉
limit_req_zone $binary_remote_addr zone=one:10m rate=1r/m;

# 绑定限流维度
server{
    
    location/seckill.html{
        limit_req zone=zone;    
        proxy_pass http://lj_seckill;
    }
}
```

1r/s代表1秒一个请求，1r/m一分钟接收一个请求， 如果Nginx这时还有别人的请求没有处理完，Nginx就会拒绝处理该用户请求。

#### 2、突发限制访问频率（突发流量）：

限制一个用户发送的请求，我Nginx多久接收一个。

上面的配置一定程度可以限制访问频率，但是也存在着一个问题：如果突发流量超出请求被拒绝处理，无法处理活动时候的突发流量，这时候应该如何进一步处理呢？

Nginx提供burst参数结合nodelay参数可以解决流量突发的问题，可以设置能处理的超过设置的请求数外能额外处理的请求数。我们可以将之前的例子添加burst参数以及nodelay参数：

```apl
# 定义限流维度，一个用户一分钟一个请求进来，多余的全部漏掉
limit_req_zone $binary_remote_addr zone=one:10m rate=1r/m;

# 绑定限流维度
server{
    
    location/seckill.html{
        limit_req zone=zone burst=5 nodelay;
        proxy_pass http://lj_seckill;
    }

}
```

为什么就多了一个 burst=5 nodelay; 呢，多了这个可以代表Nginx对于一个用户的请求会立即处理前五个，多余的就慢慢来落，没有其他用户的请求我就处理你的，有其他的请求的话我Nginx就漏掉不接受你的请求

#### 3、 限制并发连接数

Nginx中的`ngx_http_limit_conn_module`模块提供了限制并发连接数的功能，可以使用`limit_conn_zone`指令以及`limit_conn`执行进行配置。接下来我们可以通过一个简单的例子来看下：

```apl
http {
    limit_conn_zone $binary_remote_addr zone=myip:10m;
    limit_conn_zone $server_name zone=myServerName:10m;
}

server {
    location / {
        limit_conn myip 10;
        limit_conn myServerName 100;
        rewrite / http://www.lijie.net permanent;
    }
} 
```

上面配置了单个IP同时并发连接数最多只能10个连接，并且设置了整个虚拟服务器同时最大并发数最多只能100个链接。当然，只有当请求的header被服务器处理后，虚拟服务器的连接数才会计数。刚才有提到过Nginx是基于漏桶算法原理实现的，实际上限流一般都是基于漏桶算法和令牌桶算法实现的。

## 漏桶流算法和令牌桶算法知道？

#### 漏桶算法

漏桶算法思路很简单，我们把水比作是请求，漏桶比作是系统处理能力极限，水先进入到漏桶里，漏桶里的水按一定速率流出，当流出的速率小于流入的速率时，由于漏桶容量有限，后续进入的水直接溢出（拒绝请求），以此实现限流。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204221656333.png" alt="image-20220422165646249" style="zoom:67%;" />

#### 令牌桶算法

令牌桶算法的原理也比较简单，我们可以理解成医院的挂号看病，只有拿到号以后才可以进行诊病。

系统会维护一个令牌（token）桶，以一个恒定的速度往桶里放入令牌（token），这时如果有请求进来想要被处理，则需要先从桶里获取一个令牌（token），当桶里没有令牌（token）可取时，则该请求将被拒绝服务。令牌桶算法通过控制桶的容量、发放令牌的速率，来达到对请求的限制。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204221657781.png" alt="image-20220422165703696" style="zoom:67%;" />

## Nginx配置高可用性怎么配置？

当上游服务器(真实访问服务器)，一旦出现故障或者是没有及时相应的话，应该直接轮训到下一台服务器，保证服务器的高可用

Nginx配置代码：

```apl
server {
        listen       80;
        server_name  www.lijie.com;
        location / {
            # 指定上游服务器负载均衡服务器
            proxy_pass http://backServer;
     #nginx与上游服务器(真实访问的服务器)超时时间 后端服务器连接的超时时间_发起握手等候响应超时时间
            proxy_connect_timeout 1s;
            #nginx发送给上游服务器(真实访问的服务器)超时时间
            proxy_send_timeout 1s;
            # nginx接受上游服务器(真实访问的服务器)超时时间
            proxy_read_timeout 1s;
            index  index.html index.htm;
        }
    }
```



## Nginx怎么判断别IP不可访问？

```apl
  # 如果访问的ip地址为192.168.9.115,则返回403
 if  ($remote_addr = 192.168.9.115) {  
     return 403;  
 }  
```



## 在nginx中，如何使用未定义的服务器名称来阻止处理请求？

只需将请求删除的服务器就可以定义为：

服务器名被保留一个空字符串，他在没有主机头字段的情况下匹配请求，而一个特殊的nginx的非标准代码被返回，从而终止连接。

## 怎么限制浏览器访问？

```apl
## 不允许谷歌浏览器访问 如果是谷歌浏览器返回500
if ($http_user_agent ~ Chrome) {   
  return 500;  
}
```



## Rewrite全局变量是什么？

```scss
$remote_addr        //获取客户端ip
$binary_remote_addr //客户端ip（二进制)
$remote_port        //客户端port，如：50472
$remote_user        //已经经过Auth Basic Module验证的用户名
$host           //请求主机头字段，否则为服务器名称，如:blog.sakmon.com
$request        //用户请求信息，如：GET ?a=1&b=2 HTTP/1.1
$request_filename   //当前请求的文件的路径名，由root或alias和URI request组合而成，如：/2013/81.html
$status         //请求的响应状态码,如:200
$body_bytes_sent        // 响应时送出的body字节数数量。即使连接中断，这个数据也是精确的,如：40
$content_length        // 等于请求行的“Content_Length”的值
$content_type          // 等于请求行的“Content_Type”的值
$http_referer          // 引用地址
$http_user_agent      // 客户端agent信息,如：Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.76 Safari/537.36
$args            //与$query_string相同 等于当中URL的参数(GET)，如a=1&b=2
$document_uri        //与$uri相同  这个变量指当前的请求URI，不包括任何参数(见$args) 如:/2013/81.html
$document_root       //针对当前请求的根路径设置值
$hostname        //如：centos53.localdomain
$http_cookie        //客户端cookie信息
$cookie_COOKIE      //cookie COOKIE变量的值
$is_args    //如果有$args参数，这个变量等于”?”，否则等于”"，空值，如?
$limit_rate //这个变量可以限制连接速率，0表示不限速
$query_string       // 与$args相同 等于当中URL的参数(GET)，如a=1&b=2
$request_body      // 记录POST过来的数据信息
$request_body_file  //客户端请求主体信息的临时文件名
$request_method       //客户端请求的动作，通常为GET或POST,如：GET
$request_uri          //包含请求参数的原始URI，不包含主机名，如：/2013/81.html?a=1&b=2
$scheme            //HTTP方法（如http，https）,如：http
$uri            //这个变量指当前的请求URI，不包括任何参数(见$args) 如:/2013/81.html
$request_completion //如果请求结束，设置为OK. 当请求未结束或如果该请求不是请求链串的最后一个时，为空(Empty)，如：OK
$server_protocol    //请求使用的协议，通常是HTTP/1.0或HTTP/1.1，如：HTTP/1.1
$server_addr        //服务器IP地址，在完成一次系统调用后可以确定这个值
$server_name        //服务器名称，如：blog.sakmon.com
$server_port        //请求到达服务器的端口号,如：80
```

## Nginx 如何实现后端服务的健康检查？

方式一，利用 nginx 自带模块 `ngx_http_proxy_module` 和 `ngx_http_upstream_module` 对后端节点做健康检查。

方式二(推荐)，利用 `nginx_upstream_check_module` 模块对后端节点做健康检查。

## Nginx 如何开启压缩？

开启nginx gzip压缩后，网页、css、js等静态资源的大小会大大的减少，从而可以节约大量的带宽，提高传输效率，给用户快的体验。虽然会消耗cpu资源，但是为了给用户更好的体验是值得的。

开启的配置如下：

将以上配置放到nginx.conf的`http{ … }`节点中。

```apl
http {
  # 开启gzip
  gzip on;
 
  # 启用gzip压缩的最小文件；小于设置值的文件将不会被压缩
  gzip_min_length 1k;
 
  # gzip 压缩级别 1-10 
  gzip_comp_level 2;
 
  # 进行压缩的文件类型。
 
  gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png;
 
  # 是否在http header中添加Vary: Accept-Encoding，建议开启
  gzip_vary on;
}
```

保存并重启nginx，刷新页面（为了避免缓存，请强制刷新）就能看到效果了。以谷歌浏览器为例，通过F12看请求的响应头部：

我们可以先来对比下，如果我们没有开启zip压缩之前，我们的对应的文件大小，如下所示：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204221657859.png" alt="image-20220422165734808" style="zoom:67%;" />

现在我们开启了gzip进行压缩后的文件的大小，可以看到如下所示：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204221657610.png" alt="image-20220422165751552" style="zoom:67%;" />

并且我们查看响应头会看到gzip这样的压缩，如下所示

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204221658036.png" alt="image-20220422165817963" style="zoom:67%;" />

gzip压缩前后效果对比：jquery原大小90kb，压缩后只有30kb。

gzip虽然好用，但是以下类型的资源不建议启用。

#### 1、图片类型

原因：图片如jpg、png本身就会有压缩，所以就算开启gzip后，压缩前和压缩后大小没有多大区别，所以开启了反而会白白的浪费资源。（Tips：可以试试将一张jpg图片压缩为zip，观察大小并没有多大的变化。虽然zip和gzip算法不一样，但是可以看出压缩图片的价值并不大）

#### 2、大文件

原因：会消耗大量的cpu资源，且不一定有明显的效果。

## ngx_http_upstream_module的作用是什么?

ngx_http_upstream_module用于定义可通过fastcgi传递、proxy传递、uwsgi传递、memcached传递和scgi传递指令来引用的服务器组。

## 什么是C10K问题?

C10K问题是指无法同时处理大量客户端(10,000)的网络套接字。

## Nginx是否支持将请求压缩到上游?

您可以使用Nginx模块gunzip将请求压缩到上游。gunzip模块是一个过滤器，它可以对不支持“gzip”编码方法的客户机或服务器使用“内容编码:gzip”来解压缩响应。

## 如何在Nginx中获得当前的时间?

要获得Nginx的当前时间，必须使用SSI模块、和date_local的变量。

```apl
Proxy_set_header THE-TIME $date_gmt;
```

## 用Nginx服务器解释-s的目的是什么?

用于运行Nginx -s参数的可执行文件。

## 如何在Nginx服务器上添加模块?

在编译过程中，必须选择Nginx模块，因为Nginx不支持模块的运行时间选择。

## 生产中如何设置worker进程的数量呢？

在有多个cpu的情况下，可以设置多个worker，worker进程的数量可以设置到和cpu的核心数一样多，如果在单个cpu上起多个worker进程，那么操作系统会在多个worker之间进行调度，这种情况会降低系统性能，如果只有一个cpu，那么只启动一个worker进程就可以了。

## nginx状态码

499：`服务端处理时间过长，客户端主动关闭了连接`

502：

(1).FastCGI进程是否已经启动

(2).FastCGI worker进程数是否不够

(3).FastCGI执行时间过长

- fastcgi_connect_timeout 300;
- fastcgi_send_timeout 300;
- fastcgi_read_timeout 300;

(4).FastCGI Buffer不够，`nginx和apache一样，有前端缓冲限制，可以调整缓冲参数`

- fastcgi_buffer_size 32k;
- fastcgi_buffers 8 32k;

(5). Proxy Buffer不够，`如果你用了Proxying，调整`

- proxy_buffer_size 16k;
- proxy_buffers 4 16k;

(6)`php脚本执行时间过长`

- 将php-fpm.conf的0s的0s改成一个时间

# Nginx为什么比Apache高效！

Nginx才短短几年，就拿下了Web服务器大壁江山，众所周知，Nginx在处理大并发静态请求方面，效率明显高于Httpd，甚至能轻松解决C10K问题。

在高并发连接的情况下，Nginx是Apache服务器不错的替代品。Nginx同时也可以作为7层负载均衡服务器来使用。根据我的测试结果，Nginx + PHP(FastCGI) 可以承受3万以上的并发连接数，相当于同等环境下Apache的10倍。

一般来说，4GB内存的服务器+Apache（prefork模式）一般只能处理3000个并发连接，因为它们将占用3GB以上的内存，还得为系统预留1GB的内存。我曾经就有两台Apache服务器，因为在配置文件中设置的MaxClients为4000，当Apache并发连接数达到3800时，导致服务器内存和Swap空间用满而崩溃。

而这台 Nginx + PHP(FastCGI) 服务器在3万并发连接下，开启的10个Nginx进程消耗150M内存（`15M*10=150M`），开启的64个php-cgi进程消耗1280M内存（`20M*64=1280M`），加上系统自身消耗的内存，总共消耗不到2GB内存。如果服务器内存较小，完全可以只开启25个php-cgi进程，这样php-cgi消耗的总内存数才500M。

在3万并发连接下，访问Nginx+ PHP(FastCGI) 服务器的PHP程序，仍然速度飞快。

**为什么Nginx在处理高并发方面要优于httpd，我们先从两种web服务器的工作原理以及工作模式说起。**

## 一、Apache三种工作模式

我们都知道Apache有三种工作模块，分别为：prefork、worker、event。

- **prefork：**多进程，每个请求用一个进程响应，这个过程会用到select机制来通知。
- **worker：**多线程，一个进程可以生成多个线程，每个线程响应一个请求，但通知机制还是select不过可以接受更多的请求。
- **event：**基于异步I/O模型，一个进程或线程，每个进程或线程响应多个用户请求，它是基于事件驱动（也就是epoll机制）实现的。

### 1、prefork的工作原理

如果不用“–with-mpm”显式指定某种MPM，prefork就是Unix平台上缺省的MPM。它所采用的预派生子进程方式也是 Apache1.3中采用的模式。prefork本身并没有使用到线程，2.0版使用它是为了与1.3版保持兼容性；另一方面，prefork用单独的子进程来处理不同的请求，进程之间是彼此独立的,这也使其成为最稳定的MPM之一。

### 2、worker的工作原理

相对于prefork，worker是2.0版中全新的支持多线程和多进程混合模型的MPM。由于使用线程来处理，所以可以处理相对海量的请求，而系统资源的开销要小于基于进程的服务器。但是，worker也使用了多进程,每个进程又生成多个线程，以获得基于进程服务器的稳定性，这种MPM的工作方 式将是Apache2.0的发展趋势。

### 3、event 基于事件机制的特性

一个进程响应多个用户请求，利用callback机制，让套接字复用，请求过来后进程并不处理请求，而是直接交由其他机制来处理，通过epoll机制来通知请求是否完成；在这个过程中，进程本身一直处于空闲状态，可以一直接收用户请求。可以实现一个进程程响应多个用户请求。支持持海量并发连接数，消耗更少的资源。

## 二、如何提高Web服务器的并发连接处理能力

**有几个基本条件：**

1、基于线程，即一个进程生成多个线程，每个线程响应用户的每个请求。

2、基于事件的模型，一个进程处理多个请求，并且通过epoll机制来通知用户请求完成。

3、基于磁盘的AIO（异步I/O）

4、支持mmap内存映射，mmap传统的web服务器，进行页面输入时，都是将磁盘的页面先输入到内核缓存中，再由内核缓存中复制一份到web服务器上，mmap机制就是让内核缓存与磁盘进行映射，web服务器，直接复制页面内容即可。不需要先把磁盘的上的页面先输入到内核缓存去。

刚好，Nginx 支持以上所有特性。所以Nginx官网上说，Nginx支持50000并发，是有依据的。

## 三、Nginx优异之处

传统上基于进程或线程模型架构的Web服务通过每进程或每线程处理并发连接请求，这势必会在网络和I/O操作时产生阻塞，其另一个必然结果则是对内存或CPU的利用率低下。

生成一个新的进程/线程需要事先备好其运行时环境，这包括为其分配堆内存和栈内存，以及为其创建新的执行上下文等。这些操作都需要占用CPU，而且过多的进程/线程还会带来线程抖动或频繁的上下文切换，系统性能也会由此进一步下降。

另一种高性能web服务器/Web服务器反向代理：Nginx，Nginx的主要着眼点就是其高性能以及对物理计算资源的高密度利用，因此其采用了不同的架构模型。受启发于多种操作系统设计中基于“事件”的高级处理机制，Nginx采用了模块化、事件驱动、异步、单线程及非阻塞的架构，并大量采用了多路复用及事件通知机制。

在Nginx中，连接请求由为数不多的几个仅包含一个线程的进程Worker以高效的回环(run-loop)机制进行处理，而每个Worker可以并行处理数千个的并发连接及请求。

## 四、Nginx 工作原理

Nginx会按需同时运行多个进程：一个主进程(master)和几个工作进程(worker)，配置了缓存时还会有缓存加载器进程(cache loader)和缓存管理器进程(cache manager)等。所有进程均是仅含有一个线程，并主要通过“共享内存”的机制实现进程间通信。主进程以root用户身份运行，而worker、cache loader和cache manager均应以非特权用户身份运行。

**在高连接并发的情况下，Nginx是Apache服务器不错的替代品。**

Nginx 安装非常的简单 , 配置文件非常简洁（还能够支持perl语法）,Bugs 非常少的服务器: Nginx 启动特别容易, 并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动. 你还能够 不间断服务的情况下进行软件版本的升级 。

## 五、Nginx 的诞生主要解决C10K问题

最后我们从各自使用的多路复用IO模型来分析：

### 1、select模型：（apache使用，由于受模块等限制，用的不多）；

单个进程能够 监视的文件描述符的数量存在最大限制；

select()所维护的 存储大量文件描述符的数据结构 ，随着文件描述符数量的增长，其在用户态和内核的地址空间的复制所引发的开销也会线性增长；

由于网络响应时间的延迟使得大量TCP连接处于非活跃状态，但调用select()还是会对 所有的socket进行一次线性扫描 ，会造成一定的开销；

### 2、poll：poll是unix沿用select自己重新实现了一遍，唯一解决的问题是poll 没有最大文件描述符数量的限制；

### 3、epoll模型：（Nginx使用）

epoll带来了两个优势，大幅度提升了性能：

（1）基于事件的就绪通知方式 ，select/poll方式，进程只有在调用一定的方法后，内核才会对所有监视的文件描述符进行扫描，而epoll事件通过epoll_ctl()注册一个文件描述符，一旦某个文件描述符就绪时，内核会采用类似call back的回调机制，迅速激活这个文件描述符，epoll_wait()便会得到通知

（2）调用一次epoll_wait()获得就绪文件描述符时，返回的并不是实际的描述符，而是一个代表就绪描述符数量的值，拿到这些值去epoll指定的一个数组中依次取得相应数量的文件描述符即可，这里使用内存映射（mmap）技术， 避免了复制大量文件描述符带来的开销

（3）当然epoll也有一定的局限性， epoll只有Linux2.6才有实现 ，而其他平台都没有，这和apache这种优秀的跨平台服务器，显然是有些背道而驰了。

（4）简单来说epoll是select的升级版，单进程管理的文件描述符没有最大限制。但epoll只有linux平台可使用。作为跨平台的Apache没有使用

















