


# 静态资源压缩

## 为什么用 Gzip

> 建立在**动静分离的基础之上**，如果一个静态资源的Size越小，那么自然传输速度会更快，同时也会更节省带宽，因此我们在部署项目时，也可以通过Nginx对于静态资源实现压缩传输，一方面可以节省带宽资源，第二方面也可以加快响应速度并提升系统整体吞吐。

> 在Nginx也提供了三个支持资源压缩的模块ngx_http_gzip_module、ngx_http_gzip_static_module、ngx_http_gunzip_module，其中ngx_http_gzip_module属于内置模块，代表着可以直接使用该模块下的一些压缩指令，后续的资源压缩操作都基于该模块，先来看看压缩配置的一些参数/指令：

## Gzip 配置项

| 参数项            | 释义                                           | 参数值                    |
| :---------------- | :--------------------------------------------- | :------------------------ |
| gzip              | 开启或关闭压缩机制                             | on/off;                   |
| gzip_types        | 根据文件类型选择性开启压缩机制                 | image/png、text/css...    |
| gzip_comp_level   | 用于设置压缩级别，级别越高越耗时               | 1~9（越高压缩效果越好）   |
| gzip_vary         | 设置是否携带Vary:Accept-Encoding头域的响应头部 | on/off;                   |
| gzip_buffers      | 设置处理压缩请求的缓冲区数量和大小             | 数量 大小，如16 8k;       |
| gzip_disable      | 针对不同客户端的请求来设置是否开启压缩         | 如 .Chrome.*;             |
| gzip_http_version | 指定压缩响应所需要的最低HTTP请求版本           | 如1.1;                    |
| gzip_min_length   | 设置触发压缩的文件最低大小                     | 如512k;                   |
| gzip_proxied      | 对于后端服务器的响应结果是否开启压缩           | off、expired、no-cache... |

在上述的压缩配置中，最后一个`gzip_proxied`选项，可以根据系统的实际情况决定，总共存在多种选项：

- `off`：关闭`Nginx`对后台服务器的响应结果进行压缩。
- `expired`：如果响应头中包含`Expires`信息，则开启压缩。
- `no-cache`：如果响应头中包含`Cache-Control:no-cache`信息，则开启压缩。
- `no-store`：如果响应头中包含`Cache-Control:no-store`信息，则开启压缩。
- `private`：如果响应头中包含`Cache-Control:private`信息，则开启压缩。
- `no_last_modified`：如果响应头中不包含`Last-Modified`信息，则开启压缩。
- `no_etag`：如果响应头中不包含`ETag`信息，则开启压缩。
- `auth`：如果响应头中包含`Authorization`信息，则开启压缩。
- `any`：无条件对后端的响应结果开启压缩机制。

## Gzip 实战

> 在html目录下放置一个jquery.js，无需修改nginx.conf，因为本来根目录就是html

### 原生访问

访问测试：http://192.168.22.146/jquery.js

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301161203023.png" alt="image-20230116120309894" style="zoom:67%;" />

### 添加Gizp配置访问

```sh
http{
    # 开启压缩机制
    gzip on;
    # 指定会被压缩的文件类型(也可自己配置其他类型),不建议设置成*
    gzip_types text/plain application/javascript text/css application/xml text/javascript 
               image/jpeg image/gif image/png;
    # 设置压缩级别，越高资源消耗越大，但压缩效果越好
    gzip_comp_level 5;
    # 在头部中添加Vary: Accept-Encoding（建议开启）
    gzip_vary on;
    # 处理压缩请求的缓冲区数量和大小
    gzip_buffers 16 8k;
    # 对于不支持压缩功能的客户端请求不开启压缩机制
    gzip_disable "MSIE [1-6]\."; # 低版本的IE浏览器不支持压缩
    # 设置压缩响应所支持的HTTP最低版本
    gzip_http_version 1.1;
    # 设置触发压缩的最小阈值
    gzip_min_length 2k;
    # 关闭对后端服务器的响应结果进行压缩
    gzip_proxied off;
}
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301161208402.png" alt="image-20230116120831263" style="zoom:67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301161210377.png" alt="image-20230116121042250" style="zoom:67%;" />

### 对比区别

> 从图中可以很明显看出，未开启压缩机制前访问时，`js`文件的原始大小为`300K`，当配置好压缩后再重启`Nginx`，会发现文件大小从`300KB→85.7KB`，效果立竿见影！

## 注意事项

> 对于图片、视频类型的数据，会默认开启压缩机制，因此一般无需再次开启压缩。
>
> 对于.js文件而言，需要指定压缩类型为application/javascript，而并非text/javascript、application/x-javascript
>
> 配置抽取：这些配置在很多地方可能都会用到，所以我们可以将这些内容抽取到一个配置文件中，然后通过include指令把配置文件再次加载到nginx.conf配置文件中，方法使用。

## Gzip和sendfile共存问题

> 前面在讲解sendfile的时候，提到过，开启sendfile以后，在读取磁盘上的静态资源文件的时候，可以减少拷贝的次数，可以**不经过用户进程将静态文件通过网络设备发送出去**，但是Gzip要想对资源压缩，是**需要经过用户进程进行操作**的。所以如何解决两个设置的共存问题。

可以使用ngx_http_gzip_static_module模块的gzip_static指令来解决。

gzip_static: 检查与访问资源同名的.gz文件时，response中以gzip相关的header返回.gz文件的内容。

| 语法   | **gzip_static** on \| off \| always; |
| ------ | ------------------------------------ |
| 默认值 | gzip_static off;                     |
| 位置   | http、server、location               |

添加上述命令后，会报一个错误，`unknown directive "gzip_static"`主要的原因是Nginx默认是没有添加ngx_http_gzip_static_module模块。如何来添加?

### gzip_static 模块添加

```sh
# 查询当前Nginx的配置参数
nginx -v
# 将nginx安装目录下sbin目录中的nginx二进制文件进行更名
cd /usr/local/nginx/sbin
mv nginx nginxold
# 进入Nginx的安装目录
cd /root/nginx-1.23.2
# 执行make clean清空之前编译的内容
make clean
# 使用configure来配置参数
./configure --with-http_gzip_static_module
# 使用make命令进行编译
make
# 将objs目录下的nginx二进制执行文件移动到nginx安装目录下的sbin目录中
mv objs/nginx /usr/local/nginx/sbin
# 执行更新命令
make upgrade
# 查看是否安装成功
nginx -V
```

### gzip_static测试使用

直接访问`http://192.168.200.133/jquery.js`

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204281813524.png" alt="1587932106429" style="zoom:67%;" />

(2)使用gzip命令进行压缩

```apl
cd /usr/local/nginx/html
gzip jquery.js
```

(3)再次访问`http://192.168.200.133/jquery.js`

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204281813528.png" alt="1587932300006" style="zoom:67%;" />

# 静态资源缓存 ⭐

## 什么是缓存

> 缓存（cache），原始意义是指访问速度比一般随机存取存储器（RAM）快的一种高速存储器，通常它不像系统主存那样使用DRAM技术，而使用昂贵但较快速的SRAM技术。缓存的设置是所有现代计算机系统发挥高性能的重要因素之一。

## 什么是web缓存

> Web缓存是指一个Web资源（如html页面，图片，js，数据等）存在于Web服务器和客户端（浏览器）之间的副本。缓存会根据进来的请求保存输出内容的副本；当下一个请求来到的时候，如果是相同的URL，缓存会根据缓存机制决定是直接使用副本响应访问请求，还是向源服务器再次发送请求。比较常见的就是浏览器会缓存访问过网站的网页，当再次访问这个URL地址的时候，如果网页没有更新，就不会再次下载网页，而是直接使用本地缓存的网页。只有当网站明确标识资源已经更新，浏览器才会再次下载网页

## web缓存详解

客户端缓存：浏览器缓存；服务端缓存：Nginx / Redis / Memcached等

### 浏览器缓存

> 是为了节约网络的资源加速浏览，浏览器在用户磁盘上对最近请求过的文档进行存储，当访问者再次请求这个页面时，浏览器就可以从本地磁盘显示文档，这样就可以加速页面的阅览.

### 为什么要用浏览器缓存

- 成本最低的一种缓存实现
- 减少网络带宽消耗
- 降低服务器压力
- 减少网络延迟，加快页面打开速度

### 浏览器缓存的执行流程

HTTP协议中和页面缓存相关的字段，我们先来认识下：

| header        | 说明                                        |
| ------------- | ------------------------------------------- |
| Expires       | 缓存过期的日期和时间                        |
| Cache-Control | 设置和缓存相关的配置信息                    |
| Last-Modified | 请求资源最后修改时间                        |
| ETag          | 请求变量的实体标签的当前值，比如文件的MD5值 |

![](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204281823462.png)

（1）用户首次通过浏览器发送请求到服务端获取数据，客户端是没有对应的缓存，所以需要发送request请求获取数据

（2）服务端接收到请求后，获取服务端的数据及服务端缓存的允许后，返回200的成功状态码并且在响应头上附上对应资源以及缓存信息；

（3）当用户再次访问相同资源的时候，客户端会在浏览器的缓存目录中查找是否存在响应的缓存文件

（4）如果没有找到对应的缓存文件，则走(2)步

（5）如果有缓存文件，接下来对缓存文件是否过期进行判断，过期的判断标准是(Expires),

（6）如果没有过期，则直接从本地缓存中返回数据进行展示

（7）如果Expires过期，接下来需要判断缓存文件是否发生过变化

（8）判断的标准有两个，一个是ETag(Entity Tag),一个是Last-Modified

（9）判断结果是未发生变化，则服务端返回304，直接从缓存文件中获取数据

（10）如果判断是发生了变化，重新从服务端获取数据，并根据缓存协商(服务端所设置的是否需要进行缓存数据的设置)来进行数据缓存。

## 浏览器缓存指令

Nginx需要进行缓存相关设置，就需要用到如下的指令

### expires指令

expires:该指令用来控制页面缓存的作用。可以通过该指令控制HTTP应答中的“Expires"和”Cache-Control"

| 语法   | expires   [modified] time             expires epoch\|max\|off; |
| ------ | ------------------------------------------------------------ |
| 默认值 | expires off;                                                 |
| 位置   | http、server、location                                       |

- time:可以整数也可以是负数，指定过期时间，如果是负数，Cache-Control则为no-cache,如果为整数或0，则Cache-Control的值为max-age=time;
- epoch: 指定Expires的值为'1 January,1970,00:00:01 GMT'(1970-01-01 00:00:00)，Cache-Control的值no-cache
- max:指定Expires的值为'31 December2037 23:59:59GMT' (2037-12-31 23:59:59) ，Cache-Control的值为10年
- off:默认不缓存。

### add_header指令

add_header指令是用来添加指定的响应头和响应值。

| 语法   | add_header name value [always]; |
| ------ | ------------------------------- |
| 默认值 | —                               |
| 位置   | http、server、location...       |

Cache-Control作为响应头信息，可以设置如下值：

缓存响应指令：

```apl
Cache-control: must-revalidate
Cache-control: no-cache
Cache-control: no-store
Cache-control: no-transform
Cache-control: public
Cache-control: private
Cache-control: proxy-revalidate
Cache-Control: max-age=<seconds>
Cache-control: s-maxage=<seconds>
```

| 指令             | 说明                                           |
| ---------------- | ---------------------------------------------- |
| must-revalidate  | 可缓存但必须再向源服务器进行确认               |
| no-cache         | 缓存前必须确认其有效性                         |
| no-store         | 不缓存请求或响应的任何内容                     |
| no-transform     | 代理不可更改媒体类型                           |
| public           | 可向任意方提供响应的缓存                       |
| private          | 仅向特定用户返回响应                           |
| proxy-revalidate | 要求中间缓存服务器对缓存的响应有效性再进行确认 |
| max-age=<秒>     | 响应最大Age值                                  |
| s-maxage=<秒>    | 公共缓存服务器响应的最大Age值                  |

## 浏览器自带缓存演示

> ctrl+shift+del，清空浏览器缓存

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301161657904.png" alt="image-20230116165705811" style="zoom:67%;" />

第一次访问

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301161654631.png" alt="image-20230116165409518" style="zoom: 67%;" />

后续访问

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301161654556.png" alt="image-20230116165454450" style="zoom:67%;" />



## 静态资源添加缓存完整配置 ⭐

未开启缓存前

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204281836988.png" alt="image-20220428183607876" style="zoom: 80%;" />

```apl
# 资源路径
location / {
   root /usr/local/nginx/html;
   index index.html;
}
# 加上静态资源缓存
# 注意：资源路径不是/的情况下，配置有可能不生效，而且会出现资源无法访问的情况
# 嵌套在网页内的js、css、img也是会生效的比如vue页面
location ~* ^.+.(jpg|jpeg|gif|css|png|js|ico)$ {
   # 资源要给个根路径，不然访问不了404
   root html;
   expires 30d;
   add_header Pragma public;
   add_header Cache-Control "public";
}
```

访问图片：http://192.168.22.130:8089/g2.jpg  注意：单位是秒

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206231405759.png" alt="image-20220623140536613" style="zoom: 67%;" />



# 跨域

跨域问题在之前的单体架构开发中，其实是比较少见的问题，除非是需要接入第三方`SDK`时，才需要处理此问题。但随着现在前后端分离、分布式架构的流行，跨域问题也成为了每个Java开发必须要懂得解决的一个问题。[跨域问题分析和解决](https://mp.weixin.qq.com/s?__biz=MzI4Njc5NjM1NQ==&mid=2247540345&idx=2&sn=88303eec78028e75b016927dc20628a7&chksm=ebd56155dca2e843435e830e3a5fe42e75932a9414b67e4a3bbfb6bc8f6c1f58d81caeaba390&mpshare=1&scene=23&srcid=0604OEry4ZJVZWPXhaREaDHD&sharer_sharetime=1685854478207&sharer_shareid=29b8a04db1dbd975e3bf4e9f47e7ac67#rd)

## 跨域和同源策略

### 跨域问题产生原因

产生跨域问题的主要原因就在于**「同源策略」** ，为了保证用户信息安全，防止恶意网站窃取数据，同源策略是必须的，否则`cookie`可以共享。由于`http`无状态协议通常会借助`cookie`来实现有状态的信息记录，例如用户的身份/密码等，因此一旦`cookie`被共享，那么会导致用户的身份信息被盗取。同源策略主要是指三点相同，**「协议+域名+端口」** 相同的两个请求，则可以被看做是同源的，但如果其中任意一点存在不同，则代表是两个不同源的请求，同源策略会限制了不同源之间的资源交互。

### 同源策略

浏览器的同源策略：是一种约定，是浏览器最核心也是最基本的安全功能，如果浏览器少了同源策略，则浏览器的正常功能可能都会受到影响。`同源:  协议、域名(IP)、端口相同即为同源`

```sh
http://192.168.200.131/user/1
https://192.168.200.131/user/1
不

http://192.168.200.131/user/1
http://192.168.200.132/user/1
不

http://192.168.200.131/user/1
http://192.168.200.131:8080/user/1
不

http://www.nginx.com/user/1
http://www.nginx.org/user/1
不


http://192.168.200.131/user/1
http://192.168.200.131:8080/user/1
不

http://www.nginx.org:80/user/1
http://www.nginx.org/user/1
满足(因为端口默认就是80)
```

## 跨域问题重现

出现跨域问题会有什么效果?,接下来通过一个需求来给大家演示下：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204281823435.png" style="zoom:80%;" />（1）nginx的html目录下新建一个a.html

```html
<html>
  <head>
        <meta charset="utf-8">
        <title>跨域问题演示</title>
        <script src="jquery.js"></script>
        <script>
            $(function(){
                $("#btn").click(function(){
                  $.get('http://192.168.22.146:8080/getUser',function(data){
                        alert(JSON.stringify(data));
                  });
                });
            });
        </script>
  </head>
  <body>
        <input type="button" value="获取数据" id="btn"/>
  </body>
</html>
```

（2）在nginx.conf配置如下内容

```apl
server{
    listen  8080;
    server_name localhost;
    location /getUser{
        default_type application/json;
        return 200 '{"id":1,"name":"TOM","age":18}';
    }
}
server{
	listen 	80;
	server_name localhost;
	location /{
		root html;
		index index.html;
	}
}
```

(3)通过浏览器访问测试

![1588004913681](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204281823436.png)



## 解决方案

使用add_header指令，该指令可以用来添加一些头信息

此处用来解决跨域问题，需要添加两个头信息，一个是`Access-Control-Allow-Origin`,`Access-Control-Allow-Methods`。Access-Control-Allow-Origin: 直译过来是允许跨域访问的源地址信息，可以配置多个(多个用逗号分隔)，也可以使用`*`代表所有源。Access-Control-Allow-Methods:直译过来是允许跨域访问的请求方式，值可以为 GET POST PUT DELETE...,可以全部设置，也可以根据需要设置，多个用逗号分隔

###  最简单配置

```apl
# 一般设置在后端发起请求部分
location / {
    add_header Access-Control-Allow-Origin *;
    add_header Access-Control-Allow-Methods GET,POST,PUT,DELETE;
    default_type application/json;
    return 200 '{"id":1,"name":"TOM","age":18}';
}
```

### 详细配置

```apl
server {
    listen  8080;
    location / {
  		# 允许 所有头部 所有域 所有方法
  		add_header Access-Control-Allow-Origin *;
 		add_header Access-Control-Allow-Headers *;
  		add_header Access-Control-Allow-Methods *;
  		# OPTIONS 直接返回204
  		if ($request_method = 'OPTIONS') {
  			return 204;
		}
		default_type application/json;
   		return 200 '{"id":1,"name":"TOM","age":18}';
	}
}
```

### 更详细配置

```apl
location / {
    # 允许跨域的请求，可以自定义变量$http_origin，*表示所有
    add_header 'Access-Control-Allow-Origin' *;
    # 允许携带cookie请求
    add_header 'Access-Control-Allow-Credentials' 'true';
    # 允许跨域请求的方法：GET,POST,OPTIONS,PUT
    add_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS,PUT';
    # 允许请求时携带的头部信息，*表示所有
    add_header 'Access-Control-Allow-Headers' *;
    # 允许发送按段获取资源的请求
    add_header 'Access-Control-Expose-Headers' 'Content-Length,Content-Range';
    # 一定要有！！！否则Post请求无法进行跨域！
    # 在发送Post跨域请求前，会以Options方式发送预检请求，服务器接受时才会正式请求
    if ($request_method = 'OPTIONS') {
        add_header 'Access-Control-Max-Age' 1728000;
        add_header 'Content-Type' 'text/plain; charset=utf-8';
        add_header 'Content-Length' 0;
        # 对于Options方式的请求返回204，表示接受跨域请求
        return 204;
    }
    default_type application/json;
   	return 200 '{"id":1,"name":"TOM","age":18}';
}
```

### 超详细配置⭐

再贴一份完整配置（`*`号根据自己‘喜好’填写）：

```apl
server {
        listen       22222;
        server_name  localhost;
        location  / {
            if ($request_method = 'OPTIONS') {
                add_header Access-Control-Allow-Origin ':8080';
                add_header Access-Control-Allow-Headers '*';
                add_header Access-Control-Allow-Methods '*';
                add_header Access-Control-Allow-Credentials 'true';
                return 204;
            }
            if ($request_method != 'OPTIONS') {
                add_header Access-Control-Allow-Origin ':8080' always;
                add_header Access-Control-Allow-Credentials 'true';
            }
            proxy_pass  :59200; 
        }
    }
```

或者：

```apl
server {
        listen       22222;
        server_name  localhost;
        location  / {
            add_header Access-Control-Allow-Origin ':8080' always;
            add_header Access-Control-Allow-Headers '*';
            add_header Access-Control-Allow-Methods '*';
            add_header Access-Control-Allow-Credentials 'true';
            if ($request_method = 'OPTIONS') {
                return 204;
            }
            proxy_pass  :59200; 
        }
    }
```



## 响应头分析

**跨域主要涉及4个响应头：**

- `Access-Control-Allow-Origin` 用于设置允许跨域请求源地址 （预检请求和正式请求在跨域时候都会验证）
- `Access-Control-Allow-Headers` 跨域允许携带的特殊头信息字段 （只在预检请求验证）
- `Access-Control-Allow-Methods` 跨域允许的请求方法或者说HTTP动词 （只在预检请求验证）
- `Access-Control-Allow-Credentials` 是否允许跨域使用cookies，如果要跨域使用cookies，可以添加上此请求响应头，值设为true（设置或者不设置，都不会影响请求发送，只会影响在跨域时候是否要携带cookies，但是如果设置，预检请求和正式请求都需要设置）。不过不建议跨域使用（项目中用到过，不过不稳定，有些浏览器带不过去），除非必要，因为有很多方案可以代替。

网上很多文章都是告诉你直接Nginx添加这几个响应头信息就能解决跨域，当然大部分情况是能解决，但是我相信还是有很多情况，明明配置上了，也同样会报跨域问题。

什么是预检请求？：当发生跨域条件时候，览器先询问服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些HTTP动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的`XMLHttpRequest`请求，否则就报错。



# 防盗链

## 什么是资源盗链

> 资源盗链指的是此内容不在自己服务器上，而是通过技术手段，绕过别人的限制将别人的内容放到自己页面上最终展示给用户。以此来盗取大网站的空间和流量。简而言之就是**用别人的东西成就自己的网站**

首先了解一下何谓盗链：**「盗链即是指外部网站引入当前网站的资源对外展示」** ，来举个简单的例子理解：

> 好比壁纸网站`X`站、`Y`站，`X`站是一点点去购买版权、签约作者的方式，从而积累了海量的壁纸素材，但`Y`站由于资金等各方面的原因，就直接通过`<img src="X站/xxx.jpg" />`这种方式照搬了`X`站的所有壁纸资源，继而提供给用户下载。

那么如果我们自己是这个`X`站的`Boss`，心中必然不爽，那么此时又该如何屏蔽这类问题呢？「防盗链」登场了！

## Nginx 防盗链

> Nginx的防盗链机制实现，跟一个头部字段：`Referer`有关，该字段主要描述了当前请求是从哪儿发出的，那么在`Nginx`中就可获取该值，然后判断是否为本站的资源引用请求，如果不是则不允许访问。

> Nginx会通就过查看referer自动和valid_referers后面的内容进行匹配，如果匹配到了就将$invalid_referer变量置0，如果没有匹配到，则将\$invalid_referer变量置为1，匹配的过程中不区分大小写。

`Nginx`中存在一个配置项为`valid_referers`，正好可以满足前面的需求，语法如下：

- `valid_referers none | blocked | server_names | string ...;`

- - `none`：表示接受没有`Referer`字段的`HTTP`请求访问。
- `blocked`：表示允许`http://`或`https//`以外的请求访问。
- `server_names`：资源的白名单，这里可以指定允许访问的域名。
- `string`：可自定义字符串，支配通配符、正则表达式写法。

## 防盗链实现

简单了解语法后，接下来的实现如下：

```yaml
# 在动静分离的location中开启防盗链机制
location ~ .*\.(html|htm|gif|jpg|jpeg|bmp|png|ico|txt|js|css)$ {
    # 最后面的值在上线前可配置为允许的域名地址
    valid_referers blocked 192.168.22.146 www.baidu.com;
    # if后面一定要加上空格
    if ($invalid_referer) {
        # 可以配置成返回一张禁止盗取的图片
        # rewrite   ^/ http://xx.xx.com/NO.jpg;
        # 也可直接返回403，对应下面的error_page 403，这样能跳转错误页面
        return   403;
    }
    root  /usr/local/nginx/html;
    expires 7d;
}
```

访问测试：http://192.168.22.146/img/y2.jpg

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301161810975.png" alt="image-20230116181012883" style="zoom:67%;" />

> 如果在valid_referers后面再跟上none，那么即可正常访问图片

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301161813207.png" alt="image-20230116181304426" style="zoom:50%;" />

Referer的限制比较粗，比如随意加一个Referer，上面的方式是无法进行限制的。那么这个问题改如何解决？此处我们需要用到Nginx的第三方模块`ngx_http_accesskey_module`，第三方模块如何实现盗链，如果在Nginx中使用第三方模块的功能，这些我们在后面的Nginx的模块篇再进行详细的讲解。

> PS：防盗链机制也无法解决爬虫伪造`referers`信息的这种方式抓取数据。



# 全局变量和语法⭐

## 常用全局变量 ⭐

### 全局变量

> nginx的配置文件中可以使用的内置变量以美元符`$`开始，也有人叫全局变量。其中，部分预定义的变量的值是可以改变的。

| 变量                                                         | 说明                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| $args              | 变量中存放了请求URL中的请求参数。比如http://192.168.200.133/server?arg1=value1&args2=value2中的"arg1=value1&arg2=value2"，功能和$query_string一样 |                                                              |
| $http_user_agent                                             | 存储的是用户访问服务的代理信息(如果通过浏览器访问，记录的是浏览器的相关版本信息) |
| $host                                                        | 变量存储的是访问服务器的server_name值                        |
| $document_uri      | 变量存储的是当前访问地址的URI。比如http://192.168.200.133/server?id=10&name=zhangsan中的"/server"，功能和$uri一样 |                                                              |
| $document_root                                               | 变量存储的是当前请求对应location的root值，如果未设置，默认指向Nginx自带html目录所在位置 |
| $content_length                                              | 变量存储的是请求头中的Content-Length的值                     |
| $content_type                                                | 变量存储的是请求头中的Content-Type的值                       |
| $http_cookie                                                 | 变量存储的是客户端的cookie信息，可以通过add_header Set-Cookie 'cookieName=cookieValue'来添加cookie数据 |
| $limit_rate                                                  | 变量中存储的是Nginx服务器对网络连接速率的限制，也就是Nginx配置中对limit_rate指令设置的值，默认是0，不限制。 |
| $remote_addr                                                 | 变量中存储的是客户端的IP地址                                 |
| $remote_port                                                 | 变量中存储了客户端与服务端建立连接的端口号                   |
| $remote_user                                                 | 变量中存储了客户端的用户名，需要有认证模块才能获取           |
| $scheme                                                      | 变量中存储了访问协议                                         |
| $server_addr                                                 | 变量中存储了服务端的地址                                     |
| $server_name                                                 | 变量中存储了客户端请求到达的服务器的名称                     |
| $server_port                                                 | 变量中存储了客户端请求到达服务器的端口号                     |
| $server_protocol                                             | 变量中存储了客户端请求协议的版本，比如"HTTP/1.1"             |
| $request_body_file                                           | 变量中存储了发给后端服务器的本地文件资源的名称               |
| $request_method                                              | 变量中存储了客户端的请求方式，比如"GET","POST"等             |
| $request_filename                                            | 变量中存储了当前请求的资源文件的路径名                       |
| $request_uri                                                 | 变量中存储了当前请求的URI，并且携带请求参数，比如http://192.168.200.133/server?id=10&name=zhangsan中的"/server?id=10&name=zhangsan" |

### 全局变量使用示例

```yml
server {
    listen  8081;
    location /server {
  		set $name TOM;
  		set $age 18;
  		default_type text/plain;
  		return 200 $name=$age=$args;
	}
}
```

http://192.168.22.129:8081/server?username=qwe&gender=1

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204291450658.png" alt="image-20220429145059562" style="zoom:67%;" />

```yml
server {
    listen  8081;
    location /server {
  		default_type text/plain;
  		return 200 $args=$http_user_agent=$remote_addr;
	}
}
```

http://192.168.22.129:8081/server?username=qwe&gender=1

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204291455338.png" alt="image-20220429145546255" style="zoom:80%;" />

```yml
server {
    listen 80;
    server_name localhost;
    location /getVar {
        # default_type "text/html";
        return 200 "
               remote_addr: $remote_addr
               remote_port: $remote_port
               server_addr: $server_addr
               server_port: $server_port
               server_protocol: $server_protocol
               binary_remote_addr: $binary_remote_addr
               connection: $connection
               uri: $uri
               request_uri: $request_uri
               scheme: $scheme
               request_method: $request_method
               request_length: $request_length
               args: $args
               arg_pid: $arg_pid
               is_args: $is_args
               query_string: $query_string
               host: $host
               http_user_agent: $http_user_agent
               http_referer: $http_referer
               http_via: $http_via
               request_time: $request_time
               https: $https
               request_filename: $request_filename
               document_root: $document_root
               ";
     }
}
```

访问官网：http://192.168.22.130/getVar

由于 `Nginx` 中写了 `return` 方法，因此 `chrome` 浏览器会默认为我们下载一个文件，下面下载的文件内容

```sh
remote_addr: 192.168.22.1
remote_port: 13189
server_addr: 192.168.22.130
server_port: 80
server_protocol: HTTP/1.1
binary_remote_addr: 括
connection: 26
uri: /getVar
request_uri: /getVar
scheme: http
request_method: GET
request_length: 478
args: 
arg_pid: 
is_args: 
query_string: 
host: 192.168.22.130
http_user_agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36
http_referer: 
http_via: 
request_time: 0.000
https: 
request_filename: /usr/local/nginx/html/getVar
document_root: /usr/local/nginx/html
```



### 日志记录全局变量

上述参数还可以在日志文件中使用，这个就要用到前面我们介绍的`log_format`指令

```yml
# 定义在http块中，起名为main
log_format main '$remote_addr - $request - $status-$request_uri  $http_user_agent';
server {
    listen  8081;
    location /server {
         # 定义在server块中，main对应上面起的名字
         # 日志记录在logs下的access.log中
         access_log logs/access.log main;
         # 返回给页面看的，可以不写
  		default_type text/plain;
  		return 200 $args=$http_user_agent=$remote_addr;
	}
}
```

新日志的样子

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204291502302.png" alt="image-20220429150228214" style="zoom:80%;" />

## set指令

该指令用来设置一个新的变量。

| 语法   | set $variable value; |
| ------ | -------------------- |
| 默认值 | —                    |
| 位置   | server、location、if |

variable:变量的名称，该变量名称要用"$"作为变量的第一个字符，且不要与Nginx服务器预设的全局变量同名。

value:变量的值，可以是字符串、其他变量或者变量的组合等。

```yml
server {
    listen  8081;
    location /server {
  		set $name TOM;
  		set $age 18;
  		default_type text/plain;
  		return 200 $name=$age=$args;
	}
}
```



## if指令

该指令用来支持条件判断，并根据条件判断结果选择不同的Nginx配置。

| 语法   | if  (condition){...} |
| ------ | -------------------- |
| 默认值 | —                    |
| 位置   | server、location     |

condition为判定条件，可以支持以下写法：

### 条件是变量名

变量名。如果变量名对应的值为空字符串或"0"，if都判断为false,其他条件为true。

```
if ($param){
	
}
```

```yml
location /testif {
   set $username '';
   default_type text/plain;
   # 使用变量名进行判断，变量名为空或0为false，if后要有空格
   if ($username) {
      return 200 $username;
   }
   return 200 'param is empty';
}
```

### 条件是=和!=

使用"="和"!="比较变量和字符串是否相等，满足条件为true，不满足为false

```yml
if ($request_method = POST){
	return 405;
}
```

注意：此处和Java不太一样的地方是字符串`不需要添加引号,并且等号和不等号前后到需要加空格。

```yml
location /testif {
   default_type text/html;
   if ($args) {
      return 200 $args;
   }
   if ($request_method = GET) {
      # 注意：返回中文会乱码，需要在server模块加上charset utf-8;
      return 405 '页面访问为GET请求';
   }
   return 200 'param is empty';
}
```

### 正则

使用正则表达式对变量进行匹配，匹配成功返回true，否则返回false。变量与正则表达式之间使用"~","~*","!~","!~\*"

"~"代表匹配正则表达式过程中`区分大小写`，

"~\*"代表匹配正则表达式过程中`不区分大小写`

"!~"和"!~\*"刚好`和上面取相反值`，如果匹配上返回false,匹配不上返回true

```apl
if ($http_user_agent ~ MSIE){
	#$http_user_agent的值中是否包含MSIE字符串，如果包含返回true
}
```

注意：正则表达式字符串一般不需要加引号，但是如果字符串中包含"}"或者是";"等字符时，就需要把引号加上。

示例

```apl
location /testif {
  	default_type text/plain;
  	# 判断是否传入参数
	if ($http_user_agent ~* Chrome) {
		return 200 Chrome;
	}
  	return 200 error;
}
```

http://192.168.22.129:8081/testif

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204291525899.png" alt="image-20220429152535814" style="zoom:67%;" />

### 文件&目录是否存在

> 判断请求的文件是否存在使用"-f"和"!-f",
>
> 判断请求的目录是否存在使用"-d"和"!-d"
>
> 判断请求的目录或者文件是否存在使用"-e"和"!-e"
>
> 判断请求的文件是否可执行使用"-x"和"!-x"


```apl
if (-f $request_filename){
	#判断请求的文件是否存在
}
if (!-f $request_filename){
	#判断请求的文件是否不存在
}
```

如果访问文件不存在，生成页面，这样不太好，进行改进

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204291531679.png" alt="image-20220429153104588" style="zoom: 50%;" />

```apl
location / {
	root html;
	default_type text/html;
  	if (!-f $request_filename){
	   #判断请求的文件是否存在
	   return 200 '<h1>file not found</h1>';
    }	
}
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204291536072.png" alt="image-20220429153652986" style="zoom: 50%;" />

### 适配 PC 或移动设备

根据用户设备不同返回不同样式的站点，以前经常使用的是纯前端的自适应布局，但无论是复杂性和易用性上面还是不如分开编写的好，比如我们常见的淘宝、京东......这些大型网站就都没有采用自适应，而是用分开制作的方式，根据用户请求的 `user-agent` 来判断是返回 PC 还是 H5 站点。

首先在 `/usr/share/nginx/html` 文件夹下 `mkdir` 分别新建两个文件夹 `PC` 和 `mobile`，`vim` 编辑两个 `index.html` 随便写点内容。

```bash
cd /usr/share/nginx/html
mkdir pc mobile
cd pc
vim index.html   # 随便写点比如 hello pc!
cd ../mobile
vim index.html   # 随便写点比如 hello mobile!
```

然后和设置二级域名虚拟主机时候一样，去 `/etc/nginx/conf.d` 文件夹下新建一个配置文件 `fe.sherlocked93.club.conf` ：

```nginx
# /etc/nginx/conf.d/fe.sherlocked93.club.conf
server {
  listen 80;
	server_name fe.sherlocked93.club;

	location / {
		root  /usr/share/nginx/html/pc;
    if ($http_user_agent ~* '(Android|webOS|iPhone|iPod|BlackBerry)') {
        root /usr/share/nginx/html/mobile;
    }
		index index.html;
	}
}
```

配置基本没什么不一样的，主要多了一个 `if` 语句，然后使用 `$http_user_agent` 全局变量来判断用户请求的 `user-agent`，指向不同的 root 路径，返回对应站点。

在浏览器访问这个站点，然后 F12 中模拟使用手机访问：

<img src="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/4/29/171c4e97062c5124~tplv-t2oaga2asx-zoom-in-crop-mark:1304:0:0:0.awebp" alt="62haogU3DtwMRiZ" style="zoom:50%;" />

可以看到在模拟使用移动端访问的时候，Nginx 返回的站点变成了移动端对应的 html 了。

## break指令

该指令用于中断当前相同作用域中的其他Nginx配置。与该指令处于同一作用域的Nginx配置中，位于它前面的指令配置生效，位于后面的指令配置无效。并且break还有另外一个功能就是终止当前的匹配并把当前的URI在本location进行重定向访问处理。

| 语法   | break;               |
| ------ | -------------------- |
| 默认值 | —                    |
| 位置   | server、location、if |

例子:需要在html下创建testbreak目录，在该目录下创建index.html，最后执行会跳转到该页面

```sh
location /testbreak {
	default_type text/plain;
	set $username TOM;
	if ($args){
		set $username JERRY;
         break;
		set $username ROSE;
	}
	add_header username $username;
	return 200 $username;
}
```



## return指令 ⭐

> 返回http状态码 和 可选的第二个参数可以是重定向的URL，该指令用于完成对请求的处理，直接向客户端返回。在return后的所有Nginx配置都是无效的。

### return 基本语法

| 语法   | return code [text];          return code URL;          return URL; |
| ------ | ------------------------------------------------------------ |
| 默认值 | —                                                            |
| 位置   | server、location、if                                         |

> code:为返回给客户端的HTTP状态代理。可以返回的状态代码为0~999的任意HTTP状态代理
>
> text:为返回给客户端的响应体内容，支持变量的使用
>
> URL:为返回给客户端的URL地址

### return 小案例

```yml
location /testreturn {
    default_type text/html;
    charset utf-8;
    return 200 '<h1>成功</h1>';
}
```

http://192.168.22.130:8081/testreturn

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206231511116.png" alt="image-20220623151131972" style="zoom:50%;" />

### 直接返回状态码

```apl
location /code {
   default_type text/html;
   return 200; # 直接返回状态码
}
```

### 返回状态码 + 一段文本

```apl
location /codeText {
   default_type text/html;
   charset utf-8;
   return 200 "访问成功"; # 返回状态码 + 一段文本
}
```

### 返回状态码 + 重定向地址

```apl
location /codeUrl {
   return 302 https://www.baidu.com; # 返回状态码 + 重定向地址
}
```

### 返回重定向地址

```apl
location /url {
   return https://www.baidu.com ; # 返回重定向地址
}
```

# URL重写⭐

> 把匹配成功的URI替换成rewrite匹配的URI

该指令具有一个可选参数和两个必需参数。

- 第一个(必需)参数是请求URI必须匹配的正则表达式。
- 第二个参数是用于替换匹配URI的URI。
- 可选的第三个参数是可以停止进一步重写指令的处理或发送重定向(代码301或302)的标志

> Rewrite是Nginx服务器提供的一个重要基本功能，是Web服务器产品中几乎必备的功能。主要的作用是用来实现URL的重写。比如输入www.360buy.com会自动跳转到www.jd.com，这就是地址重写

> 注意:Nginx服务器的Rewrite功能的实现依赖于PCRE(正则表达式库)的支持，因此在编译安装Nginx服务器之前，需要安装PCRE库。Nginx使用的是ngx_http_rewrite_module模块来解析和处理Rewrite功能的相关配置。这个库默认就有，不用自己装

## rewrite的指令(重点)

### rewrite 语法

#### 指令详解

该指令通过正则表达式的使用来改变URI。可以同时存在一个或者多个指令，按照顺序依次对URL进行匹配和处理

| 语法   | rewrite regex replacement [flag]; |
| ------ | --------------------------------- |
| 默认值 | —                                 |
| 位置   | server、location、if              |

regex:用来匹配URI的正则表达式

> replacement:匹配成功后，用于替换URI中被截取内容的字符串。如果该字符串是以"http://"或者"https://"开头的，则不会继续向下对URI进行其他处理，而是直接返回重写后的URI给客户端。

会把匹配成功的url换成对应的url进行返回

```apl
location /rewrite {
    # 以/rewrite/url开头的任意网站都会跳转到https://www.baidu.com
	rewrite ^/rewrite/url\w*$ https://www.baidu.com;
	# 以/rewrite/test开头都能匹配到/test，$1表示对应匹配到括号里的内容
	# 注意：第二个变量表示第一个变量里括号的内容 .*表示任意字符比如/testaa/asd/aa都会匹配到/test
	rewrite ^/rewrite/(test).*$ /$1;
	rewrite ^/rewrite/(demo).*$ /$1;
}
location /test{
	default_type text/plain;
	return 200 test_success;
}
location /demo{
	default_type text/plain;
	return 200 demo_success;
}
```

进行访问

http://192.168.22.129:8081/rewrite/urlabc  ：会自动跳转到百度

http://192.168.22.129:8081/rewrite/testsad  ：会自动跳转到http://192.168.22.129:8081/test

http://192.168.22.129:8081/rewrite/demoeqa ：会自动跳转到http://192.168.22.129:8081/demo

#### 配置项

flag:用来设置rewrite对URI的处理行为，可选值有如下：

##### last(重点)

> last重写后的 URL发起新请求，再次进入 server段，重试 location的中的匹配，为重写后的URI提供了转入到其他location块的机会。

```apl
location /rewrite {
	rewrite ^/rewrite/(test)\w*$ /$1 last;
	rewrite ^/rewrite/(demo)\w*$ /$1 last;
}
location /test{
	default_type text/plain;
	return 200 test_success;
}
location /demo{
	default_type text/plain;
	return 200 demo_success;
}
```

访问 `http://192.168.200.133:8081/rewrite/testabc`,能正确访问/test

![1589475653252](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282207314.png)

##### break

> 直接使用重写后的 `URL` ，不再匹配其它 `location` 中语句；

```apl
location /rewrite {
    #/test   /usr/local/nginx/html/test/index.html
	rewrite ^/rewrite/(test)\w*$ /$1 break;
	rewrite ^/rewrite/(demo)\w*$ /$1 break;
}
location /test{
	default_type text/plain;
	return 200 test_success;
}
location /demo{
	default_type text/plain;
	return 200 demo_success;
}
```

访问 `http://192.168.200.133:8081/rewrite/demoabc`,页面报404错误

![1589475732042](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282207316.png)

##### redirct 重定向

> redirect：将重写后的URI返回给客户端，状态码为302，指明是临时重定向URI,主要用在replacement变量不是以"http://"或者"https://"开头的情况

```apl
location rewrite {
	rewrite ^/rewrite/(test)\w*$ /$1 redirect;
	rewrite ^/rewrite/(demo)\w*$ /$1 redirect;
}
location /test{
	default_type text/plain;
	return 200 test_success;
}
location /demo{
	default_type text/plain;
	return 200 demo_success;
}
```

访问`http://192.168.200.133:8081/rewrite/testabc`请求会被临时重定向，浏览器地址也会发生改变

##### permanent 永久重定向

> permanent：将重写后的URI返回给客户端，状态码为301，指明是永久重定向URI,主要用在replacement变量不是以"http://"或者"https://"开头的情况。

```apl
location rewrite {
	rewrite ^/rewrite/(test)\w*$ /$1 permanent;
	rewrite ^/rewrite/(demo)\w*$ /$1 permanent;
}
location /test{
	default_type text/plain;
	return 200 test_success;
}
location /demo{
	default_type text/plain;
	return 200 demo_success;
}
```

访问`http://192.168.200.133:8081/rewrite/testabc`请求会被永久重定向，`浏览器地址也会发生改变`



### rewrite_log指令

> 开启后，URL重写的相关日志将以notice级别输出到error_log指令配置的日志文件汇总。

| 语法   | rewrite_log on\|off;       |
| ------ | -------------------------- |
| 默认值 | rewrite_log off;           |
| 位置   | http、server、location、if |

```apl
location /rewrite {
	rewrite_log on;
	error_log  logs/error.log notice;
     #以/rewrite/url开头的任意网站都会跳转到https://www.baidu.com
	rewrite ^/rewrite/url\w*$ https://www.baidu.com;
}
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204291623245.png" alt="image-20220429162324148" style="zoom:80%;" />

## 域名跳转

### 问题分析

先来看一个效果，如果我们想访问京东网站，大家都知道我们可以输入`www.jd.com`,但是同样的我们也可以输入`www.360buy.com`同样也都能访问到京东网站。这个其实是因为京东刚开始的时候域名就是www.360buy.com，后面由于各种原因把自己的域名换成了www.jd.com,

虽然说域名变量，但是对于以前只记住了www.360buy.com的用户来说，我们如何把这部分用户也迁移到我们新域名的访问上来，针对于这个问题，我们就可以使用Nginx中Rewrite的域名跳转来解决。

目的：无论访问这三个域名中的哪一个域名，最终都会跳转到www.itcast.cn这个域名

### 环境准备

准备三个域名

```apl
vim /etc/hosts
```

```apl
127.0.0.1   www.itcast.cn
127.0.0.1   www.itheima.cn
127.0.0.1   www.itheima.com
```

通过Nginx实现访问www.itcast.cn

```apl
server {
	listen 80;
	server_name www.itcast.cn;
	location / {
		default_type text/html;
		return 200 '<h1>welcome to itcast</h1>';
	}
}
```

### 基础实现

通过Rewrite完成将www.ithema.com和www.itheima.cn的请求跳转到www.itcast.com

```apl
server {
	listen 80;
	server_name www.itheima.com www.itheima.cn;
	#以/开头都会跳转到http://www.itcast.cn
	rewrite ^/ http://www.itcast.cn;
}
```

### 进阶实现

问题描述:如何在域名跳转的过程中携带请求的URI？修改配置信息

```apl
server {
	listen 80;
	server_name www.itheima.com www.itheima.cn;
	# (.*)能匹配到/getUser等指令
	rewrite ^(.*) http://www.itcast.cn$1；
}
```

### 完整实现

```apl
server {
    listen 80;
    server_name www.itcast.cn;
    location / {
        default_type text/html;
        return 200 '<h1>welcome to itcast</h1>';
    }
}

server {
    listen 80;
    server_name www.itheima.com www.itheima.cn;
    # (.*)能匹配到/getUser等指令
    rewrite ^(.*) http://www.itcast.cn$1；
}
```

www.itheima.cn/getUser跳转到http://www.itcast.cn/getUser

www.itheima.cn/getUser/getOne跳转到http://www.itcast.cn/getUser/getOne



## 域名镜像

### 需求描述

> 镜像网站指定是将一个完全相同的网站分别放置到几台服务器上，并分别使用独立的URL进行访问。其中一台服务器上的网站叫主站，其他的为镜像网站。镜像网站和主站没有太大的区别，可以把镜像网站理解为主站的一个备份节点。可以通过镜像网站提供网站在不同地区的响应速度。镜像网站可以平衡网站的流量负载、可以解决网络宽带限制、封锁等。

![1589560433192](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282207319.png)

而我们所说的域名镜像和网站镜像比较类似，上述案例中，将www.itheima.com和 www.itheima.cn都能跳转到www.itcast.cn，那么www.itcast.cn我们就可以把它起名叫主域名，其他两个就是我们所说的镜像域名，当然如果我们不想把整个网站做镜像，只想为其中某一个子目录下的资源做镜像，我们可以在location块中配置rewrite功能，比如:

### 完整实现

我只想要user模块进行跳转，其他模块不去跳转

```apl
server {
    listen          80;
    server_name     www.itheima.cn www.itheima.com;
    location /user {
         # 以/user开头的所有请求，都要跳转到http://www.itcast.cn
    	rewrite ^/user(.*)$ http://www.itcast.cn$1;
    }
    # 访问emp则不会进行域名跳转
    location /emp{
        default_type text/html;
        return 200 '<h1>emp_success</h1>';
    }
}
```



## 独立域名

> 一个完整的项目包含多个模块，比如购物网站有商品搜索模块、商品详情模块和购物车模块等，那么我们如何为每一个模块设置独立的域名。

### 需求描述

网络上的域名ip不一致，可以都使用80，而目前使用的是本机配置的域名，则要用端口号区分

```apl
http://search.itcast.com:81   # 访问商品搜索模块
http://item.itcast.com:82	  # 访问商品详情模块
http://cart.itcast.com:83	  # 访问商品购物车模块
```

```apl
server{
	listen 81;
	server_name search.itcast.com;
	# 最终访问:http://www.itcast.cn/search/xxx
	rewrite ^(.*) http://www.itcast.cn/search$1;
}
server{
	listen 82;
	server_name item.itcast.com;
	rewrite ^(.*) http://www.itcast.cn/item$1;
}
server{
	listen 83;
	server_name cart.itcast.com;
	rewrite ^(.*) http://www.itcast.cn/cart$1;
}
```



## 目录自动添加"/"(新版本不考虑)

### 问题描述

通过一个例子来演示下问题:

```apl
server {
	listen	8082;
	server_name localhost;
	location /heima {
		root html;
		index index.html;
	}
}
```

通过`http://192.168.200.133:8082/heima`和通过`http://192.168.200.133:8082/heima/`访问的区别？

如果不加斜杠，Nginx服务器内部会自动做一个301的重定向，重定向的地址会有一个指令叫server_name_in_redirect on|off;来决定重定向的地址：

> 如果该指令为on，重定向的地址为:  http://server_name:8082/目录名/;    :8082/heima/
> 如果该指令为off，重定向的地址为:  http://原URL中的域名:8082/目录名/; http://192.168.200.133:8082/heima/

所以就拿刚才的地址来说，http://192.168.200.133:8082/heima如果不加斜杠，那么按照上述规则，如果指令server_name_in_redirect为on，则301重定向地址变为 :8082/heima/,如果为off，则301重定向地址变为http://192.168.200.133:8082/heima/。后面这个是正常的，前面地址就有问题。

> 注意server_name_in_redirect指令在Nginx的0.8.48版本之前默认都是on，之后改成了off,所以现在我们这个版本不需要考虑这个问题，但是如果是0.8.48以前的版本并且server_name_in_redirect设置为on，我们如何通过rewrite来解决这个问题？

### 解决方案

我们可以使用rewrite功能为末尾没有斜杠的URL自动添加一个斜杠

```apl
server {
	listen	80;
	server_name localhost;
	server_name_in_redirect on;
	location /heima {
		if (-d $request_filename){
			rewrite ^/(.*)([^/])$ http://$host/$1$2/ permanent;
		}
	}
}
```



## 合并目录

> 搜索引擎优化(SEO)是一种利用搜索引擎的搜索规则来提高目的网站在有关搜索引擎内排名的方式。我们在创建自己的站点时，可以通过很多中方式来有效的提供搜索引擎优化的程度。

> 其中有一项就包含URL的目录层级一般不要超过三层，否则的话不利于搜索引擎的搜索也给客户端的输入带来了负担，但是将所有的文件放在一个目录下又会导致文件资源管理混乱并且访问文件的速度也会随着文件增多而慢下来，这两个问题是相互矛盾的，那么使用rewrite如何解决上述问题?

举例，网站中有一个资源文件的访问路径时 /server/11/22/33/44/20.html,也就是说20.html存在于第5级目录下，如果想要访问该资源文件，客户端的URL地址就要写成 `http://192.168.200.133/server/11/22/33/44/20.html`,

```apl
server {
	listen 8083;
	server_name localhost;
	location /server{
		root html;
	}
}
```

但是这个是非常不利于SEO搜索引擎优化的，同时客户端也不好记.使用rewrite我们可以进行如下配置:

```apl
server {
	listen 8083;
	server_name localhost;
	location /server{
	     # $表示结束标志，之后要空格写
		rewrite ^/server-([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)\.html$ 
		        /server/$1/$2/$3/$4/$5.html last;
	}
}
```

> 这样，客户端只需要输入http://www.web.name/server-11-22-33-44-20.html就可以访问到20.html页面了。这里也充分利用了rewrite指令支持正则表达式的特性。



## 防盗链优化

> 防盗链之前我们已经介绍过了相关的知识，在rewrite中的防盗链和之前将的原理其实都是一样的，只不过通过rewrite可以将防盗链的功能进行完善下，当出现防盗链的情况，我们可以使用rewrite将请求转发到自定义的一张图片和页面，给用户比较好的提示信息。下面我们就通过根据文件类型实现防盗链的一个配置实例:

```apl
location /images {
    root html;
    # 不满足如下三种情况，就是盗链
    valid_referers none blocked www.baidu.com;
    if ($invalid_referer){
        #return 403;
        rewrite ^/   /images/forbidden.png break;
    }
}
```



# 反向代理(重点)

## 正向代理和反向代理⭐

反向代理（Reverse Proxy）对应的是正向代理（Forward Proxy），他们的区别：

> **正向代理：** 一般的访问流程是客户端直接向目标服务器发送请求并获取内容，使用正向代理后，客户端改为向代理服务器发送请求，并指定目标服务器（原始服务器），然后由代理服务器和原始服务器通信，转交请求并获得的内容，再返回给客户端。**正向代理隐藏了真实的客户端，为客户端收发请求，使真实客户端对服务器不可见**；

> 举个具体的例子 🌰，你的浏览器无法直接访问谷哥，这时候可以通过一个代理服务器来帮助你访问谷哥，那么这个服务器就叫正向代理。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205221147374.png" alt="image-20220522114748286" style="zoom:67%;" />

> **反向代理：** 与一般访问流程相比，使用反向代理后，直接收到请求的服务器是代理服务器，然后将请求转发给内部网络上真正进行处理的服务器，得到的结果返回给客户端。反向代理**隐藏了真实的服务器**，为服务器收发请求，使真实服务器对客户端不可见。一般在处理跨域请求的时候比较常用。基本上所有的大型网站都设置了反向代理

> 举个具体的例子 🌰，去饭店吃饭，可以点川菜、粤菜、江浙菜，饭店也分别有三个菜系的厨师 👨‍🍳，但是你作为顾客不用管哪个厨师给你做的菜，只用点菜即可，小二将你菜单中的菜分配给不同的厨师来具体处理，那么这个小二就是反向代理服务器。

> 简单的说，一般给客户端做代理的都是正向代理，给服务器做代理的就是反向代理。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205221148020.png" alt="image-20220522114804931" style="zoom:67%;" />

## 正向代理实现

> 我们先来通过一个小案例演示下Nginx正向代理的简单应用。

### 需求描述

需要准备3台服务器

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282207317.png" style="zoom: 80%;" />

### 具体实现

(1)服务端的设置

```apl
http {
    log_format main 'client send request=>clientIp=$remote_addr serverIp=>$host';
	server{
		listen 80;
		server_name	localhost;
		access_log logs/access.log main;
		location {
			root html;
			index index.html index.htm;
		}
	}
}
```

(2)使用客户端访问服务端，打开日志查看结果

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282207333.png" alt="1589729000713" style="zoom:67%;" />

(3)代理服务器设置：

```apl
server {
        listen  82;
        resolver 8.8.8.8;
        location /{
                proxy_pass http://$host$request_uri;
        }
    }
```

(4)查看代理服务器的IP(192.168.200.146)和Nginx配置监听的端口(82)

(5)在客户端配置代理服务器

![](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282207339.png)

(6)设置完成后，再次通过浏览器访问服务端

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282207812.png" alt="1589729479920" style="zoom:67%;" />

通过对比，上下两次的日志记录，会发现虽然我们是客户端访问服务端，但是如何使用了代理，那么服务端能看到的只是代理发送过去的请求，这样的化，就使用Nginx实现了正向代理的设置。但是Nginx正向代理，在实际的应用中不是特别多，所以我们简单了解下

## 反向代理语法

Nginx反向代理模块的指令是由`ngx_http_proxy_module`模块进行解析，该模块在安装Nginx的时候已经自己加装到Nginx中了，接下来我们把反向代理中的常用指令一一介绍下：

### proxy_pass(被代理地址) ⭐

该指令用来设置被代理服务器地，可以是主机名称、IP地址加端口号形式。

| 语法   | proxy_pass URL; |
| ------ | --------------- |
| 默认值 | —               |
| 位置   | location        |

> 1. `URL` 必须以 `http` 或 `https` 开头；
> 2. `URL` 中可以携带变量；
> 3. `URL` 中是否带 `URI` ，会直接影响发往上游请求的 `URL`

```apl
server {
	listen 80;
	server_name localhost;
	location /{
	    # 被代理服务器的地址 
		proxy_pass http://192.168.200.146;
		#proxy_pass http://192.168.200.146/;
	}
}
# 当客户端访问 /index.html,效果是一样的
# 也就是location配置的路径不起作用了
server{
	listen 80;
	server_name localhost;
	location /server{
		#proxy_pass http://192.168.200.146;
		proxy_pass http://192.168.200.146/;
	}
}
```

> 当客户端访问 /server/index.html
> 这个时候，第一个没加/proxy_pass就变成了/server/index.html
> 第二个加上/后proxy_pass就变成了/index.html效果就不一样了。

### proxy_set_header(更改请求头)

该指令可以更改Nginx服务器接收到的客户端请求的请求头信息，然后将新的请求头发送给代理的服务器

| 语法   | proxy_set_header field value;                                |
| ------ | ------------------------------------------------------------ |
| 默认值 | proxy_set_header Host $proxy_host;<br/>proxy_set_header Connection close; |
| 位置   | http、server、location                                       |

需要注意的是，如果想要看到结果，必须在被代理的服务器上来获取添加的头信息。

被代理服务器： [192.168.200.146]

```apl
server {
    listen  8080;
    server_name localhost;
    default_type text/plain;
    return 200 $http_username;
}
```

代理服务器: [192.168.200.133]

```apl
server {
   listen  8080;
   server_name localhost;
   location /server {
        proxy_pass http://192.168.200.146:8080/;
        proxy_set_header username TOM;
   }
}
```

访问测试：192.168.200.133:8080/server/  即可看到页面显示TOM

### proxy_redirect

> 该指令是用来重置头信息中的"Location"和"Refresh"的值。避免直接显示被代理服务器的IP地址

| 语法   | proxy_redirect redirect replacement;<br/>proxy_redirect default;<br/>proxy_redirect off; |
| ------ | ------------------------------------------------------------ |
| 默认值 | proxy_redirect default;                                      |
| 位置   | http、server、location                                       |

#### 指令选项

proxy_redirect redirect replacement;

```apl
redirect:目标,Location的值
replacement:要替换的值
```

proxy_redirect default;

```apl
default;
将location块的uri变量作为replacement,
将proxy_pass变量作为redirect进行替换
```

proxy_redirect off;

```apl
关闭proxy_redirect的功能
```

#### 示例

为什么要用该指令? 首先定义一个server

```apl
server {
    listen  8082;
    server_name localhost;
    location / {
        if (!-f $request_filename){
          # 请求的资源如果不存在，那么他就会进行跳转到该路径上，避免显示404
            return 302 http://192.168.1.107:8085/girl.jpg;
        }
    }
}
```

访问测试：http://192.168.22.130:8082/ab.jpg

```apl
curl -I  http://192.168.22.130:8082/girl1.jpg
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206211549419.png" alt="image-20220621154908298" style="zoom:67%;" />

显示：注意上面路径已经变成了：http://192.168.1.107:8085/girl.jpg，如何修改这个路径呢

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206211520020.png" alt="image-20220621152005750" style="zoom: 50%;" />

再设置一个server，进行反向代理

```apl
server {
    listen  8085;
    server_name localhost;
    location / {
        proxy_pass http://192.168.22.130:8082;
        proxy_redirect http://192.168.1.107:8085/girl.jpg http://192.168.22.130:8085/girl.jpg;
    }
}
```

http://192.168.22.130:8085/girl1.jpg会转换成http://192.168.22.130:8085/girl.jpg

### proxy_pass 注意事项 ⭐

> 编写proxy_pass的时候，后面的值要不要加"/"? 如下

```apl
proxy_pass http://192.168.100.33:8081

proxy_pass http://192.168.100.33:8081/
```

这两种用法的区别就是带 `/` 和不带 `/` ，在配置代理时它们的区别可大了：

- 不带 `/` 意味着 `Nginx` 不会修改用户 `URL` ，而是直接透传给上游的应用服务器；
- 带 `/` 意味着 `Nginx` 会修改用户 `URL` ，修改方法是将 `location` 后的 `URL` 从用户 `URL` 中删除

不带 `/` 的用法

```apl
location /bbs/{
    proxy_pass http://127.0.0.1:8080;
}
```

1. 用户请求 `URL` ： `/bbs/abc/test.html`
2. 请求到达 `Nginx` 的 `URL` ： `/bbs/abc/test.html`
3. 请求到达上游应用服务器的 `URL` ： `/bbs/abc/test.html`

带 `/` 的用法

```apl
location /bbs/{
    proxy_pass http://127.0.0.1:8080/;
}
```

1. 用户请求 `URL` ： `/bbs/abc/test.html`
2. 请求到达 `Nginx` 的 `URL` ： `/bbs/abc/test.html`
3. 请求到达上游应用服务器的 `URL` ： `/abc/test.html`

并没有拼接上 `/bbs` ，这点和 `root` 与 `alias` 之间的区别是保持一致的

## 反向代理实战 ⭐

### 需求描述

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282207821.png" alt="1581883378672" style="zoom:67%;" />

服务器1,2,3存在两种情况

> 第一种情况: 三台服务器的内容不一样。那么代理服务器要定向的访问服务器
> 第二种情况: 三台服务器的内容是一样。那么代理服务器要**负载均衡**的访问服务器

以下演示三个服务器内容不同的情况

如果服务器1、服务器2和服务器3的内容不一样，那我们可以根据用户请求来分发到不同的服务器。

### 代理服务器

```apl
server {
    listen    9001;
    server_name     localhost;
    default_type text/html;
    return 200 '<h1>192.168.22.130:9001</h1>';
}

server {
    listen    9002;
    server_name     localhost;
    default_type text/html;
    return 200 '<h1>192.168.22.130:9002</h1>';
}

server {
    listen    9003;
    server_name     localhost;
    default_type text/html;
    return 200 '<h1>192.168.22.130:9003</h1>';
}
```

进行访问：都能访问成功

http://192.168.22.130:9001/

http://192.168.22.130:9002/

http://192.168.22.130:9003/

### 配置代理

```apl
server {
     listen           8082;
     server_name      localhost;
     location /server1 {
         # 末尾加/，这样/server1就不会在访问时代理添加到服务器上了
         # 原来http://192.168.22.130:9001/
         proxy_pass http://192.168.22.130:9001/;
     }
     location /server2 {
         proxy_pass http://192.168.22.130:9002/;
     }
     location /server3 {
         proxy_pass http://192.168.22.130:9003/;
     }
}
```

### 访问测试

http://192.168.22.130:8082/server1会代理到http://192.168.22.130:9001

http://192.168.22.130:8082/server2会代理到http://192.168.22.130:9002

http://192.168.22.130:8082/server3会代理到http://192.168.22.130:9003

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206211618079.png" alt="image-20220621161856953" style="zoom:67%;" />

## 缓冲区+反向代理优化

### 为什么需要缓冲区

> 先来思考一个问题，接入Nginx的项目一般请求流程为：“客户端→Nginx→服务端”，在这个过程中存在两个连接：“客户端→Nginx、Nginx→服务端”，那么两个不同的连接速度不一致，就会影响用户的体验（比如浏览器的加载速度跟不上服务端的响应速度）。

> 其实也就类似电脑的内存跟不上CPU速度，所以对于用户造成的体验感极差，因此在CPU设计时都会加入三级高速缓冲区，用于缓解CPU和内存速率不一致的矛盾。在Nginx也同样存在缓冲区的机制，主要目的就在于：**「用来解决两个连接之间速度不匹配造成的问题」** ，有了缓冲后，Nginx代理可暂存后端的响应，然后按需供给数据给客户端。先来看看一些关于缓冲区的配置项：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282207828.png" alt="1581879638569" style="zoom:67%;" />

### Proxy Buffer相关指令

> proxy_buffering :该指令用来开启或者关闭代理服务器的缓冲区；

| 语法   | proxy_buffering on\|off; |
| ------ | ------------------------ |
| 默认值 | proxy_buffering on;      |
| 位置   | http、server、location   |

> proxy_buffers:该指令用来指定单个连接从代理服务器读取响应的缓存区的个数和大小。

| 语法   | proxy_buffers number size;                |
| ------ | ----------------------------------------- |
| 默认值 | proxy_buffers 8 4k \| 8K;(与系统平台有关) |
| 位置   | http、server、location                    |

number:缓冲区的个数

size:每个缓冲区的大小，缓冲区的总大小就是number*size

> proxy_buffer_size:该指令用来设置从被代理服务器获取的第一部分响应数据的大小。保持与proxy_buffers中的size一致即可，当然也可以更小。

| 语法   | proxy_buffer_size size;                     |
| ------ | ------------------------------------------- |
| 默认值 | proxy_buffer_size 4k \| 8k;(与系统平台有关) |
| 位置   | http、server、location                      |

> proxy_busy_buffers_size：该指令用来限制同时处于BUSY状态的缓冲总大小。

| 语法   | proxy_busy_buffers_size size;    |
| ------ | -------------------------------- |
| 默认值 | proxy_busy_buffers_size 8k\|16K; |
| 位置   | http、server、location           |

> proxy_temp_path:当缓冲区存满后，仍未被Nginx服务器完全接受，响应数据就会被临时存放在磁盘文件上，该指令设置文件路径

| 语法   | proxy_temp_path  path;      |
| ------ | --------------------------- |
| 默认值 | proxy_temp_path proxy_temp; |
| 位置   | http、server、location      |

注意path最多设置三层。

> proxy_temp_file_write_size：该指令用来设置磁盘上缓冲文件的大小。

| 语法   | proxy_temp_file_write_size size;    |
| ------ | ----------------------------------- |
| 默认值 | proxy_temp_file_write_size 8K\|16K; |
| 位置   | http、server、location              |

### 通用网站的配置

直接配置在http块上就行

```apl
http{
    proxy_connect_timeout 10;
    proxy_read_timeout 120;
    proxy_send_timeout 10;
    proxy_buffering on;
    client_body_buffer_size 512k;
    proxy_buffers 4 64k;
    proxy_buffer_size 16k;
    proxy_busy_buffers_size 128k;
    proxy_temp_file_write_size 128k;
    proxy_temp_path /soft/nginx/temp_buffer;
}
```

> 上述的缓冲区参数，是基于每个请求分配的空间，而并不是所有请求的共享空间。当然，具体的参数值还需要根据业务去决定，要综合考虑机器的内存以及每个请求的平均数据大小。最后提一嘴：使用缓冲也可以减少即时传输带来的带宽消耗。



# SSL 安全

## https 安全概述

### 什么是安全隔离?

> 通过代理分开了客户端到应用程序服务器端的连接，实现了安全措施。在反向代理之前设置防火墙，仅留一个入口供代理服务器访问。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282207827.png" alt="1589908851340" style="zoom: 67%;" />

### 如何使用SSL对流量进行加密

> 翻译成大家能熟悉的说法就是将我们常用的http请求转变成https请求，那么这两个之间的区别简单的来说两个都是HTTP协议，只不过https是身披SSL外壳的http.

> HTTPS是一种通过计算机网络进行安全通信的传输协议。它经由HTTP进行通信，利用SSL/TLS建立全通信，加密数据包，确保数据的安全性。

SSL(Secure Sockets Layer)安全套接层

TLS(Transport Layer Security)传输层安全

上述这两个是为网络通信提供安全及数据完整性的一种安全协议，TLS和SSL在传输层和应用层对网络连接进行加密。

总结来说为什么要使用https:

> http协议是明文传输数据，存在安全问题，而https是加密传输，相当于http+ssl，`并且可以防止流量劫持`

Nginx要想使用SSL，需要满足一个条件即需要添加一个模块`--with-http_ssl_module`,而该模块在编译的过程中又需要OpenSSL的支持，这个我们之前已经准备好了。

## 添加SSL 模块⭐

完成 `--with-http_ssl_module`模块的增量添加

```sh
# 进入nginx刚解压的目录
cd  /root/nginx-1.21.6
# 通过nginx -V，查看之前安装的模块，带上安装
nginx -V
# 安装ssl
yum -y install openssl openssl-devel make zlib zlib-devel gcc gcc-c++ libtool  pcre pcre-devel
# 添加模块，要把之前的 --with-http_gzip_static_module 加上
./configure --with-http_gzip_static_module --with-http_ssl_module 
# 进行编译
make
```

```sh
# 进入原来安装好的nginx
cd /usr/local/nginx/sbin/nginx
# 进行备份
mv /usr/local/nginx/sbin/nginx nginxold
# 将objs下面的nginx移动到/usr/local/nginx/sbin下
cp objs/nginx /usr/local/nginx/sbin
# 在源码目录下执行make upgrade进行升级，这个可以实现不停机添加新模块的功能
make upgrade
```

```sh
# 查看是否安装成功
nginx -V
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301171139880.png" alt="image-20230117113826975" style="zoom:67%;" />



## Nginx的SSL指令

因为刚才我们介绍过该模块的指令都是通过ngx_http_ssl_module模块来解析的。

### ssl

ssl:该指令用来在指定的服务器开启HTTPS,可以使用 listen 443 ssl,后面这种方式更通用些。

| 语法   | ssl on \| off; |
| ------ | -------------- |
| 默认值 | ssl off;       |
| 位置   | http、server   |

```apl
server{
	listen 443 ssl;
}
```

### ssl_certificate

ssl_certificate:为当前这个虚拟主机指定一个带有PEM格式证书的证书。

| 语法   | ssl_certificate file; |
| ------ | --------------------- |
| 默认值 | —                     |
| 位置   | http、server          |

### ssl_certificate_key

ssl_certificate_key:该指令用来指定PEM secret key文件的路径

| 语法   | ssl_ceritificate_key file; |
| ------ | -------------------------- |
| 默认值 | —                          |
| 位置   | http、server               |

### ssl_session_cache

ssl_session_cache:该指令用来配置用于SSL会话的缓存

| 语法   | ssl_sesion_cache off\|none\|[builtin[:size]] [shared:name:size] |
| ------ | ------------------------------------------------------------ |
| 默认值 | ssl_session_cache none;                                      |
| 位置   | http、server                                                 |

off:禁用会话缓存，客户端不得重复使用会话

none:禁止使用会话缓存，客户端可以重复使用，但是并没有在缓存中存储会话参数

builtin:内置OpenSSL缓存，仅在一个工作进程中使用。

shared:所有工作进程之间共享缓存，缓存的相关信息用name和size来指定

### ssl_session_timeout

ssl_session_timeout：开启SSL会话功能后，设置客户端能够反复使用储存在缓存中的会话参数时间。

| 语法   | ssl_session_timeout time; |
| ------ | ------------------------- |
| 默认值 | ssl_session_timeout 5m;   |
| 位置   | http、server              |

### ssl_ciphers

ssl_ciphers:指出允许的密码，密码指定为OpenSSL支持的格式

| 语法   | ssl_ciphers ciphers;          |
| ------ | ----------------------------- |
| 默认值 | ssl_ciphers HIGH:!aNULL:!MD5; |
| 位置   | http、server                  |

可以使用`openssl ciphers`查看openssl支持的格式。

### ssl_prefer_server_ciphers

ssl_prefer_server_ciphers：该指令指定是否服务器密码优先客户端密码

| 语法   | ssl_perfer_server_ciphers on\|off; |
| ------ | ---------------------------------- |
| 默认值 | ssl_perfer_server_ciphers off;     |
| 位置   | http、server                       |

## SSL 证书

> 之前我们使用的是自签名的SSL证书，对于浏览器来说是无效的。使用权威机构颁发的SSL证书浏览器才会认为是有效的，这里给大家推荐两种申请免费SSL证书的方法，一种是从阿里云申请，另一种是从FreeSSL申请。

### 阿里云证书

阿里云上可以申请的免费证书目前只有支持单个域名的DV级SSL证书。比如说你有`blog.macrozheng.com`和`api.macrozheng.com`两个二级域名需要使用HTTPS，就需要申请两个SSL证书。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.30/202207111611477.png" alt="image-20220711161143356" style="zoom:67%;" />

申请成功后点击下载Nginx证书即可；

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.30/202207111611641.png" alt="image-20220711161158518" style="zoom:50%;" />

下载完成后解压会有下面两个文件；

```properties
blog.macrozheng.com.key # 证书私钥文件
blog.macrozheng.com.pem # 证书文件
```

拷贝证书文件到Nginx的指定目录下，然后修改配置文件`blog.conf`，只要修改证书配置路径即可，修改完成后重启Nginx；

```properties
#SSL配置
ssl_certificate      /usr/share/nginx/html/ssl/blog/blog.macrozheng.com.pem; # 配置证书
ssl_certificate_key  /usr/share/nginx/html/ssl/blog/blog.macrozheng.com.key; # 配置证书私钥
```

再次通过HTTPS访问`blog.macrozheng.com`这个域名，发现证书已经有效了，连接也是安全的了。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.30/202207111612705.png" alt="image-20220711161225480" style="zoom:50%;" />

### FreeSSL证书

如果你有使用通配符域名的需求，可以上`FreeSSL`申请SSL证书，不过免费的有效期只有3个月，这就意味着你过3个月就要重新申请一次了。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.30/202207111612873.png" alt="image-20220711161239659" style="zoom:50%;" />

- 附上官网地址：https://freessl.cn/

### acme.sh自动申请证书

`acme.sh`脚本实现了`acme`协议, 可以从`letsencrypt`生成免费的证书。一般我们申请的证书有效期都是1年，过期就要重新申请了，使用`acme.sh`脚本可以实现到期自动申请，再也不用担心证书过期了！

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.30/202207111613253.png" alt="image-20220711161317124" style="zoom:67%;" />

附上官网地址：https://github.com/acmesh-official/acme.sh

### 腾讯云证书 ⭐

[我的证书 - SSL 证书 - 控制台 (tencent.com)](https://console.cloud.tencent.com/ssl/dsc/detail?id=v5cxO2iv)

具体配置过程网上挺多的了，也可以使用你购买的某某云，一般都会有[免费申请](https://link.juejin.cn?target=https%3A%2F%2Fcloud.tencent.com%2Fdocument%2Fproduct%2F400%2F6814)的服务器证书，安装直接看所在云的操作指南即可。

我购买的腾讯云提供的亚洲诚信机构颁发的免费证书只能一个域名使用，二级域名什么的需要另外申请，但是申请审批比较快，一般几分钟就能成功，然后下载证书的压缩文件，里面有个 nginx 文件夹，把 `xxx.crt` 和 `xxx.key` 文件拷贝到服务器目录，再配置下：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206211642406.png" alt="image-20220621164242207" style="zoom:67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206211644801.png" alt="image-20220621164400634" style="zoom:50%;" />

解压完成后

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206211644240.png" alt="image-20220621164453104" style="zoom:67%;" />

### 本地生成证书 ⭐

先要确认当前系统是否有安装openssl，如果没有，则要进行安装

```apl
openssl version
# 没有openssl，自己进行安装
yum -y install openssl openssl-devel make zlib zlib-devel gcc gcc-c++ libtool  pcre pcre-devel
```

安装下面的命令进行生成

```apl
mkdir /root/cert
cd /root/cert
# 生成server.key，执行命令时要输入密码和确认密码，自己随便设置即可
openssl genrsa -des3 -out server.key 1024
# 生成server.csr，需要输入上面设置的密码，以及国家姓名等信息
openssl req -new -key server.key -out server.csr
cp server.key server.key.org
# 需要再次输入上面设置的密码
openssl rsa -in server.key.org -out server.key
# 成功完成
openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204300934371.png" alt="image-20220430093426255" style="zoom:80%;" />

总共生成了4个文件

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204300939115.png" alt="image-20220430093925039" style="zoom: 80%;" />

## 完整配置 ⭐

### 完整示例

```
vim /etc/hosts
127.0.0.1 www.itcast.cn
ping www.itcast.cn
```



```yml
server {
    listen 80;
    server_name www.itcast.cn;
    location / {
        # 将www.itcast.cn自动加上https://www.itcast.cn
        rewrite ^(.*) https://www.itcast.cn$1;
    }
}

# HTTPS server
server {
   # https默认端口就是443，后面的ssl作用等同于ssl on
   listen       443 ssl;
   # 到时可以配置成网址：www.renshuo.xyz
   server_name  www.itcast.cn;
   # 到时可以配置成对应的pem文件和key文件
   ssl_certificate      /root/cert/server.crt;
   ssl_certificate_key  /root/cert/server.key;
   #设置ssl会话缓存
   ssl_session_cache    shared:SSL:1m;
   ssl_session_timeout  5m;
   # 密码格式默认就行
   ssl_ciphers  HIGH:!aNULL:!MD5;
   ssl_prefer_server_ciphers  on;
   # 地址都会跳转到此，可以配置多个location
   location /{
        default_type text/html;
        return 200 '<h1>hello</h1>';
    }
}
```

访问测试：输入www.itcast.cn自动转换成https://www.itcast.cn/

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206211734788.png" alt="image-20220621173419622" style="zoom:80%;" />



# 负载均衡

## 负载均衡概述

### 单机模式缺点

> 早期的网站流量和业务功能都比较简单，单台服务器足以满足基本的需求，但是随着互联网的发展，业务流量越来越大并且业务逻辑也跟着越来越复杂，单台服务器的性能及单点故障问题就凸显出来了，因此需要多台服务器进行性能的水平扩展及避免单点故障出现。那么如何将不同用户的请求流量分发到不同的服务器上呢？

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282223750.png" alt="1591631182469" style="zoom: 67%;" />

### 系统扩展方案

> 系统的扩展可以分为纵向扩展和横向扩展。
>
> 纵向扩展是从单机的角度出发，通过增加系统的硬件处理能力来提升服务器的处理能力
>
> 横向扩展是通过添加机器来满足大型网站服务的处理能力。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282223755.png" alt="1584602513812" style="zoom:67%;" />

> 这里面涉及到两个重要的角色分别是"应用集群"和"负载均衡器"。
>
> 应用集群：应用部署到多台机器上，组成处理集群，接收负载均衡设备分发的请求，进行处理并返回响应的数据
>
> 负载均衡器:将用户访问的请求根据对应的负载均衡算法，分发到集群中的一台服务器进行处理。

### 负载均衡的作用

> 1、解决服务器的高并发压力，提高应用程序的处理性能。
>
> 2、提供故障转移，实现高可用。
>
> 3、通过添加或减少服务器数量，增强网站的可扩展性。
>
> 4、在负载均衡器上进行过滤，可以提高系统的安全性。

### 常用实现负载均衡策略

#### 用户手动选择

> 这种方式比较原始，只要实现的方式就是在网站主页上面提供不同线路、不同服务器链接方式，让用户来选择自己访问的具体服务器，来实现负载均衡。

![1584602887881](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282223759.png)

#### DNS轮询方式

> DNS：域名系统（服务）协议（DNS）是一种分布式网络目录服务，主要用于域名与 IP 地址的相互转换。一个域名可以绑定多个ip地址，这样就有了多台服务器

> 大多域名注册商都支持对同一个主机名添加多条A记录，这就是DNS轮询，DNS服务器将解析请求按照A记录的顺序，随机分配到不同的IP上，这样就能完成简单的负载均衡。DNS轮询的成本非常低，在一些不重要的服务器，被经常使用。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282223756.png" alt="1591010973996" style="zoom: 40%;" />

如下是我们为某一个域名添加的IP地址，用2台服务器来做负载均衡。

![1590064506355](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282223757.png)



验证:

```apl
ping renshuo.xyz
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204301050630.png" alt="image-20220430105000541" style="zoom: 80%;" />

清空本地的dns缓存

```apl
ipconfig/flushdns
```

我们发现使用DNS来实现轮询，不需要投入过多的成本，虽然DNS轮询成本低廉，但是DNS负载均衡存在明显的缺点。

> 1.可靠性低
>
> 假设一个域名DNS轮询多台服务器，如果其中的一台服务器发生故障，那么所有的访问该服务器的请求将不会有所回应，即使你将该服务器的IP从DNS中去掉，但是由于各大宽带接入商将众多的DNS存放在缓存中，以节省访问时间，导致DNS不会实时更新。所以DNS轮流上一定程度上解决了负载均衡问题，但是却存在可靠性不高的缺点。
>
> 2.负载均衡不均衡
>
> DNS负载均衡采用的是简单的轮询负载算法，不能区分服务器的差异，不能反映服务器的当前运行状态，不能做到为性能好的服务器多分配请求，另外本地计算机也会缓存已经解析的域名到IP地址的映射，这也会导致使用该DNS服务器的用户在一定时间内访问的是同一台Web服务器，从而引发Web服务器减的负载不均衡。
>
> 负载不均衡则会导致某几台服务器负荷很低，而另外几台服务器负荷确很高，处理请求的速度慢，配置高的服务器分配到的请求少，而配置低的服务器分配到的请求多。



### 四/七层负载均衡(重点)

> 介绍四/七层负载均衡之前，我们先了解一个概念，OSI(open system interconnection),叫开放式系统互联模型，这个是由国际标准化组织ISO指定的一个不基于具体机型、操作系统或公司的网络体系结构。该模型将网络通信的工作分为七层。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282223768.png" alt="1584693830966" style="zoom:50%;" />

> 应用层：为应用程序提供网络服务。
>
> 表示层：对数据进行格式化、编码、加密、压缩等操作。
>
> 会话层：建立、维护、管理会话连接。
>
> 传输层：建立、维护、管理端到端的连接，常见的有TCP/UDP。
>
> 网络层：IP寻址和路由选择
>
> 数据链路层：控制网络层与物理层之间的通信。
>
> 物理层：比特流传输。

所谓四层负载均衡指的是OSI七层模型中的传输层，主要是基于IP+PORT的负载均衡

> 实现四层负载均衡的方式：
> 硬件：F5 BIG-IP、Radware等
> 软件：LVS、Nginx、Hayproxy等

所谓的七层负载均衡指的是在应用层，主要是基于虚拟的URL或主机IP的负载均衡

> 实现七层负载均衡的方式：
> 软件：Nginx、Hayproxy等

**四层和七层负载均衡的区别**

> 四层负载均衡数据包是在底层就进行了分发，而七层负载均衡数据包则在最顶端进行分发，所以四层负载均衡的效率比七层负载均衡的要高。
> 四层负载均衡不识别域名，而七层负载均衡识别域名。

处理四层和七层负载以为其实还有二层、三层负载均衡，二层是在数据链路层基于mac地址来实现负载均衡，三层是在网络层一般采用虚拟IP地址的方式实现负载均衡。

**实际环境采用的模式**

> 四层负载(LVS)+七层负载(Nginx)

## 七层负载均衡⭐

Nginx要实现七层负载均衡`需要用到proxy_pass代理模块配置`。Nginx默认安装支持这个模块，我们不需要再做任何处理。Nginx的负载均衡是在Nginx的反向代理基础上把用户的请求根据指定的算法分发到一组【upstream虚拟服务池】

### 基本指令

#### upstream指令

> 该指令是用来定义一组服务器，它们可以是监听不同端口的服务器，并且也可以是同时监听TCP和Unix socket的服务器。服务器可以指定不同的权重，默认为1。

| 语法   | upstream name {...} |
| ------ | ------------------- |
| 默认值 | —                   |
| 位置   | http                |

#### server指令

> 该指令用来指定后端服务器的名称和一些参数，可以使用域名、IP、端口或者unix socket

| 语法   | server name [paramerters] |
| ------ | ------------------------- |
| 默认值 | —                         |
| 位置   | upstream                  |

### 实现流程⭐

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282223124.png" alt="1590248160635" style="zoom:67%;" />

#### 定义web服务器

自定义server，写在nginx.conf中即可

```apl
server {
    listen   9001;
    server_name localhost;
    default_type text/html;
    location /{
        return 200 '<h1>192.168.22.146:9001</h1>';
    }
}
server {
    listen   9002;
    server_name localhost;
    default_type text/html;
    location /{
        return 200 '<h1>192.168.22.146:9002</h1>';
    }
}
server {
    listen   9003;
    server_name localhost;
    default_type text/html;
    location /{
        return 200 '<h1>192.168.22.146:9003</h1>';
    }
}
```

#### 定义负载均衡器

> 这个可以设置在一个单独的服务器中，目前为了测试，就把他们放在一个服务器中

```apl
upstream backend{
    server 192.168.22.146:9001;
    server 192.168.22.146:9002;
    server 192.168.22.146:9003;
}
server {
    listen 8083;
    server_name localhost;
    location /{
        proxy_pass http://backend;
    }
}
```

#### 验证测试

访问网址http://192.168.22.146:8083/，发现上面三个网址轮流被访问

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206210940809.png" alt="image-20220621094058711" style="zoom:67%;" />

或者另一种方式验证：启动CMD

```c
curl http://192.168.22.130:8083/
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206210943913.png" alt="image-20220621094301830" style="zoom:67%;" />

### 参数配置 ⭐

代理服务器在负责均衡调度中的状态有以下几个：

| 状态         | 概述                              |
| ------------ | --------------------------------- |
| down         | 当前的server暂时不参与负载均衡    |
| backup       | 预留的备份服务器                  |
| max_fails    | 允许请求失败的次数                |
| fail_timeout | 经过max_fails失败后, 服务暂停时间 |
| max_conns    | 限制最大的接收连接数              |

#### down 永久不可用

> down:将该服务器标记为永久不可用，那么该代理服务器将不参与负载均衡。

```apl
upstream backend{
	server 192.168.22.129:9001 down;
	server 192.168.22.129:9002
	server 192.168.22.129:9003;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```

该状态一般会对需要停机维护的服务器进行设置。用chrome浏览器进行访问时可能会出现只访问9002的情况，这时可以用其他浏览器或者cmd的curl进行测试：curl http://192.168.22.129:8083/

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204301107193.png" alt="image-20220430110735110" style="zoom: 80%;" />



#### backup 备份服务器

> backup:将该服务器标记为备份服务器，只有当主服务器不可用时，才将用来传递请求。此时需要将9094端口的访问禁止掉来模拟下唯一能对外提供访问的服务宕机以后，backup的备份服务器就要开始对外提供服务，此时为了测试验证，我们需要使用防火墙来进行拦截。

```apl
upstream backend{
	server 192.168.200.146:9001 down;
	server 192.168.200.146:9002 backup;
	server 192.168.200.146:9003;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```

#### max_conns 最大连接数

> max_conns=number:用来设置代理服务器同时活动链接的最大数量，**默认为0，表示不限制**，使用该配置可以根据后端服务器处理请求的并发量来进行设置，防止后端服务器被压垮。

```apl
upstream backend{
    server 192.168.22.146:9001 max_conns=1000 backup;
    server 192.168.22.146:9002 max_conns=1500;
    server 192.168.22.146:9003 max_conns=2000;
}
server {
    listen 8083;
    server_name localhost;
    location /{
        proxy_pass http://backend;
    }
}
```

#### max_fails和fail_timeout

max_fails=number:设置`允许请求代理服务器失败的次数`，默认为1。

fail_timeout=time:设置经过max_fails失败后，`服务暂停的时间`，默认是10秒。

```apl
upstream backend{
	server 192.168.200.133:9001 max_conns=10;
	server 192.168.200.133:9002 backup;
	server 192.168.200.133:9003 max_fails=3 fail_timeout=15;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```

### 可选项配置

```yml
upstream back_end{
    server 127.0.0.1:8081 weight=3 max_conns=1000 fail_timeout=10s max_fails=2;
    # 限制每个 worker 子进程与上游服务器空闲长连接的最大数量
    keepalive 32;
    # 单个长连接可以处理的最多 HTTP 请求个数
    keepalive_requests 50;
    # 空闲长连接的最长保持时间
    keepalive_timeout 30s;
}
```



### 负载均衡策略⭐

介绍完Nginx负载均衡的相关指令后，我们已经能实现将用户的请求分发到不同的服务器上，那么除了采用默认的分配方式以外，我们还能采用什么样的负载算法? Nginx的upstream支持如下六种方式的分配算法，分别是:

| 算法名称   | 说明             |
| ---------- | ---------------- |
| 轮询       | 默认方式         |
| weight     | 权重方式         |
| ip_hash    | 依据ip分配方式   |
| least_conn | 依据最少连接方式 |
| url_hash   | 依据URL分配方式  |
| fair       | 依据响应时间方式 |

#### 轮询 默认

> 是upstream模块**负载均衡默认的策略**。每个请求会按时间顺序逐个分配到不同的后端服务器。轮询不需要额外的配置，因为默认的方式就是轮询

> 每个请求按时间顺序逐一分配到不同的后端服务器，也就是说第一次请求分配到第一台服务器上，第二次请求分配到第二台服务器上，如果只有两台服务器，第三次请求继续分配到第一台上，这样循环轮询下去，也就是服务器接收请求的比例是 1:1， 如果后端服务器down掉，能自动剔除。轮询是默认配置，不需要太多的配置

```apl
upstream backend{
	server 192.168.200.146:9001;
	server 192.168.200.146:9002;
	server 192.168.200.146:9003;
}

server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```

#### weight 加权轮询

> 指定轮询几率，weight和访问比率成正比, 也就是服务器接收请求的比例就是各自配置的weight的比例，用于后端服务器性能不均的情况,比如服务器性能差点就少接收点请求，服务器性能好点就多处理点请求。

> weight=number:用来设置服务器的权重，默认为1，权重数据越大，被分配到请求的几率越大；该权重值，主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的，所有此策略比较适合服务器的硬件配置差别比较大的情况。权重越大不表示一定会选择到它，而是请求次数越多越会按照权重的比例分布

```apl
upstream backend{
    server 192.168.22.130:9001 weight=10;
    server 192.168.22.130:9002 weight=5;
    # backup是指热备，只有当9001和9002都宕机的情况下才走9003
    server 192.168.22.130:9003 weight=3 backup;
}
server {
    listen 8083;
    server_name localhost;
    location /{
        proxy_pass http://backend;
    }
}
```

进行访问：http://192.168.22.130:8083/



#### ip_hash

> 主要解决session共享问题，但无法保证负载均衡，会导致少数服务器被很多用户访问，上面的2种方式都有一个问题，那就是下一个请求来的时候请求可能分发到另外一个服务器，当我们的程序不是无状态的时候(采用了session保存数据)，这时候就有一个很大的很问题了

> 比如把登录信息保存到了session中，那么跳转到另外一台服务器的时候就需要重新登录了，所以很多时候我们需要一个客户只访问一个服务器，那么就需要用iphash了，iphash的每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。

| 语法   | ip_hash; |
| ------ | -------- |
| 默认值 | —        |
| 位置   | upstream |

```apl
upstream backend{
    ip_hash;
    server 192.168.22.130:9001;
    server 192.168.22.130:9002;
    server 192.168.22.130:9003;
}
server {
    listen 8083;
    server_name localhost;
    location /{
        proxy_pass http://backend;
    }
}
```

> 需要额外多说一点的是使用ip_hash指令无法保证后端服务器的负载均衡，可能导致有些后端服务器接收到的请求多，有些后端服务器接收的请求少，而且设置后端服务器权重等方法将不起作用。推荐使用redis来解决登录session会话保存的问题

![1591706748677](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282223131.png)

#### least_conn 最少连接

> 此负载均衡策略适合请求处理时间长短不一造成服务器过载的情况。

> 最少连接，把请求转发给连接数较少的后端服务器。轮询算法是把请求平均的转发给各个后端，使它们的负载大致相同；但是，有些请求占用的时间很长，会导致其所在的后端负载较高。这种情况下，least_conn这种方式就可以达到更好的负载均衡效果。

```apl
upstream backend{
    least_conn;
    server 192.168.22.130:9001;
    server 192.168.22.130:9002;
    server 192.168.22.130:9003;
}
server {
    listen 8083;
    server_name localhost;
    location /{
        proxy_pass http://backend;
    }
}
```

![1591809623736](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282223136.png)

#### url_hash

> 按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，要配合缓存命中来使用。**同一个资源多次请求，可能会到达不同的服务器上，导致不必要的多次下载，缓存命中率不高，以及一些资源时间的浪费。**而使用url_hash，可以使得同一个url（也就是同一个资源请求）会到达同一台服务器，一旦缓存住了资源，再此收到请求，就可以从缓存中读取。

```apl
upstream backend{
	hash &request_uri; # 如果&request_uri换成对应IP
	server 192.168.200.146:9001;
	server 192.168.200.146:9002;
	server 192.168.200.146:9003;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```

访问如下地址：

```apl
http://192.168.200.133:8083/a
http://192.168.200.133:8083/b
http://192.168.200.133:8083/c
```

![1591812222306](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282223144.png)



#### fair 智能切换

> fair采用的不是内建负载均衡使用的轮换的均衡算法，而是可以根据页面大小、加载时间长短智能的进行负载均衡。那么如何使用第三方模块的fair负载均衡策略。但是如何直接使用会报错，因为fair属于第三方模块实现的负载均衡。需要添加`nginx-upstream-fair`

##### fair模块下载配置

```sh
# 下载地址为:https://github.com/gnosek/nginx-upstream-fair
# 将下载的文件上传到服务器并进行解压缩 /root目录
unzip nginx-upstream-fair-master.zip
# 重命名资源
mv nginx-upstream-fair-master fair
# 使用./configure命令将资源添加到Nginx模块中，要通过nginx -V把nginx之前添加的模块加到configue后面
nginx -V
cd /root/nginx-1.23.2
make clean
./configure --with-http_gzip_static_module --with-http_ssl_module --add-module=/root/fair
# 编译
make
```

> 编译可能会出现如下错误，ngx_http_upstream_srv_conf_t结构中缺少default_port

![1584941470457](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282223142.png)

> 解决方案:在Nginx的源码中 src/http/ngx_http_upstream.h,找到`ngx_http_upstream_srv_conf_s`，在模块中添加添加default_port属性：/root/nginx-1.23.2/src/http

```c
in_port_t	   default_port；
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301171610497.png" alt="image-20230117161016316" style="zoom:67%;" />

```sh
# 再次进行编译执行后续步骤即可
make 
# 将objs目录下的nginx二进制执行文件移动到nginx安装目录下的sbin目录中
mv objs/nginx /usr/local/nginx/sbin
# 执行更新命令
make upgrade
# 查看是否安装成功
nginx -V
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301171618827.png" alt="image-20230117161809624" style="zoom:67%;" />

##### fair 模块使用

```coffeescript
upstream backend{
	fair;
	server 192.168.200.146:9001;
	server 192.168.200.146:9002;
	server 192.168.200.146:9003;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```

> 上面介绍了Nginx常用的负载均衡的策略，有人说是5种，是把轮询和加权轮询归为一种，也有人说是6种。那么在咱们以后的开发中到底使用哪种，这个需要根据实际项目的应用场景来决定的。



### 负载均衡案例

#### 对所有请求实现轮询规则的负载均衡

```apl
upstream backend{
	server 192.168.200.146:9001;
	server 192.168.200.146:9002;
	server 192.168.200.146:9003;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```

#### 对所有请求实现加权轮询的负载均衡

```apl
upstream backend{
	server 192.168.200.146:9001 weight=7;
	server 192.168.200.146:9002 weight=5;
	server 192.168.200.146:9003 weight=3;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```

#### 对特定资源实现负载均衡

```apl
upstream videobackend{
	server 192.168.22.146:9001;
	server 192.168.22.146:9002;
}
upstream filebackend{
	server 192.168.22.146:9003;
	server 192.168.22.146:9004;
}
server {
	listen 8084;
	server_name localhost;
	# 以video和file开头的url分别对应不同的服务器
	location /video/ {
		proxy_pass http://videobackend;
	}
	location /file/ {
		proxy_pass http://filebackend;
	}
}
```

#### 对不同域名实现负载均衡

先修改hosts

```apl
vim /etc/hosts
```

```apl
127.0.0.1 www.itcast.cn
127.0.0.1 www.itheima.cn
```

nginx.conf

```apl
upstream itcastbackend{
	server 192.168.200.146:9001;
	server 192.168.200.146:9002;
}
upstream itheimabackend{
	server 192.168.200.146:9003;
	server 192.168.200.146:9004;
}
server {
	listen	8085;
	server_name www.itcast.cn;
	location / {
		proxy_pass http://itcastbackend;
	}
}
server {
	listen	8086;
	server_name www.itheima.cn;
	location / {
		proxy_pass http://itheimabackend;
	}
}
```

注意只能在虚拟机内部浏览器访问，访问：www.itcast.cn:8085

#### 实现带有URL重写的负载均衡

```apl
upstream backend{
	server 192.168.200.146:9001;
	server 192.168.200.146:9002;
	server 192.168.200.146:9003;
}
server {
	listen	80;
	server_name localhost;
	# 对所有/file的url重写成/server开头的，加上last表示会重新匹配/server开头的location
	location /file/ {
		rewrite ^(/file/.*) /server/$1 last;
	}
	location /server {
		proxy_pass http://backend;
	}
}
```



## 四层负载均衡

> Nginx在1.9之后，增加了一个stream模块，用来实现四层协议的转发、代理、负载均衡等。stream模块的用法跟http的用法类似，允许我们配置一组TCP或者UDP等协议的监听，然后通过proxy_pass来转发我们的请求，通过upstream添加多个后端服务，实现负载均衡。

> 四层协议负载均衡的实现，一般都会用到LVS、HAProxy、F5等，要么很贵要么配置很麻烦，而Nginx的配置相对来说更简单，更能快速完成工作。

### stream 模块添加

Nginx默认是没有编译这个模块的，需要使用到stream模块，那么需要在编译的时候加上`--with-stream`。

```sh
# 查询当前Nginx的配置参数
nginx -V
# 将nginx安装目录下sbin目录中的nginx二进制文件进行更名
cd /usr/local/nginx/sbin
mv nginx nginxold
# 进入Nginx的安装目录
cd /root/nginx-1.23.2
# 执行make clean清空之前编译的内容
make clean
# 使用configure来配置参数
./configure --with-http_gzip_static_module --with-stream
# 使用make命令进行编译
make
# 将objs目录下的nginx二进制执行文件移动到nginx安装目录下的sbin目录中
mv objs/nginx /usr/local/nginx/sbin
# 执行更新命令
make upgrade
# 查看是否安装成功
nginx -V
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301171635898.png" alt="image-20230117163515656" style="zoom:67%;" />

```sh
# 需要重启nginx，不然不会生效
nginx -s stop
nginx
```



### 四层负载均衡指令

#### stream指令

该指令提供在其中指定流服务器指令的配置文件上下文。和http指令同级。

| 语法   | stream { ... } |
| ------ | -------------- |
| 默认值 | —              |
| 位置   | main           |

#### upstream指令

该指令和http的upstream指令是类似的。

### Redis 负载均衡⭐

#### 需求分析

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204282223442.png" alt="1591897178807" style="zoom:50%;" />

#### 实现步骤

准备Redis服务器,在一条服务器上准备三个Redis，端口分别是6379,6378，分别启动，即可获取两个Redis.并查看

```sh
cp /etc/redis.conf /root/reids/redis1.conf
redis-server /root/reids/redis1.conf
cp /root/reids/redis1.conf /root/reids/redis2.conf
redis-server /root/reids/redis2.conf
ps -ef | grep redis
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301171646303.png" alt="image-20230117164637109" style="zoom:67%;" />

使用Nginx将请求分发到不同的Redis服务器上。

nginx.conf配置

```apl
# 在http块外部，和http块同级
stream {
   # Redis 服务器
   upstream redisbackend {
        # 将请求转发到不同的redis服务器
        server 192.168.22.146:6379;
        server 192.168.22.146:6380;
    }
    server {
        listen  81;
        proxy_pass redisbackend;
    }
}
```

访问测试

```
redis-cli -h 192.168.22.146 -p 81
```



### Tomcat 负载均衡

准备Tomcat服务器(和上面Redis不影响)

1.上传tomcat的安装包，`apache-tomcat-8.5.56.tar.gz`

2.将安装包进行解压缩

```sh
tar -zxvf  apache-tomcat-8.5.59.tar.gz
```

3.进入tomcat的bin目录

```sh
cd apache-tomcat-8.5.59/bin
./startup.sh
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301171720651.png" alt="image-20230117172014437" style="zoom:67%;" />

```apl
stream {
    upstream backend {
        server 192.168.22.146:8080 max_fails=3 fail_timeout=30s;
    }

    server {
        listen 82;
        proxy_connect_timeout 1s;
        proxy_timeout 3s;
        proxy_pass backend;
    }
}
```

访问测试：http://192.168.22.146:82/

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301171753804.png" alt="image-20230117175315568" style="zoom:67%;" />



# 动静分离

## 动静分离概述

### 什么是动静分离?

> 动:后台应用程序的业务处理；静:网站的静态资源(html,javaScript,css,images等文件)

> 分离:将两者进行分开部署访问，提供用户进行访问。举例说明就是以后所有和静态资源相关的内容都交给Nginx来部署访问，非静态内容则交个类似于Tomcat的服务器来部署访问。

### 为什么要动静分离?

> 动静分离应该是听的次数较多的性能优化方案，那先思考一个问题：**「为什么需要做动静分离呢？它带来的好处是什么？」** 其实这个问题也并不难回答，当你搞懂了网站的本质后，自然就理解了动静分离的重要性。淘宝网为例

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301180935421.png" alt="image-20230118093506170" style="zoom: 80%;" />

> 当浏览器输入`www.taobao.com`访问淘宝首页时，打开开发者调试工具可以很明显的看到，首页加载会出现`100+`的请求数，而正常项目开发时，静态资源一般会放入到`resources/static/`目录下：

> 在项目上线部署时，这些静态资源会一起打成包，那此时思考一个问题：**「假设淘宝也是这样干的，那么首页加载时的请求最终会去到哪儿被处理？」** 答案毋庸置疑，首页100+的所有请求都会来到部署WEB服务的机器处理，那则代表着一个客户端请求淘宝首页，就会对后端服务器造成100+的并发请求。这对于后端服务器的压力是尤为巨大的。

> 但此时不妨分析看看，首页100+的请求中，是不是至少有60+是属于*.js、*.css、*.html、*.jpg.....这类静态资源的请求呢？答案是Yes。

> 既然有这么多请求属于静态的，这些资源大概率情况下，长时间也不会出现变动，那为何还要让这些请求到后端再处理呢？能不能在此之前就提前处理掉？当然`OK`，因此经过分析之后能够明确一点：**「做了动静分离之后，至少能够让后端服务减少一半以上的并发量。」** 到此时大家应该明白了动静分离能够带来的性能收益究竟有多大。

### 如何实现动静分离

> 实现动静分离的方式很多，比如静态资源可以部署到CDN、Nginx等服务器上，动态资源可以部署到Tomcat,weblogic或者websphere上。本次课程只要使用Nginx+Tomcat来实现动静分离。

## 实现步骤

①先在部署`Nginx`的机器，`Nginx`目录下创建一个目录`static_resources`：

```sh
mkdir static_resources
```

②将项目中所有的静态资源全部拷贝到该目录下，而后将项目中的静态资源移除重新打包。

③稍微修改一下`nginx.conf`的配置，增加一条`location`匹配规则：

```scss
location ~ .*\.(html|htm|gif|jpg|jpeg|bmp|png|ico|txt|js|css){
    root   /soft/nginx/static_resources;
    expires 7d;
}
```

然后照常启动`nginx`和移除了静态资源的`WEB`服务，你会发现原本的样式、`js`效果、图片等依旧有效

其中`static`目录下的`nginx_style.css`文件已被移除，但效果依旧存在（绿色字体+蓝色大边框)：

**最后提一嘴，也可以将静态资源上传到文件服务器中，然后`location`中配置一个新的`upstream`指向。**

## 动静分离实战

准备：启动SpringBoot项目，在nginx/html/web上传图片

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206211808741.png" alt="image-20220621180836592" style="zoom: 67%;" />

```apl
upstream webservice{
   server 192.168.1.107:8080;
}

server {
   listen       80;
   server_name  localhost;

   #动态资源，这样的缺点是只能写hello一个路径，写/就是表示可以访问所有路径
   location / {
         proxy_pass http://webservice;
   }
        
   # 拦截静态资源请求
   location ~/.*\.(png|jpg|gif|js|css){
         root html/web;
   }
}
```

当正常访问时：http://192.168.22.130/getAccount

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206211809644.png" alt="image-20220621180910476" style="zoom:50%;" />

当访问图片时：http://192.168.22.130/g2.jpg

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206211810268.png" alt="image-20220621181023882" style="zoom:50%;" />



## 负载均衡+动静分离

在使用Nginx和Tomcat部署项目的时候，我们使用的是一台Nginx服务器和一台Tomcat服务器，效果图如下:

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204301712100.png" alt="1604494256017" style="zoom:67%;" />

那么问题来了，如果Tomcat的真的宕机了，整个系统就会不完整，所以如何解决上述问题，一台服务器容易宕机，那就多搭建几台Tomcat服务器，这样的话就提升了后的服务器的可用性。这也就是我们常说的集群，搭建Tomcat的集群需要用到了Nginx的反向代理和赋值均衡的知识，具体如何来实现?我们先来分析下原理

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204301712106.png" alt="1604494269848" style="zoom: 67%;" />



环境准备：

(1)准备3台tomcat,使用端口进行区分[实际环境应该是三台服务器]，修改server.ml，将端口修改分别修改为8080,88081,8082

```apl
# 启动8080服务
java -jar demo.jar
# 启动8081、8082服务
java -jar demo.jar  --server.port=8081
java -jar demo.jar  --server.port=8082
```

(2)启动tomcat并访问测试，

```apl
http://192.168.0.155:8080/hello
```

```apl
http://192.168.0.155:8081/hello
```

```apl
http://192.168.0.155:8082/hello
```

(3)在Nginx对应的配置文件中添加如下内容:

```apl
# 和上面对比，主要修改了upstream，让服务器负载均衡
upstream webservice{
        server 192.168.0.155:8080;
        server 192.168.0.155:8081;
        server 192.168.0.155:8082;
}
    
server {
       listen       80;
       server_name  localhost;
       root html/web;

        #动态资源
        location / {
               # 处理跨域
               add_header Access-Control-Allow-Origin *;
               add_header Access-Control-Allow-Methods GET,POST,PUT,DELETE;
               proxy_pass http://webservice;
        }
}

server {
        listen    8089;
        server_name  localhost;

        location / {
            root html/web;
            index  index.html index.htm;
        }
         #静态资源
        location ~/.*\.(png|jpg|gif|js){
            root html/web;
            gzip on;
        }
}
```

最后进行访问：http://192.168.22.129:8089/index.html

好了，完成了上述环境的部署，我们已经解决了Tomcat的高可用性，一台服务器宕机，还有其他两条对外提供服务，同时也可以实现后台服务器的不间断更新。但是新问题出现了，上述环境中，如果是Nginx宕机了呢，那么整套系统都将服务对外提供服务了，这个如何解决？

# 限流

Nginx按请求速率限速模块使用的是**漏桶算法**，即能够强行保证请求的实时处理速度不会超过设置的阈值。

Nginx的限流主要通过修改`nginx.conf`文件来进行，有两种限流方式：

- 通过`请求数`进行限流
- 通过`连接数`进行限流

## 漏桶算法

> - 水（请求）从上方倒入水桶，从水桶下方流出（被处理）；
> - 来不及流出的水存在水桶中（缓冲），以固定速率流出；
> - 水桶满后水溢出（丢弃）。
> - 这个算法的核心是：缓存请求、匀速处理、多余的请求直接丢弃。
> - 相比漏桶算法，令牌桶算法不同之处在于它不但有一只“桶”，还有个队列，这个桶是用来存放令牌的，队列才是用来存放请求的。

## 参数分析

参数解释：

> - $binary_remote_addr：binary_目的是缩写内存占用，remote_addr表示通过IP地址来限流
> - zone:iplimit是一块内存区域（记录访问频率信息）,20m是指这块内存区域的大小
> - rate: 1r/s = 1 request / second，类似于100/m（每分钟100次请求）
> - burst: burst=2,设置一个大小为2的缓存区域，当大量请求到来，请求数量超过限流频率时，将其放入缓冲区域
> - nodelay: 缓冲区满了后直接返回503异常
> - 另外我们也可以在location下通过配置 limit_req_status 504或limit_conn_status 504来修改默认errorCode

## 根据IP限流

单个ip访问次数限制

> - 第一个参数：$binary_remote_addr 表示通过remote_addr这个标识来做限制，“binary_”的目的是缩写内存占用量，是限制同一客户端ip地址。
> - 第二个参数：zone=one:10m表示生成一个大小为10M，名字为one的内存区域，用来存储访问的频次信息。
> - 第三个参数：rate=10r/s表示允许同一个客户端的访问频次是每秒10次，还可以有比如30r/m的。

```apl
limit_req_zone $binary_remote_addr zone=iplimit:10m rate=1r/s;
# 设置返回状态码，可选
limit_req_status 503;

upstream backend{
    server 192.168.1.107:8089;
}
server {
    listen 8083;
    server_name localhost;
    location /{
        # 根据ip地址限制流量
        limit_req zone=iplimit burst=2 nodelay;
        proxy_pass http://backend;
    }
}
```

访问测试：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.23/202206281506176.png" alt="image-20220628150610095" style="zoom:67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.23/202206281506374.png" alt="image-20220628150627288" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.23/202206281505722.png" alt="image-20220628150550611" style="zoom:50%;" />

可以发现再刷新频率较低时，能正常访问服务，当频率超过1r/s时，会抛503异常

## 根据服务器限流

上面是根据单ip进行修改，我们也同时支持根据服务器级别进行限流，将$binary_remote_addr修改为$server_name即可

```apl
limit_req_zone  $server_name zone=iplimit:10m rate=1r/s;
limit_req_status 503;

upstream backend{
    server 192.168.1.107:8089;
}
server {
    listen 8083;
    server_name localhost;
    location /{
        # 根据ip地址限制流量
        limit_req zone=iplimit burst=2 nodelay;
        proxy_pass http://backend;
    }
}
```



## 

# 高可用 Keepalived

## Keepalived 环境搭建

http://192.168.0.199:8082/hello

| VIP 虚拟IP     | IP              | 主/从  |
| -------------- | --------------- | ------ |
|                | 192.168.22.128  | Master |
| 192.168.22.151 |                 |        |
|                | 192.168.200.150 | Backup |

### 环境搭建

> 步骤1:从官方网站下载keepalived,官网地址：https://keepalived.org/

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301181213088.png" alt="image-20230118121336006" style="zoom:67%;" />

> 步骤2:将下载的资源上传到服务器

```sh
# 3、创建keepalived目录，方便管理资源
mkdir keepalived
# 4、将压缩文件进行解压缩，解压缩到指定的目录
tar -xvf keepalived-2.2.7.tar.gz  -C keepalived/
cd keepalived/keepalived-2.2.7
# 5、对keepalived进行配置
./configure --sysconf=/etc --prefix=/usr/local
# 6、编译和安装
make && make install
```

```sh
keepalived -v 
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301181211645.png" alt="image-20230118121103319" style="zoom:67%;" />

> 忘记安装配置的目录，则通过如下命令找到：

```apl
whereis keepalived
```

### 文件位置

```sh
# 配置文件位置,主要操作的就是该文件 
/etc/keepalived/keepalived.conf
cp keepalived.conf.sample keepalived.conf
# 可执行脚本位置,启动和关闭keepalived
/usr/local/sbin/keepalived
```

### 前提条件

> nginx必须启动，不然启动不生效

```apl
upstream backend{
    server 192.168.0.199:8082;
}
server {
    listen 80;
    server_name localhost;
    location /{
        proxy_pass http://backend;
    }
}
```

## 实战案例

### 主服务器

> 注意：其他不需要的配置要注释起来，推荐先备份配置文件，在修改新的配置文件

```apl
! Configuration File for keepalived

global_defs {
   # 自带的邮件提醒服务，建议用独立的监控或第三方SMTP，也可选择配置邮件发送
   notification_email {
     acassen@firewall.loc
     failover@firewall.loc
     sysadmin@firewall.loc
   }
   notification_email_from Alexandre.Cassen@firewall.loc
   smtp_server 192.168.200.1
   smtp_connect_timeout 30
   #  # 高可用集群主机身份标识(集群中主机身份标识名称不能重复，建议配置成本机IP)⭐
   router_id 192.168.22.150
   vrrp_skip_check_adv_addr
   vrrp_strict
   vrrp_garp_interval 0
   vrrp_gna_interval 0
}
# 定时运行的脚本文件配置
vrrp_script check_nginx_pid_restart {
    # 之前编写的nginx重启脚本的所在位置
 script "/etc/keepalived/check_nginx_pid_restart.sh" 
    # 每间隔3秒执行一次
 interval 3
    # 如果脚本中的条件成立，重启一次则权重-20
 weight -20
}

# 定义虚拟路由，VI_1为虚拟路由的标示符（可自定义名称）
vrrp_instance VI_1 {
    # 当前节点的身份标识：用来决定主从（MASTER为主机，BACKUP为从机）
    state MASTER
    # 绑定虚拟IP的网络接口，根据自己的机器的网卡配置，必须改成ens33
    interface ens33
    # 虚拟路由的ID号，主从两个节点设置必须一样
    virtual_router_id 51
    # 填写本机IP
    mcast_src_ip 192.168.22.150
    # 节点权重优先级，主节点要比从节点优先级高
    # 优先级高的设置nopreempt，解决异常恢复后再次抢占造成的脑裂问题
    nopreempt
    priority 100
    # 组播信息发送间隔，两个节点设置必须一样，默认1s（类似于心跳检测）
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    # 将track_script块加入instance配置块
    track_script {
        # 执行Nginx监控的脚本
        check_nginx_pid_restart
    }
    virtual_ipaddress 
        # 虚拟IP(VIP)，也可扩展，可配置多个
        192.168.22.151
    }
}
```

### 备份服务器

```apl
! Configuration File for keepalived

global_defs {
   notification_email {
     acassen@firewall.loc
     failover@firewall.loc
     sysadmin@firewall.loc
   }
   notification_email_from Alexandre.Cassen@firewall.loc
   smtp_server 192.168.200.1
   smtp_connect_timeout 30
   router_id 192.168.22.128
   vrrp_skip_check_adv_addr
   vrrp_strict
   vrrp_garp_interval 0
   vrrp_gna_interval 0
}

vrrp_instance VI_1 {
    state BACKUP
    interface ens33
    virtual_router_id 51
    mcast_src_ip 192.168.22.128
    priority 90
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.22.151
    }
}
```

### 脚本配置

```sh
vi /etc/keepalived/check_nginx_pid_restart.sh
chmod +x  /etc/keepalived/check_nginx_pid_restart.sh
```

```sh
#!/bin/sh
# 通过ps指令查询后台的nginx进程数，并将其保存在变量nginx_number中
nginx_number=`ps -C nginx --no-header | wc -l`
# 判断后台是否还有Nginx进程在运行
if [ $nginx_number -eq 0 ];then
    # 如果后台查询不到`Nginx`进程存在，则执行重启指令
    nginx -c /usr/local/nginx/conf/nginx.conf
    # 重启后等待1s后，再次查询后台进程数
    sleep 1
    # 如果重启后依旧无法查询到nginx进程
    if [ `ps -C nginx --no-header | wc -l` -eq 0 ];then
        # 将keepalived主机下线，将虚拟IP漂移给从机，从机上线接管Nginx服务
        systemctl stop keepalived.service
    fi
fi
```

### 启动keepalived

分别启动两台服务器的keepalived

```sh
cd /usr/local/sbin
./keepalived
ps -ef | grep keepalived
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.1.30/202301181658973.png" alt="image-20230118165856881" style="zoom:67%;" />

### 访问测试

> 网站：http://192.168.22.151/hello，成功访问，启动keepalived之前，咱们先使用命令 `ip a`,查看192.168.200.133和192.168.200.122这两台服务器的IP情况

> 通过上述的测试，我们会发现，虚拟IP(VIP)会在MASTER节点上，当MASTER节点上的keepalived出问题以后，因为BACKUP无法收到MASTER发出的VRRP状态通过信息，就会直接升为MASTER。VIP也会"漂移"到新的MASTER。

> 从上图中可以明显看见虚拟`IP`已经成功挂载，但另外一台机器`192.168.22.128`并不会挂载这个虚拟`IP`，只有当主机下线后，作为从机的`192.168.22.128`才会上线，接替`VIP`。最后测试一下外网是否可以正常与`VIP`通信，即在`Windows`中直接`ping VIP`：



# 下载站点

## 什么是下载站点

首先我们先要清楚什么是下载站点?

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206201843998.png" alt="image-20220620184337841" style="zoom:50%;" />

我们先来看一个网站`http://nginx.org/download/`这个我们刚开始学习Nginx的时候给大家看过这样的网站，该网站主要就是用来提供用户来下载相关资源的网站，就叫做下载网站。

## 语法详解

如何制作一个下载站点:

nginx使用的是模块ngx_http_autoindex_module来实现的，该模块处理以斜杠("/")结尾的请求，并生成目录列表。

nginx编译的时候会自动加载该模块，但是该模块默认是关闭的，我们需要使用下来指令来完成对应的配置

autoindex:启用或禁用目录列表输出

| 语法   | autoindex on\|off;     |
| ------ | ---------------------- |
| 默认值 | autoindex off;         |
| 位置   | http、server、location |

autoindex_exact_size:对应HTLM格式，指定是否在目录列表展示文件的详细大小

默认为on，显示出文件的确切大小，单位是bytes。
改为off后，显示出文件的大概大小，单位是kB或者MB或者GB

| 语法   | autoindex_exact_size  on\|off; |
| ------ | ------------------------------ |
| 默认值 | autoindex_exact_size  on;      |
| 位置   | http、server、location         |

autoindex_format：设置目录列表的格式

| 语法   | autoindex_format html\|xml\|json\|jsonp; |
| ------ | ---------------------------------------- |
| 默认值 | autoindex_format html;                   |
| 位置   | http、server、location                   |

注意:该指令在1.7.9及以后版本中出现

autoindex_localtime:对应HTML格式，是否在目录列表上显示时间

默认为off，显示的文件时间为GMT时间
改为on后，显示的文件时间为文件的服务器时间

| 语法   | autoindex_localtime on \| off; |
| ------ | ------------------------------ |
| 默认值 | autoindex_localtime off;       |
| 位置   | http、server、location         |

## 案例演示 ⭐

```apl
mkdir /usr/local/download
```

在该文件夹上传若干文件

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206201849328.png" alt="image-20220620184938268" style="zoom:67%;" />

nginx.conf配置方式如下:

```apl
# 注意路径：最后会拼接root+访问路径，即/usr/local/download文件所在位置
location /download{
    root /usr/local;
    autoindex on; # 打开 autoindex，，可选参数有 on | off
    autoindex_exact_size on; # 修改为off，以KB、MB、GB显示文件大小，默认为on，以bytes显示确切⼤⼩
    autoindex_format html; # 以html的方式进行格式化，可选参数有 html | json | xml
    autoindex_localtime on; # 显示的⽂件时间为⽂件的服务器时间。默认为off，显示的⽂件时间为GMT时间
    charset 'utf-8'; # 中文乱码解决
}
```

进行访问：http://192.168.22.130/download/

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206201900605.png" alt="image-20220620190042540" style="zoom:50%;" />

点击即可进行下载，文件夹也可以点进去



## 安全下载

> 对应系统资源的访问，我们往往需要限制谁能访问，谁不能访问。这块就是我们通常所说的认证部分，认证需要做的就是根据用户输入的用户名和密码来判定用户是否为合法用户，如果是则放行访问，如果不是则拒绝访问。

Nginx对应用户认证这块是通过ngx_http_auth_basic_module模块来实现的，它允许通过使用"HTTP基本身份验证"协议验证用户名和密码来限制对资源的访问。默认情况下nginx是已经安装了该模块，如果不需要则使用--without-http_auth_basic_module。

该模块的指令比较简单，

（1）auth_basic:使用“ HTTP基本认证”协议启用用户名和密码的验证

| 语法   | auth_basic string\|off;           |
| ------ | --------------------------------- |
| 默认值 | auth_basic off;                   |
| 位置   | http,server,location,limit_except |

开启后，服务端会返回401，指定的字符串会返回到客户端，给用户以提示信息，但是不同的浏览器对内容的展示不一致。

（2）auth_basic_user_file:指定用户名和密码所在文件

| 语法   | auth_basic_user_file file;        |
| ------ | --------------------------------- |
| 默认值 | —                                 |
| 位置   | http,server,location,limit_except |

指定文件路径，该文件中的用户名和密码的设置，密码需要进行加密。可以采用工具自动生成

实现步骤:

1.nginx.conf添加如下内容

```apl
location /download{
    root /usr/local;
    autoindex on;
    autoindex_exact_size on;
    autoindex_format html;
    autoindex_localtime on;
    # 中文乱码解决
    charset 'utf-8';
    auth_basic 'please input your auth';
    # 注意路径要和下面的路径相同，不然要修改路径
    auth_basic_user_file htpasswd;
}
```

2.我们需要使用`htpasswd`工具生成

```apl
yum install -y httpd-tools
```

```apl
# 创建一个新文件记录用户名和密码，需要输入两次确认密码
htpasswd -c /usr/local/nginx/conf/htpasswd username 
htpasswd -b /usr/local/nginx/conf/htpasswd username password # 在指定文件新增一个用户名和密码
htpasswd -D /usr/local/nginx/conf/htpasswd username # 从指定文件删除一个用户信息
htpasswd -v /usr/local/nginx/conf/htpasswd username # 验证用户名和密码是否正确
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206201908865.png" alt="image-20220620190833740" style="zoom: 67%;" />

进行访问：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206201909117.png" alt="image-20220620190925040" style="zoom:67%;" />

输入上面设置的账号密码即可进入

> 上述方式虽然能实现用户名和密码的验证，但是大家也看到了，所有的用户名和密码信息都记录在文件里面，如果用户量过大的话，这种方式就显得有点麻烦了，这时候我们就得通过后台业务代码来进行用户权限的校验了。

# 服务器购买和部署⭐

## 域名配置 & 购买

### 本机配置

> hosts是一个没有扩展名的系统文件，可以用记事本等工具打开，其作用就是将一些常用的网址域名与其对应的IP地址建立一个关联“数据库”，当用户在浏览器中输入一个需要登录的网址时，系统会首先自动从hosts文件中寻找对应的IP地址，一旦找到，系统会立即打开对应网页，如果没有找到，则系统会再将网址提交DNS域名解析服务器进行IP地址的解析

```sh
windows:C:\Windows\System32\drivers\etc
centos：/etc/hosts
```

> 因为域名是要收取一定的费用，所以我们可以使用修改hosts文件来制作一些虚拟域名来使用。需要修改 `/etc/hosts`文件来添加

```sh
vim /etc/hosts
127.0.0.1 www.itcast.cn
127.0.0.1 www.itheima.cn
```

注意：只能在本机上进行访问

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204281618850.png" alt="image-20220428161815769" style="zoom:67%;" />

### 公网域名

> 阿里云域名购买：https://wanwang.aliyun.com/domain/searchresult/#/?keyword=renshuo&suffix=online
>
> 域名https://wanwang.aliyun.com/domain/1yuan?spm=5176.20907348.J_6123355440.3.2b80538aYwOvhz
>
> 注意挑选域名，有很多首年免费的

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.11.17/image-20230801172015850.png" alt="image-20230801172015850" style="zoom:80%;" />

> 个人信息模版：要审核成功才能购买，点击上面自动跳转到信息填写页，填写完成就是下面

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.11.17/image-20230801172123115.png" alt="image-20230801172123115" style="zoom:67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.11.17/image-20230801195645143.png" alt="image-20230801195645143" style="zoom:80%;" />

> 注意：配置完成要重启一下IP，然后等一会再测试，还需要配置下面服务器的安全组才行

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.11.17/image-20230801201826201.png" alt="image-20230801201826201" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.11.17/image-20230801201715903.png" alt="image-20230801201715903" style="zoom:80%;" />



```apl
ping www.renshuo.xyz
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.11.17/image-20230801201617110.png" alt="image-20230801201617110" style="zoom:80%;" />

## 买服务器

> 因为个人的工作经历，选择了阿里云服务器，我们直接买个云服务器 ECS，所谓 ECS 服务器，直接引用官方的介绍：云服务器ECS（Elastic Compute Service）是一种简单高效、处理能力可弹性伸缩的计算服务。帮助您构建更稳定、安全的应用，提升运维效率，降低IT成本，使您更专注于核心业务创新。

> 为了简单起见，**直接一键购买**

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202210022154693.png" alt="image-20221002215454567" style="zoom:67%;" />

> 地域、镜像、网络类型等我直接选择了默认。考虑到一开始也没有什么人访问，网站完全是静态的，即便买了，以后还可以升降配置，**实例规格**我选择了 `1 vCPU 1 GiB` 。



### 公网带宽

#### 付费方式

在**公网带宽**这里，有两种付费方式，一种是按固定带宽，一种是按使用流量。

> 所谓按固定带宽，先付费后使用，如果用户选择 10M 带宽，阿里云就会划分 10M 独享带宽给用户，官方建议适用于业务场景对于网络带宽要求比较稳定的客户，也就是说你的页面流量比较稳定，选择固定带宽会更合适一些。

> 而所谓按使用流量，先使用后付费，根据具体使用的流量计费，每小时扣费，官方建议适用于业务场景对网络带宽需求变化较大的场景，如平时带宽使用较低但间歇性的出现网络访问高峰的场景。

#### 带宽选择

> 如果你使用固定带宽模式，那么选择多少带宽是合适的呢，我们不妨大致的算一下：

> 所谓网络带宽是指在单位时间（一般指的是1秒钟）内能传输的数据量。网络和高速公路类似，带宽越大，就类似高速公路的车道越多，其通行能力越强，简单的来说，带宽越大，网站的访问速度越快。

> 而 `1M` 带宽对应的下载峰值就是 `128KB/S`，这是因为云厂商提供的云服务器带宽的单位是 `bit`（比特），我们通常说的 `1M` 完整写法其实是 `1Mb/s`，注意这其中的 `b` 是小写的。而用户下载速度使用的单位是 `Byte`（字节），`1Byte`（字节）= `8bit`（比特），所以 `1Mb = 1/8MB = 0.125MB`，我们知道 `1MB = 1024KB`，所以 `1Mb = 0.125MB = 128KB`，当然你也可以这样换算：

> 1Mbit/s = 1024kbit/s = 1024/8(KByte/s) = 128(KByte/s)

> 总之带宽是下载速度的 8 倍，1M 带宽对应下载速度是 128KB/s，2M 对应 256KB/s，4M 对应 512KB/s，依此类推。那我们的页面的资源大小是多少呢？我们可以在浏览器的 `NetWorks` 选项中查看页面的总资源大小，这里以我搭建的 **TypeScript 学习站点**[5]为例，打开开发工具查看：

![图片](https://mmbiz.qpic.cn/mmbiz_png/UfCRfwFgbJ2eFI1QicvDYY3Yo9B8KtY67DRhciadhia9AJEdKhrssroKbSk9oX9otLichGTmeDn4MY06XKjb8qp5bw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

> 我们可以看到已传输的资源大小为 `443kB`，所选资源大小为 `852kB`，之所以会有差别，是因为服务器和浏览器传输的数据是可以被压缩的，就比如 gzip 压缩。

> 当客户端和服务端握手的时候，客户端会告诉服务端是否支持压缩，如果服务端开启了压缩，且客户端支持压缩，便会将压缩后的数据传输过去，客户端再进行解压操作，我们可以在 `headers` 的 `content-encoding` 中查看压缩方式：

![图片](https://mmbiz.qpic.cn/mmbiz_png/UfCRfwFgbJ2eFI1QicvDYY3Yo9B8KtY67ZIA5X3ZVDlGNLlxyTzOib8KZtsOT6q19MN6qI0jUqibzl8V5A2IAxHfQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

> 那这里实际传输的大小，就是 `443kB`，如果我们希望用户能够在 1s 之内就打开我们的网站，我们至少需要 `443 / 128 = 3.46` M 的带宽，当然这样算，非常的粗糙，用户的带宽、CDN 优化等等都没有考虑进去，所以就是这么随便一算，如果优化做的好，即便只有 1M 带宽，也可以带来不错的效果。

如果我们 4M 的固定带宽买 1 个月，这里给的价格是 155.60 元。

> 但如果我们使用按流量付费，如果 4M 每秒都跑满（每秒都有很多人访问），总共的流量为：4 * 128KB/S * 86400 = 11059200KB = 42.1875GB，按照￥0.800/GB 的价格算，每天是大概是 33 元，一个月大概是 1000 元左右，这也就是为什么，如果你的流量比较稳定，会建议使用固定带宽。

> 那我们再算一个例子，如果我的网站每天有 1000 PV，假设他们打开了首页就撤了，大概产生的流量为 `1000 * 443KB = 0.42GB`，每天的费用为 3 毛钱，一个月大概是 9 元。考虑刚开始也没有什么流量，这里我选择了按使用流量计费，并设置了最大网络带宽为 25M，之所以设置最大网络带宽，是考虑到突然爆发的流量产生较高的费用，我们指定容许的最大网络带宽进行一点限制。

### 重置实例密码

> 如果是一键购买，我们应该会看到这样一则提示：

![图片](https://mmbiz.qpic.cn/mmbiz_png/UfCRfwFgbJ2eFI1QicvDYY3Yo9B8KtY67HAPdX4IGibZgPyISt1YDE6VmBp6jZCgpU2YnSXanO99qoT9fiaA0yl0Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

> 在购买后，我们根据这个页面**https://help.aliyun.com/document_detail/25439.html**[6] 的操作示例，重置一下密码，否则我们无法登陆服务器。

### 配置安全组

> 我们知道，当我们使用 HTTP 协议访问网站的时候，默认监听的是 80 端口，但阿里云服务器默认关闭 80 端口，为了能支持 HTTP 访问，我们登陆云服务器 ECS 管理后台，选择安全组，再点击第一个安全组：

![图片](https://mmbiz.qpic.cn/mmbiz_png/UfCRfwFgbJ2eFI1QicvDYY3Yo9B8KtY671Dx1PBA452vTQRIe9xApQ2wPySApHWrRH5CzDCbrQzYY86qTyGxEGQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

> 点击`手动添加`，添加 80 、443、23端口，添加完的效果如下：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.11.17/image-20230801201023254.png" alt="image-20230801201023254" style="zoom:80%;" />

## 应用安装

> 自动安装官网：https://oneinstack.com/

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.11.17/image-20230801202136693.png" alt="image-20230801202136693" style="zoom:80%;" />

> 安装命令：得安装好久

```
wget -c http://mirrors.linuxeye.com/oneinstack-full.tar.gz && tar xzf oneinstack-full.tar.gz && ./oneinstack/install.sh --nginx_option 1 --php_option 9 --phpcache_option 1 --db_option 2 --dbinstallmethod 1 --dbrootpwd 315217 --reboot 
```

> 安装完成后文件夹目录

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.11.17/image-20230801222000129.png" alt="image-20230801222000129" style="zoom:80%;" />



## SSL证书

> 证书官网：[SSL证书](https://yundun.console.aliyun.com/?spm=0.2020520163.products-recent.dcas.4d41799d1wawKx&p=cas#/certExtend/free/cn-hangzhou)

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.11.17/image-20230801223245202.png" alt="image-20230801223245202" style="zoom:67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.11.17/image-20230801223428141.png" alt="image-20230801223428141" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.11.17/image-20230801223546394.png" alt="image-20230801223546394" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.11.17/image-20230801223606064.png" alt="image-20230801223606064" style="zoom: 80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.11.17/image-20230801223645591.png" alt="image-20230801223645591" style="zoom:80%;" />



<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.11.17/image-20230801223738722.png" alt="image-20230801223738722" style="zoom:80%;" />



> 将下面的两个文件复制到nginx的conf文件中

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.11.17/image-20230801223949123.png" alt="image-20230801223949123" style="zoom:80%;" />



## CA签名

> 下载地址：https://www.hohnstaedt.de/xca/index.php/download







# 可视化配置

[还在手撸 Nginx 配置？试试这款可视化配置工具吧，真心强大！ (qq.com)](https://mp.weixin.qq.com/s?__biz=MzU1Nzg4NjgyMw==&mid=2247499315&idx=1&sn=4ae8c55c415ab2ed844c8e2a706bc459&chksm=fc2c423bcb5bcb2da2af884d6d0a0759e1a9353851c72cd6dabd49f8501f717710eb854e8a72&mpshare=1&scene=23&srcid=0723UxY0M9AxOffTEmjC2zB0&sharer_sharetime=1658554673231&sharer_shareid=29b8a04db1dbd975e3bf4e9f47e7ac67#rd)

[NGINXConfig | DigitalOcean](https://www.digitalocean.com/community/tools/nginx?domains.0.routing.index=index.html&domains.0.routing.fallbackHtml=true&global.app.lang=zhCN)：能自动生成nginx配置文件内容



# 前后端项目部署 ⭐

## 部署前端项目

### 背景

- **Nginx**可以作为静态web服务器来部署静态资源**。静态资源**指在服务端真实存在并且能够直接展示的一些文件，比如常见的html页面、css文件、js文件、图片、视频等资源。

- 相对于Tomcat，Nginx处理静态资源的能力更加高效，所以在生产环境下，一般都会将静态资源部署到Nginx中。

- 将静态资源部署到Nginx非常简单，只需要将文件复制到Nginx安装目录下的html目录中即可。

### 实战

[Vue3 项目打包 | 菜鸟教程 (runoob.com)](https://www.runoob.com/vue3/vue3-build.html)

在vue.config.js中加入如下代码即可，最下面那个

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206211843273.png" alt="image-20220621184341109" style="zoom:67%;" />

```apl
module.exports = {
  publicPath: './'
}
```

再进行打包，显示图片成功，生成dist目录

```apl
npm run build
```

将dist目录拷贝到nginx和html同级目录下

编写配置文件：就是复制一份server改一改

[(42条消息) vue项目用nginx部署完成界面刷新404_元气满满ya~的博客-CSDN博客_nginx部署vue项目刷新404](https://blog.csdn.net/m0_65376942/article/details/123922663)

方式一

```apl
server {
   listen       8089;
   server_name  localhost;
   location / {
       root   dist;
       index  index.html index.htm;
       # 这条命令是避免刷新404的
       try_files $uri $uri/ /index.html;
   }
   error_page   500 502 503 504  /50x.html;
       location = /50x.html {
       root   html;
   }
}
```

方式二

```apl
server {
   listen       8089;
   server_name  localhost;
   location / {
       root   dist;
       index  index.html index.htm;
       # 这条命令是避免刷新404的
       try_files $uri $uri/ /index.html;
   }
   
   # 拦截静态资源请求,缓存，压缩
   location ~/.*\.(png|jpg|gif|js|css){
         root dist;
         expires 30d;
         add_header Pragma public;
         add_header Cache-Control "public";
         gzip on;
   }

   error_page   500 502 503 504  /50x.html;
       location = /50x.html {
       root   html;
   }
}
```

```apl
systemctl restart nginx.service
```

进行访问：成功显示页面

```apl
http://192.168.220.130:8089/
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206231412018.png" alt="image-20220623141210888" style="zoom:67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206211857770.png" alt="image-20220621185717577" style="zoom:50%;" />



## 部署后台项目

注意点：mysql地址，静态资源保存位置

首先要打包成jar包

然后上传到centos7里，执行进行启动项目

```apl
java -jar reggie_take_out-1.0-SNAPSHOT.jar
```

然后修改nginx.conf

```apl
server {
  listen       8088;
  server_name  localhost;
  location / {
      proxy_pass :8080; 
  }
}
```

```apl
systemctl restart nginx.service
```

进行访问

http://192.168.220.130:8088/backend/page/login/login.html

