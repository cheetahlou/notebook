

# 日志⭐⭐

日志是mysql数据库的重要组成部分，记录着数据库运行期间各种状态信息。mysql日志主要包括错误日志、查询日志、慢查询日志、事务日志、二进制日志几大类。作为开发，我们重点需要关注的是二进制日志(binlog)和事务日志(包括redo log和undo log)，本文接下来会详细介绍这三种日志。

## 错误日志

> 错误日志是 MySQL 中最重要的日志之一，**它记录了当 mysqld 启动和停止时，以及服务器在运行过程中发生任何严重错误时的相关信息**。**当数据库出现任何故障导致无法正常使用时，建议首先查看此日志**。
>

默认情况下，该日志功能是开启的，通过如下命令查找错误日志文件的存放路径。

> 该日志是默认开启的，默认存放目录 /var/log/，默认的日志文件名为 mysqld.log 
>

```mysql
show variables like '%log_error%';
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202209221927339.png" alt="image-20220922192758261" style="zoom:80%;" />

> **注意**：错误日志中记录的可并非全是错误信息，像 MySQL 如何启动 `InnoDB` 的表空间文件、如何初始化自己的存储引擎，初始化 `buffer pool` 等等，这些也记录在错误日志文件中。

```apl
tail -f mysqld.log
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202209221953596.png" alt="image-20220922195352467" style="zoom:80%;" />

## 二进制日志⭐

> binlog**用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中**。**binlog是mysql的逻辑日志，并且由Server层进行记录，使用任何存储引擎的mysql数据库都会记录binlog日志**。

> - 逻辑日志：可以简单理解为记录的就是sql语句。
> - 物理日志：因为mysql数据最终是保存在数据页中的，物理日志记录的就是数据页变更。

> binlog是通过追加的方式进行写入的，可以通过max_binlog_size参数设置每个binlog文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。

### binlog 使用场景

在实际应用中，binlog的主要使用场景有两个，分别是主从复制和数据恢复。

> - 主从复制：**在Master端开启binlog，然后将binlog发送到各个Slave端，Slave端重放binlog达到主从数据一致**
> - 数据恢复：**通过使用mysqlbinlog工具来恢复数据**。

### binlog刷盘时机

> 对于InnoDB存储引擎而言，只有在事务提交时才会记录biglog，此时记录还在内存中，那么biglog是什么时候刷到磁盘中的呢？mysql通过sync_binlog参数控制biglog的刷盘时机，取值范围是0-N：

> - 0：不去强制要求，由系统自行判断何时写入磁盘；
> - 1：每次commit的时候都要将binlog写入磁盘；
> - N：每N个事务，才会将binlog写入磁盘。

> 从上面可以看出，sync_binlog最安全的是设置是1，这也是MySQL 5.7.7之后版本的默认值。但是设置一个大一些的值可以提升数据库性能，因此实际情况下也可以将值适当调大，牺牲一定的一致性来获取更好的性能。

### 开启二进制日志

> 在MySQL8版本中，默认二进制日志是开启着的，以下是mysql5.7配置开启

```mysql
server-id=202
log-bin=mysql-bin
binlog-ignore-db = mysql,information_schema
```

加入后，重启mysql服务，查看是否开启

```mysql
show variables like '%log_bin%';
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202209221955877.png" alt="image-20220922195508824" style="zoom:80%;" />

进入/var/lib/mysql目录查看

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202209221956080.png" alt="image-20220922195607997" style="zoom:80%;" />



### binlog日志格式⭐

binlog日志有三种格式，分别为 STATMENT、ROW和MIXED。

> 在 MySQL 5.7.7之前，默认的格式是STATEMENT，MySQL 5.7.7之后，默认值是ROW。通过binlog-format指定格式

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202209221957855.png" alt="image-20220922195734784" style="zoom:80%;" />

#### STATEMENT 模式

> 内容：binlog 只会记录可能引起数据变更的 sql 语句，对数据进行修改的SQL都会记录在日志文件中
>
> 优势：该模式下，因为没有记录实际的数据，所以日志量和 IO 都消耗很低，性能是最优的
>
> 劣势：但有些操作并不是确定的，比如 uuid() 函数会随机产生唯一标识，当依赖 binlog 回放时，该操作生成的数据与原数据必然是不同的，此时可能造成无法预料的后果。

#### ROW 模式

> 内容：基于行的日志记录，binlog 会**记录每次操作的源数据与修改后的目标数据**，默认就是该模式
>
> 优势：**可以绝对精准的还原，从而保证了数据的安全与可靠，并且复制和数据恢复过程可以是并发进行的**
>
> 劣势：**缺点在于 binlog 体积会非常大，同时，对于修改记录多、字段长度大的操作来说，记录时性能消耗会很严重。阅读的时候也需要特殊指令来进行读取数据**。**会产生大量的日志，尤其是alter table的时候会让日志暴涨**

#### MIXED 模式

> 内容：是对上述STATEMENT 跟 ROW  两种模式的混合使用。
>
> 细节：对于绝大部分操作，都使用 STATEMENT 来进行 binlog 的记录，只有以下操作使用 ROW 来实现：表的存储引擎为 NDB，使用了uuid() 等不确定函数，使用了 insert delay 语句，使用了临时表

#### binlog格式查看 & 修改

##### 查看日志格式

```mysql
show variables like '%binlog_format%';
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202209221958233.png" alt="image-20220922195808183" style="zoom:80%;" />

##### 修改日志格式

```ini
binlog_format=STATEMENT
```

```apl
systemctl restart mysqld
```

重启服务，再次查询format，可以发现已经由ROW改成STATEMENT

### binlog日志操作⭐

#### 日志查看

```sql
show binary logs;
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202209222004335.png" alt="image-20220922200458281" style="zoom:80%;" />

由于日志是以二进制方式存储的，**不能直接读取**，需要通过二进制日志查询工具 mysqlbinlog 来查看

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img/image-20220205120832788.png" alt="image-20220205120832788" style="zoom:80%;" />

```sh
cd /var/lib/mysql
mysqlbinlog -v  mysql-bin.000036
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202209222001547.png" alt="image-20220922200126439" style="zoom:80%;" />

#### 日志删除

##### 手动删除

对于比较繁忙的业务系统，每天生成的binlog数据巨大，如果长时间不清除，将会占用大量磁盘空间。

可以通过以下几种方式清理日志：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img/image-20220205120915414.png" alt="image-20220205120915414" style="zoom:80%;" />

```mysql
-- 删除它编号之前的日志(不包含它本身)
purge master logs to 'mysql-bin.000037';
-- 删除全部
reset master ;
```

再次查看

```sql
show binary logs;
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202209222009318.png" alt="image-20220922200910265" style="zoom:80%;" />

##### 自动删除

> 也可以在mysql的配置文件中配置二进制日志的过期时间，设置了之后，二进制日志过期会自动删除。一般来说开启bin log都会给日志文件设置过期时间（默认永久保存），要不然日志的体量会非常庞大。
>

```ini
# 修改它就能决定二进制日志的保存时间，0表示不删除，604800表示3600*24*7，7天时间
binlog_expire_logs_seconds=604800
```

重启服务后，查询

```apl
systemctl restart mysqld
```

```mysql
show variables like '%binlog_expire_logs_seconds%';
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202209222014969.png" alt="image-20220922201408917" style="zoom:80%;" />



## 查询日志

> 一般查询日志（general query log）：用来记录用户的**所有**操作，包括客户端何时连接了服务器、客户端发送的所有SQL以及其他事件，比如 MySQL服务启动和关闭等等。MySQL服务器会按照它接收到语句的先后顺序写入日志文件。由于一般查询日志记录的内容过于详细，开启后 Log 文件的体量会非常庞大，所以出于对性能的考虑，默认情况下，该日志功能是关闭的，通常会在排查故障需获得详细日志的时候才会临时开启。
>

我们可以通过以下命令查看一般查询日志是否开启，命令如下：

```sql
show variables like 'general_log';
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202209222015381.png" alt="image-20220922201517332" style="zoom:80%;" />

下边开启一般查询日志并查看日志存放的位置。

```ini
# 该选项用来开启查询日志,可选值0和1；0代表关闭，1代表开启
general_log=1
# 设置日志的文件名,如果没有指定,默认的文件名为host_name.log
general_log_file=mysql_query.log
```

重启服务，进行查询看是否开启

```mysql
systemctl restart mysqld
show variables like '%general%';
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img/image-20220205122545081.png" alt="image-20220205122545081" style="zoom:80%;" />

生成文件位置：/var/lib/mysql

```apl
tail -f mysql_query.log 
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202209222024518.png" alt="image-20220922202440431" style="zoom:80%;" />

> 开启了查询日志之后，在MySQL的数据存放目录，也就是 /var/lib/mysql/ 目录下就会出现mysql_query.log 文件。
>
> 之后所有的客户端的增删改查操作都会记录在该日志文件之中，长时间运行后，该日志文件将会非常大。

## 慢查询日志

> 慢查询日志（**`slow query log`**）: 用来记录在 MySQL 中执行时间超过指定时间的查询语句，在 SQL 优化过程中会经常使用到。通过慢查询日志，我们可以查找出哪些查询语句的执行效率低，耗时严重。
>

> 出于性能方面的考虑，一般只有在排查慢SQL、调试参数时才会开启，默认情况下，慢查询日志功能是关闭的。可以通过以下命令查看是否开启慢查询日志：
>

> 慢查询日志记录了所有执行时间超过参数 long_query_time 设置值并且扫描记录数不小min_examined_row_limit的所有的SQL语句的日志，默认未开启。long_query_time 默认为 10 秒，最小为 0， 精度可以到微秒。
>

```sql
show variables like '%slow_query%';
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202209221946189.png" alt="image-20220922194652140" style="zoom:80%;" />

在my.cnf中开启慢日志

```ini
slow-query-log=1
slow_query_log_file="slow.log"
# 默认慢查询日志为10s，这里改小，方便测试
long_query_time=0.00001
```

上边提到超过 `指定时间` 的查询语句才算是慢查询，那么这个时间阈值又是多少嘞？我们通过 `long_query_time` 参数来查看一下，发现默认是 10 秒。

> 慢查询日志目录：/var/lib/mysql

```apl
tail -f /var/lib/mysql/slow.log
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202209222034518.png" alt="image-20220922203410446" style="zoom:80%;" />

> 默认情况下，不会记录管理语句，也不会记录不使用索引进行查找的查询。可以使用log_slow_admin_statements和 更改此行为 log_queries_not_using_indexes，如下所述。
>

```ini
# 记录执行较慢的管理语句
log_slow_admin_statements=1
# 记录执行较慢的未使用索引的语句
log_queries_not_using_indexes=1
```

> 上述所有的参数配置完成之后，都需要重新启动MySQL服务器才可以生效。

## 注意事项

### 修改日志时区

> 默认 UTC 这样会导致日志中记录的时间比中国这边的慢，导致查看日志不方便。修改为 SYSTEM 就能解决问题

```sql
show variables like '%log_timestamps%'
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202209221936725.png" alt="image-20220922193641672" style="zoom:80%;" />

```ini
# 在my.ini中写入如下，跟随系统时间，重启服务，即可发现时间正确
log_timestamps=SYSTEM
```

```apl
systemctl restart mysqld
```

### redo log与binlog区别

> 由binlog和redo log的区别可知：binlog日志只用于归档，只依靠binlog是没有crash-safe能力的。但只有redo log也不行，因为redo log是InnoDB特有的，且日志上的记录落盘后会被覆盖掉。因此需要binlog和redo log二者同时记录，才能保证当数据库发生宕机重启时，数据不会丢失。
>

# 配置文件

[MySQL 配置文件 my.cnf / my.ini 逐行详解-阿里云开发者社区 (aliyun.com)](https://developer.aliyun.com/article/822935)

> Windows 和 Linux 下的 MySQL 配置文件的名字和存放位置都是不同的，WIndows 下 MySQL 配置文件是 `my.ini` 存放在 MySQL 安装目录的根目录下；Linux 下 MySQL 配置文件是 `my.cnf` 存放在 `/etc/my.cnf`、`/etc/mysql/my.cnf`。我们也可以通过 `find` 命令进行查找。

> 另外要注意的是，通过 rpm 命令安装的 MySQL 是没有 `/etc/my.cnf` 文件的，如果需要配置 MySQL，可以在`/etc/my.cnf`新建配置文件，然后把本文的配置信息复制到文件中即可。

```sh
# 查看配置文件位置
mysql --help | grep 'cnf'
```

## [client]

> 在MySQL的配置文件my.cnf中，[client]部分是用于配置客户端连接MySQL服务器的参数，[mysqld]部分则是用于配置MySQL服务器本身的参数。

> 在[client]部分中，port参数指定了客户端连接MySQL服务器使用的端口号，即连接MySQL服务器的网络端口号。这个端口号通常是3306。

> 在[mysqld]部分中，port参数指定了MySQL服务器监听的端口号，即MySQL服务器绑定的网络端口号。当客户端需要连接MySQL服务器时，就会使用这个端口号来连接。可以通过修改这个参数来更改MySQL服务器监听的端口号。

> 因此，这两个port参数虽然名字相同，但是含义不同，分别用于配置客户端连接MySQL服务器的端口号和MySQL服务器监听的端口号。

客户端设置。当前为客户端默认参数

```sh
port = 3306
```

默认连接端口为 `3306`

```sh
socket = /tmp/mysql.sock
```

本地连接的 `socket` 套接字

```sh
default_character_set = utf8
```

设置字符集，通常使用 `uft8` 即可

## [mysqld_safe]

`mysqld_safe` 是服务器端工具，用于启动 `mysqld`，也是 `mysqld` 的守护进程。当 mysql 被 kill 时，`mysqld_safe` 负责重启启动它。

```sh
open_files_limit = 8192
```

此为 MySQL 打开的文件描述符限制，它是 MySQL 中的一个全局变量且不可动态修改。它控制着 mysqld 进程能使用的最大文件描述符数量。默认最小值为 1024

需要注意的是这个变量的值并不一定是你在这里设置的值，mysqld 会在系统允许的情况下尽量取最大值。

当 `open_files_limit` 没有被配置时，比较 `max_connections*5` 和 `ulimit -n` 的值，取最大值

当 `open_file_limit` 被配置时，比较 `open_files_limit` 和 `max_connections*5` 的值，取最大值

```sh
user = mysql
```

用户名，错误 log 记录文件

```
log-error  = error.log
```

## [mysqld]

服务端基本配置

```
port = 3306
```

mysqld 服务端监听端口

```
socket = /tmp/mysql.sock
```

MySQL 客户端程序和服务器之间的本地通讯指定一个套接字文件

```
max_allowed_packet  = 16M
```

允许最大接收数据包的大小，防止服务器发送过大的数据包。

当发出长查询或 mysqld 返回较大结果时，mysqld 才会分配内存，所以增大这个值风险不大，默认 16M，也可以根据需求改大，但太大会有溢出风险。取较小值是一种安全措施，避免偶然出现但大数据包导致内存溢出。

```
default_storage_engine = InnoDB 
```

创建数据表时，默认使用的存储引擎。这个变量还可以通过 `–default-table-type` 进行设置

```
max_connections  = 512
```

最大连接数，当前服务器允许多少并发连接。默认为 100，一般设置为小于 1000 即可。太高会导致内存占用过多，MySQL 服务器会卡死。作为参考，小型站设置 100 - 300

```
max_user_connections = 50
```

用户最大的连接数，默认值为 50 一般使用默认即可。

```
thread_cache_size = 64
```

线程缓存，用于缓存空闲的线程。这个数表示可重新使用保存在缓存中的线程数，当对方断开连接时，如果缓存还有空间，那么客户端的线程就会被放到缓存中，以便提高系统性能。我们可根据物理内存来对这个值进行设置，对应规则 1G 为 8；2G 为 16；3G 为 32；4G 为 64 等。

## 核心参数

```properties
innodb_buffer_pool 
# 注：缓冲池位于主内存中，InnoDB用它来缓存被访问过的表和索引文件，使常用数据可以直接在内存中被处理，从而提升处理速度；
innodb_buffer_pool_instance
# 注：MySQL5.6.6之后可以调整为多个。表示InnoDB缓冲区可以被划分为多个区域，也可以理解为把innodb_buffer_pool划分为多个实例，可以提高并发性，避免在高并发环境下，出现内存的争用问题；
innodb_data_file_path
# 注：该参数可以指定系统表空间文件的路径和ibdata1文件的大小。默认大小是10MB，这里建议调整为1GB
transaction_isolation
# 注：MySQL数据库的事务隔离级别有四种，分别为READ-UNCOMMITTED、READ-COMMITTED、REPEATABLE-READ和SERIALIZABLE。默认采用REPEATABLE-READ（可重复读）
innodb_log_buffer_size
# 注：是日志缓冲的大小，InnoDB改变数据的时候，它会把这次改动的记录先写到日志缓冲中
innodb_log_file_size
# 注：是指Redo log日志的大小，该值设置不宜过大也不宜过小，如果设置太大，实例恢复的时候需要较长时间，如果设置太小，会造成redo log 切换频繁，产生无用的I/O消耗，影响数据库性能
innodb_log_files_in_group
# 注：redo log文件组中日志文件的数量，默认情况下至少有2个
max_connections
# 该参数代表MySQL数据库的最大连接数
expire_logs_days
# 注：该参数代表binlog的过期时间，单位是天
slow_query_log
# 注：慢查询日志的开关，该参数等于1代表开启慢查询
long_query_time
# 注：慢查询的时间，某条SQL语句超过该参数设置的时间，就会记录到慢查询日志中。单位是秒
binlog_format
# 注：该参数代表二进制日志的格式。binlog格式有三种statement、row和mixed。生产环境中使用row这种格式更安全，不会出现跨库复制丢数据的情况
lower_case_table_names
# 注：表名是否区分大小的参数。默认是值为0。0代表区分大小写，1代表不区分大小写，以小写存储
interactive_timeout
# 注：是服务器关闭交互式连接前等待活动的时间,默认是28800s（8小时）
wait_timeout
# 注：是服务器关闭非交互式连接之前等待活动的时间，默认是28800s（8小时）
innodb_flush_method
# 注：这个参数影响InnoDB数据文件，redo log文件的打开刷写模式
log_queries_not_using_indexes
# 注：如果运行的SQL语句没有使用索引，则MySQL数据库同样会将这条SQL语句记录到慢查询日志文件中
```

## 配置文件优化

```properties

###########################################################################
## my.cnf for MySQL 8.0.x                                                  
## 本配置参考  https://imysql.com/my-cnf-wizard.html                         
## 注意：                                                                   
##   (1)本配置假设物理服务器内存为 16G，总表数量在300之内，中小型企业业务          
##   (2)请根据实际情况作调整部分参数                                          
##   (3)本人不对这些建议结果负相应责任 ，仅作参考                             
###########################################################################

###########################################################################
##客户端参数配置
###########################################################################
[client]
port	= 3306
socket	=/var/lib/mysql/mysqld.sock

[mysql]
#prompt="\u@mysqldb \R:\m:\s [\d]> "
#关闭自动补全sql命令功能
no-auto-rehash

###########################################################################
##服务端参数配置
###########################################################################
[mysqld]
port	= 3306
datadir	= /var/lib/mysql
socket	= /var/lib/mysql/mysqld.sock
log-error = /var/lib/mysql/error.log
pid-file = /var/lib/mysql/mysqld.pid

#只能用IP地址检查客户端的登录，不用主机名
skip_name_resolve = 1

#若你的MySQL数据库主要运行在境外，请务必根据实际情况调整本参数
default_time_zone = "+8:00"

#数据库默认字符集, 主流字符集支持一些特殊表情符号（特殊表情符占用4个字节）
character-set-server = utf8mb4

#数据库字符集对应一些排序等规则，注意要和character-set-server对应
collation-server = utf8mb4_general_ci

#设置client连接mysql时的字符集,防止乱码
init_connect='SET NAMES utf8mb4'

#是否对sql语句大小写敏感，1表示不敏感
lower_case_table_names = 1

# 执行sql的模式，规定了sql的安全等级, 暂时屏蔽，my.cnf文件中配置报错
#sql_mode = STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION

#事务隔离级别，默认为可重复读，mysql默认可重复读级别（此级别下可能参数很多间隙锁，影响性能）
transaction_isolation = READ-COMMITTED

#TIMESTAMP如果没有显示声明NOT NULL，允许NULL值
explicit_defaults_for_timestamp = true

#它控制着mysqld进程能使用的最大文件描述(FD)符数量。
#需要注意的是这个变量的值并不一定是你设定的值，mysqld会在系统允许的情况下尽量获取更多的FD数量
open_files_limit    = 65535

#最大连接数
max_connections = 300

#最大错误连接数
max_connect_errors = 600

#在MySQL暂时停止响应新请求之前的短时间内多少个请求可以被存在堆栈中
#官方建议 back_log = 50 + (max_connections / 5),封顶数为65535,默认值= max_connections
back_log = 110

# The number of open tables for all threads
# For example, for 200 concurrent running connections, specify a table cache size of at least 200 * N, 
# where N is the maximum number of tables per join in any of the queries which you execute. 
table_open_cache = 600

# The number of table definitions that can be stored in the definition cache 
# MIN(400 + table_open_cache / 2, 2000)
table_definition_cache = 700

# 为了减少会话之间的争用，可以将opentables缓存划分为table_open_cache/table_open_cache_instances个小缓存
table_open_cache_instances = 64

# 每个线程的堆栈大小 如果线程堆栈太小，则会限制执行复杂SQL语句
thread_stack = 512K

# 禁止外部系统锁
external-locking = FALSE

#SQL数据包发送的大小，如果有BLOB对象建议修改成1G
max_allowed_packet = 128M

#order by 或group by 时用到
#建议先调整为4M，后期观察调整
sort_buffer_size = 4M

#inner left right join时用到
#建议先调整为4M，后期观察调整
join_buffer_size = 4M

# How many threads the server should cache for reuse.
# 如果您的服务器每秒达到数百个连接，则通常应将thread_cache_size设置得足够高，以便大多数新连接使用缓存线程
# default value = 8 + ( max_connections / 100) 上限为100
thread_cache_size = 20

#MySQL连接闲置超过一定时间后(单位：秒)将会被强行关闭
#MySQL默认的wait_timeout  值为8个小时, interactive_timeout参数需要同时配置才能生效
interactive_timeout = 1800
wait_timeout = 1800

#Metadata Lock最大时长（秒）， 一般用于控制 alter操作的最大时长sine mysql5.6
#执行 DML操作时除了增加innodb事务锁外还增加Metadata Lock，其他alter（DDL）session将阻塞
lock_wait_timeout = 3600

#内部内存临时表的最大值。
#比如大数据量的group by ,order by时可能用到临时表，
#超过了这个值将写入磁盘，系统IO压力增大
tmp_table_size = 64M
max_heap_table_size = 64M

#--###########################-- 慢SQL日志记录 开始 --##########################################

#是否启用慢查询日志，1为启用，0为禁用  
slow_query_log = 1

#记录系统时区
log_timestamps = SYSTEM

#指定慢查询日志文件的路径和名字
slow_query_log_file = /var/lib/mysql/slow.log

#慢查询执行的秒数，必须达到此值可被记录
long_query_time = 5

#将没有使用索引的语句记录到慢查询日志  
log_queries_not_using_indexes = 0

#设定每分钟记录到日志的未使用索引的语句数目，超过这个数目后只记录语句数量和花费的总时间  
log_throttle_queries_not_using_indexes = 60

#对于查询扫描行数小于此参数的SQL，将不会记录到慢查询日志中
min_examined_row_limit = 5000

#记录执行缓慢的管理SQL，如alter table,analyze table, check table, create index, drop index, optimize table, repair table等。  
log_slow_admin_statements = 0

#作为从库时生效, 从库复制中如何有慢sql也将被记录
#对于ROW格式binlog，不管执行时间有没有超过阈值，都不会写入到从库的慢查询日志
log_slow_slave_statements = 1

#--###########################-- 慢SQL日志记录 结束 --##########################################

#--###########################-- Bin-Log设置 开始 --############################################
server-id = 110

#开启bin log 功能
log-bin=mysql-bin

#binlog 记录内容的方式，记录被操作的每一行
binlog_format = ROW

#对于binlog_format = ROW模式时，FULL模式可以用于误操作后的flashBack。
#如果设置为MINIMAL，则会减少记录日志的内容，只记录受影响的列，但对于部分update无法flashBack
binlog_row_image = FULL

#bin log日志保存的天数
#如果 binlog_expire_logs_seconds 选项也存在则 expire_logs_days 选项无效
#expire_logs_days 已经被标注为过期参数
#expire_logs_days = 7
binlog_expire_logs_seconds = 1209600

#master status and connection information输出到表mysql.slave_master_info中
master_info_repository = TABLE

#the slave's position in the relay logs输出到表mysql.slave_relay_log_info中
relay_log_info_repository = TABLE

#作为从库时生效, 想进行级联复制，则需要此参数
log_slave_updates

#作为从库时生效, 中继日志relay-log可以自我修复
relay_log_recovery = 1

#作为从库时生效, 主从复制时忽略的错误
#如果在备份过程中执行ddl操作，从机需要从主机的备份恢复时可能会异常，从而导致从机同步数据失败
#如果对数据完整性要求不是很严格，那么这个选项确实可以减轻维护的成本
slave_skip_errors = ddl_exist_errors

#####RedoLog日志 和 binlog日志的写磁盘频率设置 BEGIN ###################################
# RedoLog日志（用于增删改事务操作） +  binlog日志（用于归档，主从复制）
# 为什么会有两份日志呢？ 
# 因为最开始MySQL没有 InnoDB 引擎,自带MyISAM引擎没有 crash-safe能力，binlog日志只用于归档
# InnoDB 引擎是另一个公司以插件形式引入MySQL的，采用RedoLog日志来实现 crash-safe 能力

# redo log 的写入（即事务操作）拆成两阶段提交（2PC）：prepare阶段 和 commit阶段
#(事务步骤1) 执行commit命令，InnoDB redo log 写盘，然后告知Mysql执行器:[你可以写binlog了，且一并提交事务]，事务进入 prepare 状态
#(事务步骤2) 如果前面 prepare 成功，Mysql执行器生成 binlog 并且将binlog日志写盘
#(事务步骤3) 如果binlog写盘成功，Mysql执行器一并调用InnoDB引擎的提交事务接口，事务进入 commit 状态，操作完成，事务结束

#参数设置成 1，每次事务都直接持久化到磁盘
#参数设置成 0，mysqld进程的崩溃会导致上一秒钟所有事务数据的丢失。
#参数设置成 2，只有在操作系统崩溃或者系统掉电的情况下，上一秒钟所有事务数据才可能丢失。
#即便都设置为1，服务崩溃或者服务器主机crash，Mysql也可能丢失但最多一个事务

#控制 redolog 写磁盘频率 默认为1
innodb_flush_log_at_trx_commit = 1

#控制 binlog 写磁盘频率
sync_binlog = 1

#####RedoLog日志 和 binlog日志的写磁盘频率设置 END #####################################

#一般数据库中没什么大的事务，设成1~2M，默认32kb
binlog_cache_size = 4M

#binlog 能够使用的最大cache 内存大小
max_binlog_cache_size = 2G

#单个binlog 文件大小 默认值是1GB
max_binlog_size = 1G

#开启GTID复制模式
gtid_mode = on

#强制gtid一致性，开启后对于create table ... select ...或 CREATE TEMPORARY TABLE 将不被支持
enforce_gtid_consistency = 1

#解决部分无主键表导致的从库复制延迟问题
#其基本思路是对于在一个ROWS EVENT中的所有前镜像收集起来，
#然后在一次扫描全表时，判断HASH中的每一条记录进行更新
#该参数已经被标注为过期参数
#slave-rows-search-algorithms = 'INDEX_SCAN,HASH_SCAN'

# default value is CRC32
#binlog_checksum = 1

# default value is ON
#relay-log-purge = 1

#--###########################-- Bin-Log设置 结束 --##########################################

#--###########################-- 可能用到的MyISAM性能设置 开始 --#############################

#对MyISAM表起作用，但是内部的临时磁盘表是MyISAM表，也要使用该值。
#可以使用检查状态值 created_tmp_disk_tables 得知详情
key_buffer_size = 15M

#对MyISAM表起作用，但是内部的临时磁盘表是MyISAM表，也要使用该值，
#例如大表order by、缓存嵌套查询、大容量插入分区。
read_buffer_size = 8M

#对MyISAM表起作用 读取优化
read_rnd_buffer_size = 4M

#对MyISAM表起作用 插入优化
bulk_insert_buffer_size = 64M
#--###########################-- 可能用到的MyISAM性能设置 开始 --################################

#--###########################-- innodb性能设置 开始 --##########################################
# Defines the maximum number of threads permitted inside of InnoDB. 
# A value of 0 (the default) is interpreted as infinite concurrency (no limit)
innodb_thread_concurrency = 0

#一般设置物理存储的 60% ~ 70%
innodb_buffer_pool_size = 8G

#当缓冲池大小大于1GB时，将innodb_buffer_pool_instances设置为大于1的值，可以提高繁忙服务器的可伸缩性
innodb_buffer_pool_instances = 4

#默认启用。指定在MySQL服务器启动时，InnoDB缓冲池通过加载之前保存的相同页面自动预热。 通常与innodb_buffer_pool_dump_at_shutdown结合使用
innodb_buffer_pool_load_at_startup = 1

#默认启用。指定在MySQL服务器关闭时是否记录在InnoDB缓冲池中缓存的页面，以便在下次重新启动时缩短预热过程
innodb_buffer_pool_dump_at_shutdown = 1

# Defines the name, size, and attributes of InnoDB system tablespace data files
innodb_data_file_path = ibdata1:1G:autoextend

#InnoDB用于写入磁盘日志文件的缓冲区大小（以字节为单位）。默认值为16MB
innodb_log_buffer_size = 32M

#InnoDB日志文件组数量
innodb_log_files_in_group = 3

#InnoDB日志文件组中每一个文件的大小
innodb_log_file_size = 2G

#是否开启在线回收（收缩）undo log日志文件，支持动态设置，默认开启
innodb_undo_log_truncate = 1

#当超过这个阀值（默认是1G），会触发truncate回收（收缩）动作，truncate后空间缩小到10M
innodb_max_undo_log_size = 4G

#The path where InnoDB creates undo tablespaces
#没有配置则在数据文件目录下
#innodb_undo_directory = /var/lib/mysql/undolog

#用于设定创建的undo表空间的个数
#已经弃用了，只能手动添加undo表空间
#The innodb_undo_tablespaces variable is deprecated and is no longer configurable as of MySQL 8.0.14
#innodb_undo_tablespaces = 95

#提高刷新脏页数量和合并插入数量，改善磁盘I/O处理能力
#根据您的服务器IOPS能力适当调整
#一般配普通SSD盘的话，可以调整到 10000 - 20000
#配置高端PCIe SSD卡的话，则可以调整的更高，比如 50000 - 80000
innodb_io_capacity = 4000
innodb_io_capacity_max = 8000

#如果打开参数innodb_flush_sync, checkpoint时，flush操作将由page cleaner线程来完成，此时page cleaner会忽略io capacity的限制，进入激烈刷脏
innodb_flush_sync = 0
innodb_flush_neighbors = 0

#CPU多核处理能力设置，假设CPU是4颗8核的，设置如下
#读多，写少可以设成 2:6的比例
innodb_write_io_threads = 8
innodb_read_io_threads = 8
innodb_purge_threads = 4
innodb_page_cleaners = 4
innodb_open_files = 65535
innodb_max_dirty_pages_pct = 50

#该参数针对unix、linux，window上直接注释该参数.默认值为 NULL
#O_DIRECT减少操作系统级别VFS的缓存和Innodb本身的buffer缓存之间的冲突
innodb_flush_method = O_DIRECT

innodb_lru_scan_depth = 4000
innodb_checksum_algorithm = crc32

#为了获取被锁定的资源最大等待时间，默认50秒，超过该时间会报如下错误:
# ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction
innodb_lock_wait_timeout = 20

#默认OFF，如果事务因为加锁超时，会回滚上一条语句执行的操作。如果设置ON，则整个事务都会回滚
innodb_rollback_on_timeout = 1

#强所有发生的死锁错误信息记录到 error.log中，之前通过命令行只能查看最近一次死锁信息
innodb_print_all_deadlocks = 1

#在创建InnoDB索引时用于指定对数据排序的排序缓冲区的大小
innodb_sort_buffer_size = 67108864

#控制着在向有auto_increment 列的表插入数据时，相关锁的行为，默认为2
#0：traditonal （每次都会产生表锁）
#1：consecutive （mysql的默认模式，会产生一个轻量锁，simple insert会获得批量的锁，保证连续插入）
#2：interleaved （不会锁表，来一个处理一个，并发最高）
innodb_autoinc_lock_mode = 1

#表示每个表都有自已独立的表空间
innodb_file_per_table = 1

#指定Online DDL执行期间产生临时日志文件的最大大小，单位字节，默认大小为128MB。
#日志文件记录的是表在DDL期间的数据插入、更新和删除信息(DML操作)，一旦日志文件超过该参数指定值时，
#DDL执行就会失败并回滚所有未提交的当前DML操作，所以，当执行DDL期间有大量DML操作时可以提高该参数值，
#但同时也会增加DDL执行完成时应用日志时锁定表的时间
innodb_online_alter_log_max_size = 4G

#--###########################-- innodb性能设置 结束 --##########################################

[mysqldump]
quick
max_allowed_packet = 128M
```

## 配置优化备选

```properties
[client]
port = 3306
socket = /tmp/mysql.sock
[mysqld]
port = 3306
socket = /tmp/mysql.sock
basedir = /usr/local/mysql
datadir = /data/mysql
pid-file = /data/mysql/mysql.pid
user = mysql
bind-address = 0.0.0.0
server-id = 1 #表示是本机的序号为1,一般来讲就是master的意思
skip-name-resolve
# 禁止MySQL对外部连接进行DNS解析，使用这一选项可以消除MySQL进行DNS解析的时间。
# 但需要注意，如果开启该选项，则所有远程主机连接授权都要使用IP地址方式，否则MySQL将无法正常处理连接请求
#skip-networking
back_log = 600
# MySQL能有的连接数量。当主要MySQL线程在一个很短时间内得到非常多的连接请求，这就起作用，
# 然后主线程花些时间(尽管很短)检查连接并且启动一个新线程。
# back_log值指出在MySQL暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中。
# 如果期望在一个短时间内有很多连接，你需要增加它。也就是说，
# 如果MySQL的连接数据达到max_connections时，新来的请求将会被存在堆栈中，
# 以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不被授予连接资源。
# 另外，这值（back_log）限于您的操作系统对到来的TCP/IP连接的侦听队列的大小。
# 你的操作系统在这个队列大小上有它自己的限制（可以检查你的OS文档找出这个变量的最大值），
# 试图设定back_log高于你的操作系统的限制将是无效的。
max_connections = 1000
# MySQL的最大连接数，如果服务器的并发连接请求量比较大，建议调高此值，以增加并行连接数量，
# 当然这建立在机器能支撑的情况下，因为如果连接数越多，介于MySQL会为每个连接提供连接缓冲区，
# 就会开销越多的内存，所以要适当调整该值，不能盲目提高设值。
# 可以过'conn%'通配符查看当前状态的连接数量，以定夺该值的大小。
max_connect_errors = 6000
# 对于同一主机，如果有超出该参数值个数的中断错误连接，
# 则该主机将被禁止连接。如需对该主机进行解禁，执行：FLUSH HOST。
open_files_limit = 65535
# MySQL打开的文件描述符限制，默认最小1024;当open_files_limit没有被配置的时候，
# 比较max_connections*5和ulimit -n的值，哪个大用哪个，
# 当open_file_limit被配置的时候，比较open_files_limit和max_connections*5的值，哪个大用哪个
table_open_cache = 128
# MySQL每打开一个表，都会读入一些数据到table_open_cache缓存中，
# 当MySQL在这个缓存中找不到相应信息时，才会去磁盘上读取。默认值64
# 假定系统有200个并发连接，则需将此参数设置为200*N(N为每个连接所需的文件描述符数目)；
# 当把table_open_cache设置为很大时，如果系统处理不了那么多文件描述符，那么就会出现客户端失效，连接不上
max_allowed_packet = 4M
# 接受的数据包大小；增加该变量的值十分安全，这是因为仅当需要时才会分配额外内存。
# 例如，仅当你发出长查询或MySQLd必须返回大的结果行时MySQLd才会分配更多内存。
# 该变量之所以取较小默认值是一种预防措施，以捕获客户端和服务器之间的错误信息包，
# 并确保不会因偶然使用大的信息包而导致内存溢出。
binlog_cache_size = 1M
# 一个事务，在没有提交的时候，产生的日志，记录到Cache中；
# 等到事务提交需要提交的时候，则把日志持久化到磁盘。默认binlog_cache_size大小32K
max_heap_table_size = 8M
# 定义了用户可以创建的内存表(memory table)的大小。这个值用来计算内存表的最大行数值。这个变量支持动态改变
tmp_table_size = 16M
# MySQL的heap（堆积）表缓冲大小。所有联合在一个DML指令内完成，并且大多数联合甚至可以不用临时表即可以完成
# 大多数临时表是基于内存的(HEAP)表。具有大的记录长度的临时表 (所有列的长度的和)
# 或包含BLOB列的表存储在硬盘上。
# 如果某个内部heap（堆积）表大小超过tmp_table_size，
# MySQL可以根据需要自动将内存中的heap表改为基于硬盘的MyISAM表。
# 还可以通过设置tmp_table_size选项来增加临时表的大小。
# 也就是说，如果调高该值，MySQL同时将增加heap表的大小，可达到提高联接查询速度的效果
read_buffer_size = 2M
# MySQL读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySQL会为它分配一段内存缓冲区read_buffer_size变量控制这一缓冲区的大小。
# 如果对表的顺序扫描请求非常频繁，并且你认为频繁扫描进行得太慢，
# 可以通过增加该变量值以及内存缓冲区大小提高其性能
read_rnd_buffer_size = 8M
# MySQL的随机读缓冲区大小。当按任意顺序读取行时(例如，按照排序顺序)，
# 将分配一个随机读缓存区。进行排序查询时，
# MySQL会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。
# 但MySQL会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大
sort_buffer_size = 8M
# MySQL执行排序使用的缓冲大小。如果想要增加ORDER BY的速度，
# 首先看是否可以让MySQL使用索引而不是额外的排序阶段。
# 如果不能，可以尝试增加sort_buffer_size变量的大小
join_buffer_size = 8M
# 联合查询操作所能使用的缓冲区大小，和sort_buffer_size一样，该参数对应的分配内存也是每连接独享
thread_cache_size = 8
# 这个值（默认8）表示可以重新利用保存在缓存中线程的数量，
# 当断开连接时如果缓存中还有空间，那么客户端的线程将被放到缓存中，
# 如果线程重新被请求，那么请求将从缓存中读取,如果缓存中是空的或者是新的请求，
# 那么这个线程将被重新创建,如果有很多新的线程，
# 增加这个值可以改善系统性能.通过比较Connections和Threads_created状态的变量，
# 可以看到这个变量的作用。(–>表示要调整的值)
# 根据物理内存设置规则如下：
# 1G  —> 8
# 2G  —> 16
# 3G  —> 32
# 大于3G  —> 64
query_cache_size = 8M
#MySQL的查询缓冲大小（从4.0.1开始，MySQL提供了查询缓冲机制）使用查询缓冲，MySQL将SELECT语句和查询结果存放在缓冲区中，
# 今后对于同样的SELECT语句（区分大小写），将直接从缓冲区中读取结果。
# 根据MySQL用户手册，使用查询缓冲最多可以达到238%的效率。
# 通过检查状态值'Qcache_%'，可以知道query_cache_size设置是否合理：
# 如果Qcache_lowmem_prunes的值非常大，则表明经常出现缓冲不够的情况，
# 如果Qcache_hits的值也非常大，则表明查询缓冲使用非常频繁，此时需要增加缓冲大小；
# 如果Qcache_hits的值不大，则表明你的查询重复率很低，
# 这种情况下使用查询缓冲反而会影响效率，那么可以考虑不用查询缓冲。
# 此外，在SELECT语句中加入SQL_NO_CACHE可以明确表示不使用查询缓冲
query_cache_limit = 2M
# 指定单个查询能够使用的缓冲区大小，默认1M
key_buffer_size = 4M
# 指定用于索引的缓冲区大小，增加它可得到更好处理的索引(对所有读和多重写)，
# 到你能负担得起那样多。如果你使它太大，
# 系统将开始换页并且真的变慢了。对于内存在4GB左右的服务器该参数可设置为384M或512M。
# 通过检查状态值Key_read_requests和Key_reads，
# 可以知道key_buffer_size设置是否合理。比例key_reads/key_read_requests应该尽可能的低，
# 至少是1:100，1:1000更好(上述状态值可以使用SHOW STATUS LIKE 'key_read%'获得)。
# 注意：该参数值设置的过大反而会是服务器整体效率降低
ft_min_word_len = 4
# 分词词汇最小长度，默认4
transaction_isolation = REPEATABLE-READ
# MySQL支持4种事务隔离级别，他们分别是：
# READ-UNCOMMITTED, READ-COMMITTED, REPEATABLE-READ, SERIALIZABLE.
# 如没有指定，MySQL默认采用的是REPEATABLE-READ，ORACLE默认的是READ-COMMITTED
log_bin = mysql-bin
binlog_format = mixed
# 超过30天的binlog删除
expire_logs_days = 30
# 错误日志路径
log_error = /data/mysql/mysql-error.log 
slow_query_log = 1
long_query_time = 1 
# 慢查询时间 超过1秒则为慢查询
slow_query_log_file = /data/mysql/mysql-slow.log
performance_schema = 0
explicit_defaults_for_timestamp
#lower_case_table_names = 1 #不区分大小写
# MySQL选项以避免外部锁定。该选项默认开启
skip-external-locking 
# 默认存储引擎
default-storage-engine = InnoDB 
innodb_file_per_table = 1
# InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据空间
# 独立表空间优点：
# 1．每个表都有自已独立的表空间。
# 2．每个表的数据和索引都会存在自已的表空间中。
# 3．可以实现单表在不同的数据库中移动。
# 4．空间可以回收（除drop table操作处，表空不能自已回收）
# 缺点：单表增加过大，如超过100G
# 结论：共享表空间在Insert操作上少有优势。其它都没独立表空间表现好。当启用独立表空间时，请合理调整：innodb_open_files
innodb_open_files = 500
# 限制Innodb能打开的表的数据，如果库里的表特别多的情况，请增加这个。这个值默认是300
innodb_buffer_pool_size = 64M
# InnoDB使用一个缓冲池来保存索引和原始数据, 不像MyISAM.
# 这里你设置越大,你在存取表里面数据时所需要的磁盘I/O越少.
# 在一个独立使用的数据库服务器上,你可以设置这个变量到服务器物理内存大小的80%
# 不要设置过大,否则,由于物理内存的竞争可能导致操作系统的换页颠簸.
# 注意在32位系统上你每个进程可能被限制在 2-3.5G 用户层面内存限制,所以不要设置的太高.
innodb_write_io_threads = 4
innodb_read_io_threads = 4
# innodb使用后台线程处理数据页上的读写 I/O(输入输出)请求,根据你的 CPU 核数来更改,默认是4
# 注:这两个参数不支持动态改变,需要把该参数加入到my.cnf里，修改完后重启MySQL服务,允许值的范围从 1-64
innodb_thread_concurrency = 0
# 默认设置为 0,表示不限制并发数，这里推荐设置为0，更好去发挥CPU多核处理能力，提高并发量
innodb_purge_threads = 1
# InnoDB中的清除操作是一类定期回收无用数据的操作。
# 在之前的几个版本中，清除操作是主线程的一部分，这意味着运行时它可能会堵塞其它的数据库操作。
# 从MySQL5.5.X版本开始，该操作运行于独立的线程中,并支持更多的并发数。
# 用户可通过设置innodb_purge_threads配置参数来选择清除操作是否使用单
# 独线程,默认情况下参数设置为0(不使用单独线程),设置为 1 时表示使用单独的清除线程。建议为1
innodb_flush_log_at_trx_commit = 2
# 0：如果innodb_flush_log_at_trx_commit的值为0,log buffer每秒就会被刷写日志文件到磁盘，
# 提交事务的时候不做任何操作（执行是由mysql的master thread线程来执行的。
# 主线程中每秒会将重做日志缓冲写入磁盘的重做日志文件(REDO LOG)中。不论事务是否已经提交）
# 默认的日志文件是ib_logfile0,ib_logfile1
# 1：当设为默认值1的时候，每次提交事务的时候，都会将log buffer刷写到日志。
# 2：如果设为2,每次提交事务都会写日志，但并不会执行刷的操作。
# 每秒定时会刷到日志文件。要注意的是，并不能保证100%每秒一定都会刷到磁盘，这要取决于进程的调度。
# 每次事务提交的时候将数据写入事务日志，而这里的写入仅是调用了文件系统的写入操作，
# 而文件系统是有 缓存的，所以这个写入并不能保证数据已经写入到物理磁盘
# 默认值1是为了保证完整的ACID。当然，你可以将这个配置项设为1以外的值来换取更高的性能，
# 但是在系统崩溃的时候，你将会丢失1秒的数据。
# 设为0的话，mysqld进程崩溃的时候，就会丢失最后1秒的事务。
# 设为2,只有在操作系统崩溃或者断电的时候才会丢失最后1秒的数据。InnoDB在做恢复的时候会忽略这个值。
# 总结
# 设为1当然是最安全的，但性能页是最差的（相对其他两个参数而言，但不是不能接受）。
# 如果对数据一致性和完整性要求不高，完全可以设为2，如果只最求性能，
# 例如高并发写的日志服务器，设为0来获得更高性能
innodb_log_buffer_size = 2M
# 此参数确定些日志文件所用的内存大小，以M为单位。缓冲区更大能提高性能，
# 但意外的故障将会丢失数据。MySQL开发人员建议设置为1－8M之间
innodb_log_file_size = 32M
# 此参数确定数据日志文件的大小，更大的设置可以提高性能，但也会增加恢复故障数据库所需的时间
innodb_log_files_in_group = 3
# 为提高性能，MySQL可以以循环方式将日志文件写到多个文件。推荐设置为3
innodb_max_dirty_pages_pct = 90
# innodb主线程刷新缓存池中的数据，使脏数据比例小于90%
innodb_lock_wait_timeout = 120 
# InnoDB事务在被回滚之前可以等待一个锁定的超时秒数
# InnoDB在它自己的锁定表中自动检测事务死锁并且回滚事务
# InnoDB用LOCK TABLES语句注意到锁定设置。默认值是50秒
bulk_insert_buffer_size = 8M
# 批量插入缓存大小， 这个参数是针对MyISAM存储引擎来说的。
# 适用于在一次性插入100-1000+条记录时， 提高效率。默认值是8M。可以针对数据量的大小，翻倍增加。
myisam_sort_buffer_size = 8M
# MyISAM设置恢复表之时使用的缓冲区的尺寸，当在REPAIR TABLE或用CREATE INDEX创建索引
# 或ALTER TABLE过程中排序 MyISAM索引分配的缓冲区
myisam_max_sort_file_size = 10G
# 如果临时文件会变得超过索引，不要使用快速排序索引方法来创建一个索引。注释：这个参数以字节的形式给出
myisam_repair_threads = 1
# 如果该值大于1，在Repair by sorting过程中并行创建MyISAM表索引(每个索引在自己的线程内) 
interactive_timeout = 28800
# 服务器关闭交互式连接前等待活动的秒数。
# 交互式客户端定义为在mysql_real_connect()中使用CLIENT_INTERACTIVE选项的客户端。
# 默认值：28800秒（8小时）
wait_timeout = 28800
# 服务器关闭非交互连接之前等待活动的秒数。在线程启动时，
# 根据全局wait_timeout值或全局interactive_timeout值初始化会话wait_timeout值，
# 取决于客户端类型(由mysql_real_connect()的连接选项CLIENT_INTERACTIVE定义)。
# 参数默认值：28800秒（8小时）
# MySQL服务器所支持的最大连接数是有上限的，因为每个连接的建立都会消耗内存，
# 因此我们希望客户端在连接到MySQL Server处理完相应的操作后，
# 应该断开连接并释放占用的内存。如果你的MySQL Server有大量的闲置连接，
# 他们不仅会白白消耗内存，而且如果连接一直在累加而不断开，
# 最终肯定会达到MySQL Server的连接上限数，这会报'too many connections'的错误。
# 对于wait_timeout的值设定，应该根据系统的运行情况来判断。
# 在系统运行一段时间后，可以通过show processlist命令查看当前系统的连接状态，
# 如果发现有大量的sleep状态的连接进程，则说明该参数设置的过大，
# 可以进行适当的调整小些。要同时设置interactive_timeout和wait_timeout才会生效。
[mysqldump]
quick
max_allowed_packet = 16M #服务器发送和接受的最大包长度
[myisamchk]
key_buffer_size = 8M
sort_buffer_size = 8M
read_buffer = 4M
write_buffer = 4M
```



# 数据恢复

> 一般来说，在生产环境DBA都会在定期生成全量数据的备份，然后开启binlog记录增量数据。恢复的时候借助数据备份和binlog日志一般情况下是可以很大程度上复原数据，当然一般情况下开发也不会拥有删库的权限，一般都是有删除数据的权限。所以我们在遇到这种紧急情况不能慌，要赶紧去想办法补救。[删库不再跑路！我在里面含泪写下 MySQL 数据恢复大法（重要，还没搞）](https://mp.weixin.qq.com/s?__biz=MzI1NzI5NDM4Mw==&mid=2247495274&idx=1&sn=994800c3833570311fbb56fd3fefe26c&chksm=ea1b072add6c8e3cf0c833733e33794b15ef71505ffed4e56721642cc9b8414688ee111ca162&mpshare=1&scene=23&srcid=06092XEdcYSAZqsxhWsOtsrV&sharer_sharetime=1686270792091&sharer_shareid=29b8a04db1dbd975e3bf4e9f47e7ac67#rd)
>

> 最简单，也是最实用的方式就是在我们接到，清理数据，或者是修改数据的需求时，先将**数据备份**，备份是王道。这样会让我们的数据恢复变得更容易。一般在企业中，DBA都会有备份脚本，他们会长期定时对数据进行备份，防止发生悲剧。
>

## 规范操作

操作前，先备份，不要怕麻烦，出错后就悔不当初了；

删除数据库、表时，不要直接用drop命令，而是重命名到一个专用归档库里；

删除数据时，不要直接用delete或truncate命令，尤其是truncate命令，目前不支持事务，无法回滚；

使用delete命令删除数据时，应当先开启事务，这样误操作时，还是有机会进行回滚；

要大批量删除数据时，可以将这些数据插入到一个新表中，确认无误后再删除。或者把要保留的数据写到新表，然后将表重命名对掉，这样需要注意的是增量数据，不要把新插入的数据丢掉；

## 基本的恢复流程

- 看看是否有定期备份，和binlog日志（没有就凉凉）
- 先备份数据恢复
- 用mysqlbinlog命令将上述的binlog文件导出为sql文件，并剔除其中的drop语句
- 恢复binlog中增量数据的部分

## 补救措施

1. 优先考虑是否能只通过binlog恢复，不能的化，再考虑其它
2. 执行 DROP DATABASE / DROP TABLE 命令误删库表时，如果采用的是共享表空间模式，还有恢复的机会。如果不是，直接从备份文件恢复吧；在共享表空间模式下，误删后立刻杀掉（kill -9）mysql相关进程（mysqld_safe、mysqld），然后尝试从ibdataX文件中恢复数据；
3. 误删除正在运行中的MySQL表ibd或ibdataX文件。利用linux系统的proc文件特点，把该ibd文件从内存中拷出来，再进行恢复，因为此时mysqld实例在内存中是保持打开该文件的，切记这时不要把mysqld实例关闭了。此模式恢复，需要停止线上业务对该实例的写入操作，不再写入新数据，防止丢失新数据。把复制出来的ibd 或 ibdataX文件拷贝回datadir后，重启mysqld进入recovery模式，innodb_force_recovery 选项从 0 - 6 逐级测试，直至能备份出整个实例或单表的所有数据后，再重建实例或单表，恢复数据。
4. 未开启事务模式下，执行delete误删数据。发现问题严重性后，立即将mysqld（以及mysqld_safe）进程杀掉（kill -9），然后再用工具将表空间数据读取出来。因为执行delete删除后，实际数据并没有从磁盘清除，只是先打上deleted-mark标签，后续再统一清理，因此快速杀掉进程可以防止数据被物理删除。
5. 执行truncate误清整张表。如果没使用共享表空间模式的话，直接使用备份恢复和binlog恢复。
6. 执行不带where条件的update，或者update错数据。数据规模大没法补救的话，也只能通过走备份恢复和binlog恢复。

## 相关操作

查看是否开启binlog日志

```apl
# log_bin是ON，就说明打开了 OFF就是关闭状态。
show variables like 'log_bin';
# log_bin相关的内容都能查到
show variables like '%log_bin%';
```

binlog日志位置

```apl
show variables like '%datadir%';
```

根据binlog日志恢复数据

- cd 到binlog文件目录
- mysql安装目录/mysql/bin/下找到binlog日志解析工具mysqlbinlog
- 通过mysqlbinlog工具命令按照对应时间解析binlog日志内容，输出到新的文件中

该工具也支持过滤指定表的相关操作记录

```sql
mysqlbinlog --base64-output=decode-rows -v 
  --database=mall 
  --start-datetime="2021-09-17 20:50:00" 
  --stop-datetime="2021-09-17 21:30:00" 
  D:\tmp\mysql-bin.000001 > mysqllog.sql
```

对参数进行一下说明：

- `base64-output=decode-rows`：基于行事件解析成 sql 语句，并将数据转换正常的字符。
- `database`：数据库名。
- `start-datetime`：从 binlog 中第一个等于或晚于该时间戳的事件开始读取，也就是恢复数据的起始时间。
- `stop-datetime`：与上面对应的，是恢复数据的结束时间。
- `D:\tmp\mysql-bin.000001`：恢复数据的日志文件。
- `mysqllog.sql`：恢复数据的输出文件。

执行完成后，在`bin`目录下会生成一个`mysqllog.sql`的文件，打开文件看一下，可以找到删除时执行的`delete`语句：从语句中可以拿到`delete`命令执行时每一行数据的值，这样就可以进行数据的恢复了。如果需要恢复的数据量非常大的话，建议使用脚本批量将`delete`语句转换为`insert`语句，减轻恢复数据的工作量。

通过配置文件对binlog 日志进行配置

```apl
# 日志格式
# Statement模式，每一条会修改数据的sql都会记录在binlog中。
# Row模式，5.1.5版本的MySQL才开始支持row,它不记录sql语句上下文相关信息，仅保存哪条记录被修改。
# Mixed模式，一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则采用row格式保存binlog，MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和Row之间选择一种。
# 设置日志格式
binlog_format = mixed

# 设置日志路径，需要注意的是该路经需要mysql用户有写权限
log-bin = /data/mysql/logs/mysql-bin.log

# 设置binlog清理时间
expire_logs_days = 7

# binlog每个日志文件大小
max_binlog_size = 100m

# binlog缓存大小
binlog_cache_size = 4m

# 最大binlog缓存大小
max_binlog_cache_size = 512m
```

# 主从复制⭐

## 概述

### 应用场景

> 主从复制是指将主数据库的DDL 和 DML 操作通过二进制日志传到从库服务器中，然后在从库上对这些日志重新执行（也叫重做），从而 使得从库和主库的数据保持同步。
>

> MySQL支持一台主库同时向多台从库进行复制，从库同时也可以作为其他从服务器的主库，实现链状复制。
>

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202303021426600.png" alt="image-20230302142651516" style="zoom:80%;" />



### 原理

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202303021429017.png" alt="image-20230302142908937" style="zoom:80%;" />

## 搭建主从

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202303021432762.png" alt="image-20230302143239669" style="zoom:80%;" />

```sh
systemctl stop firewalld
systemctl disable firewalld
```

### 查看MySQL配置文件位置

```apl
/usr/bin/mysql --verbose --help | grep -A 1 'Default options'
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205261501433.png" alt="image-20220526150106366" style="zoom:80%;" />

这个信息的意思是： 服务器首先读取的是/etc/my.cnf文件，如果前一个文件不存在则继续读/etc/mysql/my.cnf文件，如若还不存在便会去读~/.my.cnf文件

### 主库配置

> 注意：主库中已经创建的数据库不会再进行同步，只有同步开始后新创建的数据库才能同步

```apl
vi /etc/my.cnf
```

```ini
# 设置server_id，同一局域网中需要唯一，只有它是必须的，剩下的都是可加可不加的
server_id=101 
# 是否只读，1代表只读，0代表读写(可选)
read-only=0
```

详细(可选)

```ini
# 节点ID，确保唯一 一般设置为IP
server-id = 1   
# 是否只读，1代表只读，0代表读写(可选)
read-only=0
# 指定不需要同步的数据库名称
binlog-ignore-db=mysql  
# 复制过滤：需要备份的数据库，输出binlog
binlog-do-db=book
# 开启mysql的binlog日志功能 可以随便取，最好有含义
log-bin = mysql-bin  
# 控制数据库的binlog刷到磁盘上去 , 0 不控制，性能最好，1每次事物提交都会刷到日志文件中，
# 性能最差，最安全
sync_binlog = 1
#binlog日志格式，mysql默认采用statement，建议使用mixed（mixed,statement,row）
binlog_format = mixed   
#binlog过期清理时间 二进制日志自动删除/过期的天数。默认值为0，表示不自动删除
expire_logs_days = 7      
#binlog每个日志文件大小
max_binlog_size = 100m     
#binlog缓存大小  为每个session 分配的内存，在事务过程中用来存储二进制日志的缓存
binlog_cache_size = 4m     
#最大binlog缓存大
max_binlog_cache_size= 512m  
#不需要备份的数据库不生成日志文件的数据库，多个忽略数据库可以用逗号拼接，或者 复制这句话，写多行
binlog-ignore-db=mysql     
## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致
## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。
#slave-skip-errors = all #跳过从库错误
slave-skip-errors = all 
```

重启MYSQL服务器，如果重启没有报错，证明修改没问题

```apl
systemctl restart mysqld
systemctl start mysqld
systemctl stop mysqld
```

通过指令,查看二进制日志坐标

```mysql
mysql -uroot -p123456
show master status ;
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img/image-20220206102052371.png" alt="image-20220206102052371" style="zoom:80%;" />

字段含义说明：

- file : 从哪个日志文件开始推送日志文件


- position ： 从哪个位置开始推送日志


- binlog_ignore_db : 指定不需要同步的数据库

登录主库mysql，创建角色和授予权限(可选)，因为主库已经有root用户了，**这个角色不创建也行**

创建用户

接下来添加一个仅用于数据同步的账户，出于安全考虑，这里仅提供对heima这个库的操作权限。

```mysql
-- 降低密码等级
set global validate_password.policy=0;
set global validate_password.length=4;
-- 创建用户授予权限
create user 'itcast1'@'%' identified by 'itcast';
GRANT  select,replication slave ON *.* TO 'itcast1'@'%';
flush privileges;
```

### 从库配置

```apl
vi /etc/my.cnf
```

```mysql
# mysql服务ID，保证整个集群环境中唯一，取值范围1-2的32次方-1
server-id=2
# 是否只读，1代表只读，0代表读写(可选)，注意：这表示开发人员对数据库的操作权限
# read-only=1
```

详细配置(可选)

```ini
# 设置server_id，同一局域网中需要唯一
server_id=102
# 指定不需要同步的数据库名称
binlog-ignore-db=mysql
# 开启二进制日志功能，以备Slave作为其它数据库实例的Master时使用
log-bin=mysql-slave1-bin
# 设置二进制日志使用内存大小（事务）
binlog_cache_size=1M
# 设置使用的二进制日志格式（mixed,statement,row）
binlog_format=row
# 二进制日志过期清理时间。默认值为0，表示不自动清理。
expire_logs_days=7
# 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。
# 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致
slave_skip_errors=1062
# relay_log配置中继日志
relay_log=mall-mysql-relay-bin
# log_slave_updates表示slave将复制事件写进自己的二进制日志
log_slave_updates=1
# slave设置为只读（具有super权限的用户除外）
read_only=1
```

重启mysql数据库

```c
systemctl restart mysqld
```

### 登录从库

```c
mysql -uroot -p123456 -h 192.168.0.155 -P 3307
```

3、设置和主库关联(根据上面的二进制坐标来填写)

> 8.0.23之后使用change replication

```mysql
change replication source to 
SOURCE_HOST='192.168.22.145',
SOURCE_USER='root',
SOURCE_PASSWORD='123456',
SOURCE_LOG_FILE='mall-mysql-bin.000002',
SOURCE_LOG_POS=431;
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209171317671.png" alt="image-20220917131744582" style="zoom:80%;" />

> 8.0.23之前使用change master

```sql
change master to 
MASTER_HOST='192.168.22.145',
MASTER_USER='root',
MASTER_PASSWORD='123456',
MASTER_LOG_FILE='mall-mysql-bin.000002',
MASTER_LOG_POS=431;
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img/image-20220206102601205.png" alt="image-20220206102601205" style="zoom:80%;" />

4、开启同步(从库开启)

```mysql
start replica; # 8.0.22之后，相应的关闭就是stop replica；
start slave; # 8.0.22之前
```

5、查看同步状态

```mysql
show replica status\G;
show slave status\G;
```

重点看下面这两个，只要都是Yes代表可以了

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img/image-20220206103238500.png" alt="image-20220206103238500" style="zoom:80%;" />

### 测试

```
mysql -uroot -p -h 192.168.22.145 -P 3306
```

在主库创建数据库、表、并插入数据

```mysql
create database ph2;
use ph2;
create table author (
    id int(11) primary key auto_increment,
    name varchar(50),
    country varchar(50)
);
insert into author values (null,'村上春树', '日本');
insert into author values (null,'莫言', '中国');
insert into author values (null,'冯唐', '中国');
-- 更新
update author set name='刘备' where id=1;
```

进入从库进行查询，发现已经主从同步了

```mysql
show databases ;
use ph2;
show tables ;
select * from author;
```

### 停止和重置

需要的时候，可以使用如下SQL语句

```sql
-- 在从机上执行。功能说明：停止I/O 线程和SQL线程的操作。
stop slave; 

-- 在从机上执行。功能说明：用于删除SLAVE数据库的relaylog日志文件，并重新启用新的relaylog文件。
reset slave;

-- 在主机上执行。功能说明：删除所有的binglog日志文件，并将日志索引文件清空，重新开始所有新的日志文件。
-- 用于第一次进行搭建主从库时，进行主库binlog初始化工作；
reset master;
```

### 监控连接

主从都可以用它来监控

```sql
show processlist;
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209171750897.png" alt="image-20220917175059721" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209171751630.png" alt="image-20220917175112508" style="zoom:80%;" />

### 常见问题

#### 问题1

启动主从同步后，常见错误是`Slave_IO_Running： No 或者 Connecting` 的情况，此时查看下方的 `Last_IO_ERROR`错误日志，根据日志中显示的错误信息在网上搜索解决方案即可

![img](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209171542809.png)

**典型的错误例如：**`Last_IO_Error: Got fatal error 1236 from master when reading data from binary log: 'Client requested master to start replication from position > file size'`

**解决方案：**

```sql
-- 在从机停止slave
stop slave;
-- 在主机查看mater状态
SHOW MASTER STATUS;
-- 在主机刷新日志
FLUSH LOGS;
-- 再次在主机查看mater状态（会发现File和Position发生了变化）
SHOW MASTER STATUS;
-- 修改从机连接主机的SQL，并重新连接即可
```

#### 问题2

启动docker容器后提示 `WARNING: IPv4 forwarding is disabled. Networking will not work.`

![img](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209171542811.png)

此错误，虽然不影响主从同步的搭建，但是如果想从远程客户端通过以下方式连接docker中的MySQL则没法连接

```shell
C:\Users\administrator>mysql -h 192.168.100.201 -P 3306 -u root -p
```

**解决方案：**

```shell
#修改配置文件：
vim /usr/lib/sysctl.d/00-system.conf
#追加
net.ipv4.ip_forward=1
#接着重启网络
systemctl restart network
```



## Docker搭建MySQL

创建容器，设置端口映射、目录映射

```shell
docker run -d -p 3307:3306 --privileged=true \
-v /DockerData/mysql/log1:/var/log/mysql \
-v /DockerData/mysql/data1:/var/lib/mysql \
-v /DockerData/mysql/conf1:/etc/mysql/conf.d \
-e MYSQL_ROOT_PASSWORD=123456  \
--name mysql5.7.1 \
mysql:5.7
```

创建容器，设置端口映射、目录映射

```shell
docker run -d -p 3308:3306 --privileged=true \
-v /DockerData/mysql/log2:/var/log/mysql \
-v /DockerData/mysql/data2:/var/lib/mysql \
-v /DockerData/mysql/conf2:/etc/mysql/conf.d \
-e MYSQL_ROOT_PASSWORD=123456  \
--name mysql5.7.2 \
mysql:5.7
```

创建容器，设置端口映射、目录映射

```shell
docker run -d -p 3309:3306 --privileged=true \
-v /DockerData/mysql/log3:/var/log/mysql \
-v /DockerData/mysql/data3:/var/lib/mysql \
-v /DockerData/mysql/conf3:/etc/mysql/conf.d \
-e MYSQL_ROOT_PASSWORD=123456  \
--name mysql5.7.3 \
mysql:5.7
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209171617650.png" alt="image-20220917161748373" style="zoom:80%;" />

### 配置文件

```
cd /DockerData/mysql/conf1
vim my.cnf
```

编辑my.cnf

```ini
[client]
default_character_set=utf8
[mysqld]
collation_server = utf8_general_ci
character_set_server = utf8
```

```apl
cp my.cnf /DockerData/mysql/conf2/my.cnf 
cp my.cnf /DockerData/mysql/conf3/my.cnf 
```

重启mysql5.7服务

```apl
docker restart mysql5.7.1
docker restart mysql5.7.2
docker restart mysql5.7.3
```

查看编码(修改成功)

```apl
# 进入容器，操作mysql
docker exec -it mysql5.7.1 /bin/bash
mysql -uroot -p123456
```

```mysql
show variables like 'character%';
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img/image-20220208130605973.png" alt="image-20220208130605973" style="zoom:67%;" />

### 主从配置

主数据库

```properties
[mysqld]
## 设置server_id，同一局域网中需要唯一
server_id=101 
## 指定不需要同步的数据库名称
binlog-ignore-db=mysql  
## 开启二进制日志功能
log-bin=mall-mysql-bin  
## 设置二进制日志使用内存大小（事务）
binlog_cache_size=1M  
## 设置使用的二进制日志格式（mixed,statement,row）
binlog_format=row  
## 二进制日志过期清理时间。默认值为0，表示不自动清理。
expire_logs_days=7  
## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。
## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致
slave_skip_errors=1062
```

从数据库

```properties
[mysqld]
## 设置server_id，同一局域网中需要唯一
server_id=102
```

```properties
[mysqld]
## 设置server_id，同一局域网中需要唯一
server_id=103
```

## 主从连接配置

### 主数据库

进入主节点，查看binlog位置

```apl
docker exec -it mysql5.7.1 /bin/bash
mysql -uroot -p123456
show master status ;
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209171709277.png" alt="image-20220917170939185" style="zoom:80%;" />

### 从数据库

```apl
docker exec -it mysql5.7.2 /bin/bash
mysql -uroot -p123456
```

```apl
docker exec -it mysql5.7.3 /bin/bash
mysql -uroot -p123456
```

```mysql
change master to master_host='192.168.22.145', 
master_user='root', 
master_password='123456', 
master_port=3307, 
master_log_file='mall-mysql-bin.000002', 
master_log_pos=154, 
master_connect_retry=30;
```

主从复制命令参数说明

- master_host：主数据库的IP地址；
- master_port：主数据库的运行端口；
- master_user：在主数据库创建的用于同步数据的用户账号；
- master_password：在主数据库创建的用于同步数据的用户密码；
- master_log_file：指定从数据库要复制数据的日志文件，通过查看主数据的状态，获取File参数；
- master_log_pos：指定从数据库从哪个位置开始复制数据，通过查看主数据的状态，获取Position参数；
- master_connect_retry：连接失败重试的时间间隔，单位为秒。

在从数据库中开启主从同步

```apl
start slave;
```

查看从数据库状态发现已经同步

```apl
show slave status \G;
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209171632017.png" alt="image-20220917163234910" style="zoom:80%;" />

## 主从复制测试

主机新建库-使用库-新建表-插入数据，ok

```sql
create database ph3;
use ph3;
create table author (
    id int(11) primary key auto_increment,
    name varchar(250),
    country varchar(250)
);
insert into author values (null,'村上春树', '日本');
insert into author values (null,'莫言', '中国');
insert into author values (null,'冯唐', '中国');
```

从机使用库-查看记录，ok

```sql
use ph3;
select * from author;
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img/image-20220209115009974.png" alt="image-20220209115009974" style="zoom: 80%;" />



# 数据库迁移工具

[数据库迁移搞炸了！没用这款开源神器的锅？ (qq.com)](https://mp.weixin.qq.com/s?__biz=MzU1Nzg4NjgyMw==&mid=2247488603&idx=1&sn=a41d446aa061833c15f45f5c7c5b34c7&chksm=fc2fa853cb5821458d0c5fa3dc0238c7838f72928087c98467d0ca554d5533a046984d71e33e&mpshare=1&scene=23&srcid=0812syBdoLDotnnSdT7yJl10&sharer_sharetime=1660275406289&sharer_shareid=29b8a04db1dbd975e3bf4e9f47e7ac67#rd)

> 当我们的应用升级时往往会伴随着数据库表结构的升级，此时就需要迁移数据库的表结构。一般我们会使用工具或者脚本来实现，手动操作毕竟有一定风险，要是能在应用启动时自动升级数据库表结构就好了！Flyway正是这么一款工具，通过Flyway和SpringBoot结合使用，在应用启动时就可以自动升级数据库表结构，非常方便，推荐给大家！官方文档：https://flywaydb.org/documentation/

## Flyway简介

Flyway是一款数据库迁移工具，它让数据库迁移变得更加简单。它能像Git一样对数据库进行版本控制，支持命令行工具、Maven插件、第三方工具（比如SpringBoot）等多种使用方式。

Flyway具有如下特点：

- 简单：使用和学习简单，通过不同版本的SQL脚本实现数据库迁移。
- 专业：专注于数据库迁移功能，你无需担心有任何问题。
- 功能强大：支持多种数据库，拥有大量的第三方工具，支持CI/DI。

## 相关概念

### 工作原理

使用Flyway时我们需要编写好数据库迁移的SQL脚本，比如`V1__Initial_Setup.sql`中初始化了三种表，`V2__First_Changes.sql`中又新增了两种表。Flyway会创建`flyway_schema_history`表，用于存储这些SQL脚本的执行情况，从而对数据库进行版本控制。当我们使用Flyway进行数据库迁移时，Flyway会根据`flyway_schema_history`表中的记录，自行决定需要执行哪些SQL脚本，从而实现数据库迁移。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208141844580.png" alt="image-20220814184424491" style="zoom:67%;" />

### 脚本命名规范

在创建Flyway的SQL脚本时，有些命名规范需要遵守，这些命名规范决定了Flyway执行脚本的顺序和方式，可以先参考下面的示意图。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208141844367.png" alt="image-20220814184440305" style="zoom:67%;" />

为了能被Flyway正确执行，SQL迁移脚本需要遵循如下规范：

- Prefix（前缀）：`V`表示有版本号的数据库迁移，`U`表示一些数据库版本的回滚，`R`表示可重复执行的数据库迁移；
- Version（版本号）：Flyway会按照版本号的大小顺序来执行数据库迁移脚本；
- Separator（分隔符）：命名时使用双下划线分隔符；
- Description（描述）：用于描述该迁移脚本的具体操作说明；
- Suffix（后缀）：表示`.sql`文件。

### 相关命令

- migrate：数据库迁移命令，会根据设置好的SQL脚本直接将数据库表升级至最新版本。
- clean：删除数据库中所有的表，千万别在生产环境上使用。
- info：打印所有关于数据库迁移的详细信息和状态信息。
- validate：验证数据库迁移是否可用。
- undo：对数据库迁移进行回滚操作。
- baseline：以现有数据库为基准，创建`flyway_schema_history`表，大于基准版本的数据库迁移才会被应用。
- repair：修复`flyway_schema_history`表。

## 命令行工具

> 使用Flyway实现数据迁移有多种方式，我们先通过命令行工具的方法来体验下Flyway的使用。

首先需要下载Flyway的命令行工具，下载社区版即可，下载地址：https://flywaydb.org/download

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208141845927.png" alt="image-20220814184534838" style="zoom:67%;" />

下载完成后进行解压，解压完成后目录结构如下；

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208141846411.png" alt="image-20220814184623341" style="zoom:67%;" />

修改Flyway的配置文件`/conf/flyway.conf`，修改下数据库配置即可；

```apl
flyway.url=jdbc:mysql://localhost:3306/flyway?useUnicode=true&characterEncoding=utf-8&serverTimezone=Asia/Shanghai 
flyway.user=root
flyway.password=root
```

在`/sql`目录下添加SQL执行脚本，这里添加创建`ums_admin`表的执行脚本`V1.0.1__Create_ums_admin_table.sql`；

```sql
CREATE TABLE `ums_admin`
(
  `id`          bigint(20) NOT NULL AUTO_INCREMENT,
  `username`    varchar(64)  DEFAULT NULL,
  `password`    varchar(64)  DEFAULT NULL,
  `icon`        varchar(500) DEFAULT NULL COMMENT '头像',
  `email`       varchar(100) DEFAULT NULL COMMENT '邮箱',
  `nick_name`   varchar(200) DEFAULT NULL COMMENT '昵称',
  `note`        varchar(500) DEFAULT NULL COMMENT '备注信息',
  `create_time` datetime     DEFAULT NULL COMMENT '创建时间',
  `login_time`  datetime     DEFAULT NULL COMMENT '最后登录时间',
  `status`      int(1)       DEFAULT '1' COMMENT '帐号启用状态：0->禁用；1->启用',
  PRIMARY KEY (`id`)
) ENGINE = InnoDB
  AUTO_INCREMENT = 8
  DEFAULT CHARSET = utf8 COMMENT ='后台用户表';
```

- 使用`flyway migrate`命令进行数据迁移，此时我们会发现需要先使用`flyway baseline`命令创建保存迁移记录的表`flyway_schema_history`才行；

![图片](https://mmbiz.qpic.cn/mmbiz_png/CKvMdchsUwkD6LiaaNyMnSlTEOgIZrXz5Ptg33NxXiahjwc5O9Povem3PM5j7VdKaLUMfuTZia3bibLZvy9SxzXZxg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- 先使用`flyway baseline`命令，再使用`flyway migrate`命令，命令行会输出执行成功的信息；

![图片](https://mmbiz.qpic.cn/mmbiz_png/CKvMdchsUwkD6LiaaNyMnSlTEOgIZrXz5qP9TAgTpsAmLMIrEtFZnicJibOvV0x8a8cECCOZSicnONk55eiawdS6LxQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- 在`\sql`目录下添加SQL执行脚本，给`ums_admin`表添加一些数据，执行脚本为`V1.0.2__Add_ums_admin.sql`；

```sql
INSERT INTO ums_admin (username, PASSWORD, email, nick_name, STATUS)
VALUES ('test', '123456', 'test@qq.com', '测试账号', 1);
INSERT INTO ums_admin (username, PASSWORD, email, nick_name, STATUS)
VALUES ('macro', '123456', 'macro@qq.com', '普通账号', 1);
INSERT INTO ums_admin (username, PASSWORD, email, nick_name, STATUS)
VALUES ('andy', '123456', 'andy@qq.com', '普通账号', 1);
```

- 我们可以使用`flyway info`命令查看`flyway_schema_history`表中的数据迁移记录，可以发现`1.0.2`版本的更新还处于`Pending`状态，使用`flyway migrate`命令后变为`Success`；

![图片](https://mmbiz.qpic.cn/mmbiz_png/CKvMdchsUwkD6LiaaNyMnSlTEOgIZrXz5m2ricmjjzXFkh94ASpc5BFWV1sGXbxOGf0fJicIe0z0xZvYtl4Unbf7w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- 我们可以创建可重复执行的SQL脚本，通常可以用来创建视图、存储过程、函数等，比如基于`ums_admin`表创建一个视图，执行脚本为`R__Ums_admin_view.sql`;

```sql
CREATE
  OR REPLACE VIEW ums_admin_view AS
SELECT username,
       PASSWORD,
       email
FROM ums_admin;
```

- 使用`flyway migrate`命令可以重复执行（当R开头的脚本有变更时），该脚本会在所有`V`开头的脚本执行完成后执行；

![图片](https://mmbiz.qpic.cn/mmbiz_png/CKvMdchsUwkD6LiaaNyMnSlTEOgIZrXz5xHZsrnibnx1fxvTlzwtfM778Evv2liaFKWNBkFwqFcUjlHqj71S0u0ng/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- Flyway的回滚机制需要依赖SQL脚本，这里创建`U1.0.1__Create_ums_admin_table.sql`和`U1.0.2__Add_ums_admin.sql`两个回滚脚本；

```sql
# U1.0.1__Create_ums_admin_table.sql
DROP TABLE ums_admin
# U1.0.2__Add_ums_admin.sql
DELETE FROM ums_admin;
```

- 使用`flyway undo`命令可以执行回滚，很遗憾的是社区版本不支持回滚，看样子数据库升级之前还是得通过工具做好备份才行！

![图片](https://mmbiz.qpic.cn/mmbiz_png/CKvMdchsUwkD6LiaaNyMnSlTEOgIZrXz5xbXzl1O6vYefHxw6UYwjFQQs7jQ6Uic82HHLdpke3iapqoSNDP0oSdRg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

## Maven插件

> Flyway也提供了Maven插件，插件所支持功能与命令行工具基本一致。

- 想要在Maven项目通过插件使用Flyway，首先需要在pom.xml中添加Flyway的插件并配置好数据库连接信息；

```xml
<!--Flyway的Maven插件-->
<plugin>
    <groupId>org.flywaydb</groupId>
    <artifactId>flyway-maven-plugin</artifactId>
    <version>7.3.2</version>
    <configuration>
        <url>jdbc:mysql://localhost:3306/flyway?serverTimezone=Asia/Shanghai</url>
        <user>root</user>
        <password>root</password>
    </configuration>
    <dependencies>
        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
            <version>8.0.15</version>
        </dependency>
    </dependencies>
</plugin>
```

- 在resouce目录下创建`db\migration`目录，将数据库升级使用的SQL脚本放入进去；

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208141847072.png" alt="image-20220814184746003" style="zoom: 50%;" />

- Flyway的Maven插件支持如下几种命令；

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208141848640.png" alt="image-20220814184801549" style="zoom:50%;" />

- 双击`flyway:info`命令使用，输出如下内容，此方式与命令行工具使用基本没啥区别。



## 结合SpringBoot使用

> 由于SpringBoot官方已经支持了Flyway，所以Flyway结合SpringBoot使用非常简单！

- 首先在pom.xml中添加Flyway相关依赖，注意无需添加Flyway的版本号：

```
<!--Flyway相关依赖-->
<dependency>
    <groupId>org.flywaydb</groupId>
    <artifactId>flyway-core</artifactId>
</dependency>
```

- 修改配置文件`application.yml`，对数据源和Flyway进行配置；

```yml
spring:
  datasource:
    url: jdbc:mysql://localhost:3306/flyway?useUnicode=true&characterEncoding=utf-8&serverTimezone=Asia/Shanghai
    username: root
    password: root
  flyway:
    # 启用Flyway功能
    enabled: true
    # 禁用Flyway的clean命令，使用clean命令会删除schema下的所有表
    clean-disabled: true
    # 设置Flyway的SQL脚本路径
    locations: classpath:db/migration
    # 设置版本信息控制表名称，默认flyway_schema_history
    table: flyway_schema_history
    # 在执行migrate命令时需要有flyway_schema_history表，通过baseline命令可以生成该表
    baseline-on-migrate: true
    # 指定baseline版本号，低于该版本的SQL脚本在migrate是不会执行
    baseline-version: 1
    # 设置字符编码
    encoding: UTF-8
    # 不允许不按顺序迁移
    out-of-order: false
    # 设置Flyway管控的schema，不设置的话为datasourcel.url中指定的schema
    schemas: flyway
    # 执行migrate时开启校验
    validate-on-migrate: true
```

最后直接运行SpringBoot应用，即可自动创建好对应的数据库，控制台会输出如下信息。

# 数据库文档生成⭐

> 大家好，我是 Guide，今天分享一个好用的数据库文档生成工具。在项目中，我们经常需要整理数据库表结构文档。一般情况下，我们都是手动整理数据库表结构文档，当表结构有变动的时候，自己手动进行维护。数据库表少的时候还好，数据库表多了之后，手动整理和维护数据库表结构文档简直不要太麻烦，而且，还非常容易出错！

> **有没有什么好用的工具帮助我们自动生成数据库表结构文档呢？**当然有！Github 上就有一位朋友开源了一款数据库表结构文档自动生成工具—— **screw** 。项目地址：https://github.com/pingfangushi/screw 。

<img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzqRXJ6dYEnWic3y3J2U7icks3dnahYE6KwWSCNgga0ZV6xOocIeblqMeXyAbRnMmvgJycNAoqeQ9zw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:67%;" />

> screw 翻译过来的意思就是螺丝钉，作者希望这个工具能够像螺丝钉一样切实地帮助到我们的开发工作。目前的话，screw 已经支持市面上大部分常见的数据库比如 MySQL、MariaDB、Oracle、SqlServer、PostgreSQL、TiDB。另外，screw 使用起来也非常简单，根据官网提示，不用 10 分钟就能成功在本地使用起来！

## 数据准备

为了验证 screw 自动生成数据库表结构文档的效果，我们首先创建一个简单的存放博客数据的数据库表。

```sql
use xuexi;
CREATE TABLE `blog` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '主键',
  `title` varchar(255) NOT NULL COMMENT '博客标题',
  `content` longtext NOT NULL COMMENT '博客内容',
  `description` varchar(255) DEFAULT NULL COMMENT '博客简介',
  `cover` varchar(255) DEFAULT NULL COMMENT '博客封面图片地址',
  `views` int(11) NOT NULL DEFAULT '0' COMMENT '博客阅读次数',
  `user_id` bigint(20) DEFAULT '0' COMMENT '发表博客的用户ID',
  `channel_id` bigint(20) NOT NULL COMMENT '博客分类ID',
  `recommend` bit(1) NOT NULL DEFAULT b'0' COMMENT '是否推荐',
  `top` bit(1) NOT NULL DEFAULT b'0' COMMENT '是否置顶',
  `comment` bit(1) NOT NULL DEFAULT b'1' COMMENT '是否开启评论',
  `created_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `updated_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '更新时间',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=16 DEFAULT CHARSET=utf8mb4 COMMENT='博客';
```

## 基于 Java 代码

### 引入依赖

创建一个普通的 Maven 项目即可！然后引入 screw、HikariCP、MySQL 这 3 个依赖。

```xml
<!--screw-->
<dependency>
    <groupId>cn.smallbun.screw</groupId>
    <artifactId>screw-core</artifactId>
    <version>1.0.5</version>
</dependency>
<!-- HikariCP -->
<dependency>
    <groupId>com.zaxxer</groupId>
    <artifactId>HikariCP</artifactId>
    <version>3.4.5</version>
</dependency>
<!--MySQL-->
<dependency>
    <groupId>mysql</groupId>
    <artifactId>mysql-connector-java</artifactId>
</dependency>
```

你可以通过下面的地址在 mvnrepository 获取最新版本的 screw。

> https://mvnrepository.com/artifact/cn.smallbun.screw/screw-core

### 编写代码

```java
public class t1 {
    public static void main(String[] args) {
        documentGeneration();
    }
    public static void documentGeneration() {
        //数据源
        HikariConfig hikariConfig = new HikariConfig();
        hikariConfig.setDriverClassName("com.mysql.cj.jdbc.Driver");
        hikariConfig.setJdbcUrl("jdbc:mysql://127.0.0.1:3307/xuexi");
        hikariConfig.setUsername("root");
        hikariConfig.setPassword("123456");
        //设置可以获取tables remarks信息
        hikariConfig.addDataSourceProperty("useInformationSchema", "true");
        hikariConfig.setMinimumIdle(2);
        hikariConfig.setMaximumPoolSize(5);
        DataSource dataSource = new HikariDataSource(hikariConfig);
        //生成配置
        EngineConfig engineConfig = EngineConfig.builder()
                //生成文件路径
                .fileOutputDir("D:\\SpringBoot新项目\\demo\\doc")
                //打开目录
                .openOutputDir(true)
                //文件类型
                .fileType(EngineFileType.HTML)
                //生成模板实现
                .produceType(EngineTemplateType.freemarker)
                //自定义文件名称
                .fileName("自定义文件名称").build();

        //忽略表，有就忽略，没有就不管
        ArrayList<String> ignoreTableName = new ArrayList<>();
        ignoreTableName.add("blog");
        ignoreTableName.add("user");
        //忽略表前缀，有就忽略，没有就不管
        ArrayList<String> ignorePrefix = new ArrayList<>();
        ignorePrefix.add("test_");
        //忽略表后缀，有就忽略，没有就不管
        ArrayList<String> ignoreSuffix = new ArrayList<>();
        ignoreSuffix.add("_test");
        ProcessConfig processConfig = ProcessConfig.builder()
                //指定生成逻辑、当存在指定表、指定表前缀、指定表后缀时，
                //将生成指定表，其余表不生成、并跳过忽略表配置
                //根据名称指定表生成
                .designatedTableName(new ArrayList<>())
                //根据表前缀生成
                .designatedTablePrefix(new ArrayList<>())
                //根据表后缀生成
                .designatedTableSuffix(new ArrayList<>())
                //忽略表名
                .ignoreTableName(ignoreTableName)
                //忽略表前缀
                .ignoreTablePrefix(ignorePrefix)
                //忽略表后缀
                .ignoreTableSuffix(ignoreSuffix).build();
        //配置
        Configuration config = Configuration.builder()
                //版本
                .version("1.0.0")
                //描述
                .description("数据库设计文档生成")
                //数据源
                .dataSource(dataSource)
                //生成配置
                .engineConfig(engineConfig)
                //生成配置
                .produceConfig(processConfig)
                .build();
        //执行生成
        new DocumentationExecute(config).execute();
    }
}
```

下图就是生成的 HTML 格式的数据库设计文档。

![图片](https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzqRXJ6dYEnWic3y3J2U7icksLsIxcBkzt61dy2OwsZ2axCUOMpHl3WUyxLT6okSiaqv0flGH05D47uw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

## 基于 Maven 插件⭐

除了基于 Java 代码这种方式之外，你还可以通过 screw 提供的 Maven 插件来生成数据库文档。方法也非常简单！

### 1、配置 Maven 插件

务必将数据库相关的配置修改成你自己的。

```xml
<build>
    <plugins>
        <plugin>
            <groupId>cn.smallbun.screw</groupId>
            <artifactId>screw-maven-plugin</artifactId>
            <version>1.0.5</version>
            <dependencies>
                <!-- HikariCP -->
                <dependency>
                    <groupId>com.zaxxer</groupId>
                    <artifactId>HikariCP</artifactId>
                    <version>3.4.5</version>
                </dependency>
                <!--mysql driver-->
                <dependency>
                    <groupId>mysql</groupId>
                    <artifactId>mysql-connector-java</artifactId>
                    <version>8.0.28</version>
                </dependency>
            </dependencies>
            <configuration>
                <!--username-->
                <username>root</username>
                <!--password-->
                <password>123456</password>
                <!--driver-->
                <driverClassName>com.mysql.cj.jdbc.Driver</driverClassName>
                <!--jdbc url-->
                <jdbcUrl>jdbc:mysql://127.0.0.1:3306/javaguide-blog</jdbcUrl>
                <!--生成文件类型-->
                <fileType>MD</fileType>
                <!--打开文件输出目录-->
                <openOutputDir>true</openOutputDir>
                <!--生成模板-->
                <produceType>freemarker</produceType>
                <!--文档名称 为空时:将采用[数据库名称-描述-版本号]作为文档名称-->
                <fileName>数据库结构文档</fileName>
                <!--描述-->
                <description>数据库设计文档生成</description>
                <!--版本-->
                <version>${project.version}</version>
                <!--标题-->
                <title>数据库文档</title>
            </configuration>
            <executions>
                <execution>
                    <phase>compile</phase>
                    <goals>
                        <goal>run</goal>
                    </goals>
                </execution>
            </executions>
        </plugin>
    </plugins>
</build>
```

### 2、手动执行生成数据库文档

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.2.30/202301311835939.png" alt="image-20230131183537872" style="zoom:67%;" />

我们这里指定生成的是 Markdown 格式

![图片](https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzqRXJ6dYEnWic3y3J2U7icksEyxqKgm5hG7UAsbakj0UKOPxbNR48OhmqyN7ia201XmbMbBww0eDszg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

### 3、生成文档

下图就是生成的 Markdown 格式的数据库设计文档，效果还是非常不错的！

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.2.30/202301311836506.png" alt="image-20230131183638419" style="zoom: 67%;" />

### 4、参数可选项⭐

#### fileType生成文件类型

```xml
<!--生成文件类型-->
<fileType>MD</fileType>
<!--生成文件类型-->
<fileType>HTML</fileType>
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.2.30/202301311839189.png" alt="image-20230131183945099" style="zoom:67%;" />

# MySQL脚本工具

> 对于正在运行的mysql 性能如何？参数设置的是否合理？账号设置的是否存在安全隐患？你是否了然于胸？俗话说工欲善其事，必先利其器，定期对你的MYSQL数据库进行一个体检，是保证数据库安全运行的重要手段。

> 影响数据库因素：**SQL查询速度、服务器硬件、网卡流量、磁盘IO**

## mysqltuner.pl

> 这是mysql一个常用的数据库性能诊断工具，主要检查参数设置的合理性**包括日志文件、存储引擎、安全建议及性能分析**。针对潜在的问题，给出改进的建议，是mysql优化的好帮手。在上一版本中，**MySQLTuner支持MySQL / MariaDB / Percona Server的约300个指标**
>

> 项目地址：https://github.com/major/MySQLTuner-perl
>

### 下载 & 使用

```sh
wget https://raw.githubusercontent.com/major/MySQLTuner-perl/master/mysqltuner.pl
```

```sh
perl  mysqltuner.pl  --user=root --pass=123456   --socket /var/lib/mysql/mysql.sock
```

### 报告分析

1）重要关注[!!]（中括号有叹号的项）例如`[!!] Maximum possible memory usage: 4.8G (244.13% of installed RAM)`，表示内存已经严重用超了。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202303021513472.png" alt="image-20230302151308245" style="zoom:67%;" />

2）关注最后给的建议“Recommendations ”。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202303021513485.png" alt="image-20230302151351286" style="zoom:67%;" />

## tuning-primer.sh

这是mysql的另一个优化工具，针于mysql的整体进行一个体检，对潜在的问题，给出优化的建议。

> 项目地址：https://github.com/BMDan/tuning-primer.sh

### 下载 & 使用

```sh
wget https://launchpad.net/mysql-tuning-primer/trunk/1.6-r1/+download/tuning-primer.sh
```

```sh
show variables like '%socket%';
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202303021506586.png" alt="image-20230302150617515" style="zoom:80%;" />

```sh
bash tuning-primer.sh all --user=root --pass=123456  --socket=/var/lib/mysql/mysql.sock
```

### 报告分析

重点查看有红色告警的选项，根据建议结合自己系统的实际情况进行修改，例如：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202303021507445.png" alt="image-20230302150705314" style="zoom: 80%;" />

## pt-variable-advisor

> **`pt-variable-advisor`** 是 Percona 工具包中的一个工具，用于分析 MySQL 的配置文件以及运行时参数，并给出优化建议。它可以帮助你确定哪些变量应该被调整以优化 MySQL 的性能。

### 安装 & 使用

> https://www.percona.com/downloads/percona-toolkit/LATEST/

```sh
wget https://www.percona.com/downloads/percona-toolkit/3.0.13/binary/redhat/7/x86_64/percona-toolkit-3.0.13-re85ce15-el7-x86_64-bundle.tar
yum install percona-toolkit-3.0.13-1.el7.x86_64.rpm 
```

`pt-variable-advisor`是pt工具集的一个子工具，主要用来诊断你的参数设置是否合理。

```
 pt-variable-advisor localhost --socket /var/lib/mysql/mysql.sock
```

### 报告分析

重点关注有WARN的信息的条目，例如：

![图片](https://mmbiz.qpic.cn/mmbiz/8Jeic82Or04k265dJaKFFtmLTCGYTPiaaRrHqUnoVAiay0TfwluBsRhyMSibacic5CjYTaVCTjsdP1wdzlCHPOpEeibA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1&random=0.4055236122777566)

## pt-qurey-digest

`pt-query-digest` 主要功能是从日志、进程列表和tcpdump分析MySQL查询。

安装官网：http://www.ywnds.com/?p=8174

### 安装 & 使用

`pt-query-digest`主要用来分析mysql的慢日志，与`mysqldumpshow`工具相比，`py-query_digest `工具的分析结果更具体，更完善。

```
pt-query-digest /var/lib/mysql/slowtest-slow.log 
```

> pt-query-digest 是分析MySQL查询日志最有力的工具，该工具功能强大，它可以分析binlog，Generallog，slowlog，也可以通过show processlist或者通过 tcpdump 抓取的MySQL协议数据来进行分析，比 mysqldumpslow 更具体

```apl
# 安装命令
yum install perl-IO-Socket-SSL perl-DBD-MySQL perl-Time-HiRes perl-TermReadKey perl-IO-Socket-SSL -y
yum localinstall https://www.percona.com/downloads/percona-toolkit/2.2.20/RPM/percona-toolkit-2.2.20-1.noarch.rpm
```

### 基本使用

```c
//直接分析慢查询文件
pt-query-digest  /var/lib/mysql/slow.log > /var/lib/mysql/slow_report.log
```

打开查看

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202209222048701.png" alt="image-20220922204805635" style="zoom:80%;" />

> 该工具可以将查询的剖析报告打印出来，可以分析结果输出到文件中，分析过程是先对查询语句的条件进行参数化，然后对参数化以后的查询进行分组统计，统计出各查询的执行时间，次数，占比等，可以借助分析结果找出问题进行优化。

### 常见用法分析

1）直接分析慢查询文件:

```sh
pt-query-digest /var/lib/mysql/slowtest-slow.log > slow_report.log
```

2）分析最近12小时内的查询：

```sh
pt-query-digest --since=12h /var/lib/mysql/slowtest-slow.log > slow_report2.log
```

3）分析指定时间范围内的查询：

```sh
pt-query-digest /var/lib/mysql/slowtest-slow.log --since '2017-01-07 09:30:00' --until '2017-01-07 10:00:00'> > slow_report3.log
```

4）分析指含有select语句的慢查询

```sh
pt-query-digest --filter '$event->{fingerprint} =~ m/^select/i' /var/lib/mysql/slowtest-slow.log> slow_report4.log
```

5）针对某个用户的慢查询

```sh
pt-query-digest --filter '($event->{user} || "") =~ m/^root/i' /var/lib/mysql/slowtest-slow.log> slow_report5.log
```

6）查询所有所有的全表扫描或`full join`的慢查询

```sh
pt-query-digest --filter '(($event->{Full_scan} || "") eq "yes") ||(($event->{Full_join} || "") eq "yes")' /var/lib/mysql/slowtest-slow.log> slow_report6.log
```

### 报告分析

**第一部分：总体统计结果**

- `Overall`：总共有多少条查询
- `Time range`：查询执行的时间范围
- `unique`：唯一查询数量，即对查询条件进行参数化以后，总共有多少个不同的查询
- `total`：总计  min：最小  max：最大  avg：平均
- `95%`：把所有值从小到大排列，位置位于95%的那个数，这个数一般最具有参考价值
- `median`：中位数，把所有值从小到大排列，位置位于中间那个数

**第二部分：查询分组统计结果**

- `Rank`：所有语句的排名，默认按查询时间降序排列，通过--order-by指定
- `Query ID`：语句的ID，（去掉多余空格和文本字符，计算hash值）
- `Response`：总的响应时间
- `time`：该查询在本次分析中总的时间占比
- `calls`：执行次数，即本次分析总共有多少条这种类型的查询语句
- `R/Call`：平均每次执行的响应时间
- `V/M`：响应时间Variance-to-mean的比率
- `Item`：查询对象

**第三部分：每一种查询的详细统计结果**

由下面查询的详细统计结果，最上面的表格列出了执行次数、最大、最小、平均、95%等各项目的统计。

- `ID`：查询的ID号，和上图的Query ID对应
- `Databases`：数据库名
- `Users`：各个用户执行的次数（占比）
- `Query_time distribution` ：查询时间分布, 长短体现区间占比，本例中1s-10s之间查询数量是10s以上的两倍。
- `Tables`：查询中涉及到的表
- `Explain`：SQL语句

# Navicat实用功能

## 数据备份

[Navicat实用功能：数据备份与结构同步 (qq.com)](https://mp.weixin.qq.com/s?__biz=MzU1Nzg4NjgyMw==&mid=2247483745&idx=1&sn=bae7a292d30f3da7e9792de392d7c0ca&scene=21#wechat_redirect)

现在我们先对World数据库备份，备份完成后，删除表的数据，然后利用备份进行数据还原。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205261415372.png" alt="image-20220526141550324" style="zoom:67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205261415520.png" alt="image-20220526141501458" style="zoom: 67%;" />

删除原数据表内容后，进行还原备份

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205261416560.png" alt="image-20220526141658508" style="zoom:80%;" />

## 结构同步

就是让不同数据库具有相同的表和表结构

原来的mall-test模块中只有商品模块的表，现在我们经过了一段时间的开发，新增了订单模块，同时删除和修改了商品模块的一些表，而mall-prod表中还是原来的商品模块表，我们现在要做的是把mall-test的数据库表结构同步到mall-prod。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205261418765.png" alt="image-20220526141809716" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205261419134.png" alt="image-20220526141901062" style="zoom:67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205261419035.png" alt="image-20220526141925957" style="zoom:67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205261419224.png" alt="image-20220526141947133" style="zoom:67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205261420139.png" alt="image-20220526142008070" style="zoom:67%;" />

## 数据同步

上面只同步结构，这里选择同步数据

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205261426133.png" alt="image-20220526142617084" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205261424299.png" alt="image-20220526142423224" style="zoom:67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205261425752.png" alt="image-20220526142510701" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205261425978.png" alt="image-20220526142544925" style="zoom:67%;" />

## 数据生成

这个神器就是我们日常使用的 Navicat，但是最低是要在16版本，之前的版本是没有这个功能的（其实是我没有低版本，懒得测试了，哈哈）进入 Navicat Premium 16 工具 -> 数据生成

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304171535715.png" alt="image-20230417153535640" style="zoom:67%;" />

然后连接到数据库，选择你想造数据的表，选择需要造数据的字段，想造多少条都可以

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304171536033.png" alt="image-20230417153605934" style="zoom:80%;" />

> 注意：这边不要写太大，写1000就行，下图太大生成就会出错

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304171536039.png" alt="image-20230417153639971" style="zoom:80%;" />

你还可以对每个字段都设置想要的生成规则，例如：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304171537167.png" alt="image-20230417153717099" style="zoom: 80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304171537554.png" alt="image-20230417153737483" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304171539744.png" alt="image-20230417153952668" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304171538314.png" alt="image-20230417153858251" style="zoom:80%;" />

> 预览效果

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304171540549.png" alt="image-20230417154022466" style="zoom:80%;" />



# 定时备份数据方案（全库备份）

## 如何选择备份工具

根据备份的方法（是否需要数据库离线）可以将备份分为：

> - 热备（Hot Backup）
> - 冷备（Cold Backup）
> - 温备（Warm Backup）

MySQL 中进行不同方式的备份还要考虑存储引擎是否支持，如 MyISAM 不支持热备，支持温备和冷备。而 InnoDB 支持热备、温备和冷备。一般情况下，我们需要备份的数据分为以下几种：

> - 表数据
> - 二进制日志、InnoDB 事务日志
> - 代码（存储过程、存储函数、触发器、事件调度器）
> - 服务器配置文件

下面是几种常用的备份工具：

> - mysqldump：逻辑备份工具，适用于所有的存储引擎，支持温备、完全备份、部分备份、对于 InnoDB 存储引擎支持热备。
> - cp、tar 等归档复制工具：物理备份工具，适用于所有的存储引擎、冷备、完全备份、部分备份。
> - lvm2 snapshot：借助文件系统管理工具进行备份。
> - mysqlhotcopy：名不副实的一个工具，仅支持 MyISAM 存储引擎。
> - xtrabackup：一款由 percona 提供的非常强大的 InnoDB/XtraDB 热备工具，支持完全备份、增量备份。

直接复制数据文件是最为直接、快速的备份方法，但缺点是基本上不能实现增量备份。备份时必须确保没有使用这些表。如果在复制一个表的同时服务器正在修改它，则复制无效。备份 文件时，最好关闭服务器，然后重新启动服务器。

## 数据备份命令⭐

### 命令分析

在MySQL中提供了命令行导出数据库数据以及文件的一种方便的工具mysqldump,我们可以通过命令行直接实现数据库内容的导出dump,首先我们简单了解一下mysqldump命令用法:

```sql
# MySQLdump常用
mysqldump -u root -p --databases 数据库1 数据库2 > xxx.sql
```

### 常用操作示例

```sql
-- 1.备份全部数据库的数据和结构
mysqldump -uroot -p123456 -A > /data/mysqlDump/mydb.sql

-- 2.备份全部数据库的结构（加 -d 参数）
mysqldump -uroot -p123456 -A -d > /data/mysqlDump/mydb.sql

-- 3.备份全部数据库的数据(加 -t 参数)
mysqldump -uroot -p123456 -A -t > /data/mysqlDump/mydb.sql

-- 4.备份单个数据库的数据和结构(数据库名mydb)
mysqldump -uroot-p123456 mydb > /data/mysqlDump/mydb.sql

-- 5.备份单个数据库的结构
mysqldump -uroot -p123456 mydb -d > /data/mysqlDump/mydb.sql

-- 6.备份单个数据库的数据
mysqldump -uroot -p123456 mydb -t > /data/mysqlDump/mydb.sql

-- 7.备份多个表的数据和结构（数据，结构的单独备份方法与上同）
mysqldump -uroot -p123456 mydb t1 t2 > /data/mysqlDump/mydb.sql

-- 8.一次备份多个数据库
mysqldump -uroot -p123456 --databases db1 db2 > /data/mysqlDump/mydb.sql
```

### 还原备份内容

有两种方式还原，第一种是在MySQL命令行中，第二种是使用SHELL行完成还原

1.在系统命令行中，输入如下实现还原：

```sql
mysql -uroot -p123456 < /data/mysqlDump/mydb.sql
```

2.在登录进入mysql系统中,通过source指令找到对应系统中的文件进行还原：

```sql
mysql> source /data/mysqlDump/mydb.sql
```

## 脚本实现⭐

在linux中，通常使用BASH脚本对需要执行的内容进行编写，加上定时执行命令crontab实现日志自动化生成。

以下代码功能就是针对mysql进行备份，配合crontab，实现备份的内容为近一个月（31天）内的每天的mysql数据库记录。

### 编写BASH维护固定数量备份文件

在Linux中，使用vi或者vim编写脚本内容并命名为：`mysql_dump_script.sh`

```sh
#!/bin/bash
#保存备份个数，备份31天数据
number=31
#备份保存路径
backup_dir=/root/mysqlbackup
#日期
dd=`date +%Y-%m-%d-%H-%M-%S`
#备份工具
tool=mysqldump
#用户名
username=root
#密码
password=123456
#将要备份的数据库
database_name=edoctor

#如果文件夹不存在则创建
if [ ! -d $backup_dir ]; 
then     
    mkdir -p $backup_dir; 
fi

# 简单写法  mysqldump -u root -p123456 users > /root/mysqlbackup/users-$filename.sql
$tool -u $username -p$password $database_name > $backup_dir/$database_name-$dd.sql

# 写创建备份日志
echo "create $backup_dir/$database_name-$dd.dump" >> $backup_dir/log.txt

# 找出需要删除的备份
delfile=`ls -l -crt  $backup_dir/*.sql | awk '{print $9 }' | head -1`

# 判断现在的备份数量是否大于$number
count=`ls -l -crt  $backup_dir/*.sql | awk '{print $9 }' | wc -l`

if [ $count -gt $number ]
then
  #删除最早生成的备份，只保留number数量的备份
  rm $delfile
  #写删除文件日志
  echo "delete $delfile" >> $backup_dir/log.txt
fi
```

如上代码主要含义如下：

> 1.首先设置各项参数，例如number最多需要备份的数目，备份路径，用户名，密码等。
>
> 2.执行mysqldump命令保存备份文件，并将操作打印至同目录下的log.txt中标记操作日志。
>
> 3.定义需要删除的文件：通过ls命令获取第九列，即文件名列，再通过

```apl
head -1
```

实现定义操作时间最晚的那个需要删除的文件。

4.定义备份数量：通过ls命令加上

```apl
wc -l
```

统计以sql结尾的文件的行数。

5.如果文件超出限制大小，就删除最早创建的sql文件

### 使用crontab定期执行备份脚本

在LINUX中，周期执行的任务一般由cron这个守护进程来处理`[ps -ef|grep cron]`。cron读取一个或多个配置文件，这些配置文件中包含了命令行及其调用时间。

cron的配置文件称为“crontab”，是“cron table”的简写。

#### cron服务

cron是一个linux下 的定时执行工具，可以在无需人工干预的情况下运行作业。

```c
service crond start    //启动服务
service crond stop     //关闭服务
service crond restart  //重启服务
service crond reload   //重新载入配置
service crond status   //查看服务状态 
```

#### crontab语法

> crontab命令用于安装、删除或者列出用于驱动cron后台进程的表格。用户把需要执行的命令序列放到crontab文件中以获得执行。每个用户都可以有自己的crontab文件。`/var/spool/cron`下的crontab文件不可以直接创建或者直接修改。该crontab文件是通过crontab命令创建的。
>

> 在crontab文件中如何输入需要执行的命令和时间。该文件中每行都包括六个域，其中前五个域是指定命令被执行的时间，最后一个域是要被执行的命令。
>

每个域之间使用空格或者制表符分隔。格式如下：

```apl
minute hour day-of-month month-of-year day-of-week commands 
```

合法值 `00-59 00-23 01-31 01-12 0-6 (0 is sunday)`

除了数字还有几个个特殊的符号就是"`*`"、"`/`"和"`-`"、"`,`"，`*`代表所有的取值范围内的数字，"`/`"代表每的意思,"`/5`"表示每5个单位，"`-`"代表从某个数字到某个数字,"`,`"分开几个离散的数字。

- `-l` 在标准输出上显示当前的crontab。
- `-r` 删除当前的crontab文件。
- `-e` 使用VISUAL或者EDITOR环境变量所指的编辑器编辑当前的crontab文件。当结束编辑离开时，编辑后的文件将自动安装。

#### 创建cron脚本

第一步：写cron脚本文件,命名为mysqlRollBack.cron。

`15,30,45,59 * * * * echo "xgmtest....." >> xgmtest.txt` 表示，每隔15分钟，执行打印一次命令

第二步：添加定时任务。执行命令 “`crontab crontest.cron`”。搞定

第三步："`crontab -l`" 查看定时任务是否成功或者检测`/var/spool/cron`下是否生成对应cron脚本

> 注意：这操作是直接替换该用户下的crontab，而不是新增

定期执行编写的定时任务脚本（记得先给shell脚本执行权限）

```apl
0 2 * * * /root/mysql_backup_script.sh
```

随后使用crontab命令定期指令编写的定时脚本

```apl
crontab mysqlRollback.cron
```

再通过命令检查定时任务是否已创建：

```apl
crontab -l
```

#### 执行效果截图

以下是我的测试每分钟的截图效果，其对应代码如下：

```apl
* * * * * /root/mysql_backup_script.sh
```

效果截图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.30/202207291712639.png" alt="image-20220729171223513" style="zoom:67%;" />

其中的log.txt记录备份的操作详细日志：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.30/202207291712064.png" alt="image-20220729171234990" style="zoom:80%;" />

# 监控状态指标(status)

> MySQL Status提供服务器状态信息，是单纯的累计数（如重启就会重置），表面上只能体现多和少。但这些统计值，如zabbix，prometheus监控平台一样，通过某个时间间隔的差值，体现MySQL某种偏向的执行情况。比如临时表使用比较多，底层page交换频繁凡 等。Status统计信息是日常监控的部分核心数据，也是问题排查中非常有意义的参考数据。Status计数，不仅是监控需要的指标，也是日常排查问题的一种判断推理依据。

语法

```apl
SHOW [GLOBAL | SESSION] STATUS [LIKE 'pattern' | WHERE expr]
```

例子

```sql
show status like 'Com_insert';
show status like 'uptime';
```

## 查看所有状态

```apl
show  global status;
```

## 执行情况

> 性能指标（TPS，QPS）是衡量数据库的能力的一个标准。这些指标依据也是通过Status里计算的。
> QPS（Queries Per Second，每秒查询数）=Com_select
> TPS（Transactions Per Second，每秒处理事务数）=Com_insert + Com_delete + Com_update

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206221153866.png" alt="image-20220622115354787" style="zoom:67%;" />

```sql
# 查看多个指标
show status like 'Com_______';
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206221200051.png" alt="image-20220622120050987" style="zoom:67%;" />

## SQL质量情况

对于mysql来说随着数据量增加 全表扫描，不使用索引，排序，回滚 这些现象对于MySQL是最致命的。大量消耗mysql处理能力，服务器资源（硬盘io，cpu资源 等）。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206221154994.png" alt="image-20220622115424779" style="zoom:67%;" />

```sql
show status like 'Slow%';
```

## 临时表利用率

临时表多，说明多表join产生大量的中间表，排序无索引，聚合等。最终会趋向于语句执行越来越慢 等问题。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206221154397.png" alt="image-20220622115444326" style="zoom:67%;" />

关注下临时表设置是否合理(tmp_table_size，max_heap_table_size）,临时表缓存 大概16M~128M既可以，如果已经非常大，说明SQL要进行优化.

```sql
show status like 'Created%';
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.10.30/202209221707754.png" alt="image-20220922170741603" style="zoom:80%;" />

## 文件表数量

说明底层ibd，frm 文件太多 或 操作系统 /etc/security/limits.conf设置太小导致

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206221155384.png" alt="image-20220622115517290" style="zoom:67%;" />

需要协调的参数有5个需要按照实际情况进行调整：

> innodb_open_files
> open_files_limit
> table_open_cache
> table_open_cache_instances
> table_space_definition_cache

## 底层page相关操作

innodb引擎对于page的操作。

特别是Handler_read_rnd_next 对于性能影响非常大。主要体现SQL语句方面不使用索引，全表扫描情况。大数据量随机读之类的。
<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206221155861.png" alt="image-20220622115553787" style="zoom:67%;" />

## binlog情况

binlog是逻辑写入，一旦变更量多之后（insert，delete，update，ddl），binlog缓存刷新频率过高，影响一定的性能，带来迟缓效应。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206221156503.png" alt="image-20220622115617432" style="zoom:67%;" />

binlog_cache_size默认是32k，建议范围在1M~16M以内 ，如果超过这个值 就会使用临时表，所以MySQL不适合一些大事务。

## 线程

线程信息往往代表mysql链接情况。比如频繁的短连接可能对于mysql穷住，内存无法释放等问题。
当前执行的线程数也不能太多，会达到处理的瓶颈。
<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206221156960.png" alt="image-20220622115646890" style="zoom:67%;" />

## 链接错误

当通信故障错误出现时，MySQL的状态变量Aborted_clients和Aborted_connects的计数会增加。这两个状态变量描述了链接中断，登录MySQL失败的计数。

客户端无权限,密码有误,连接包错误,连接时间限制，客户端没有进行关闭,突然终止 等。
参数timeout不合理也会出现这些值上升。（connect_timeout，wait_timeout，interactive_timeout net_read_timeout，net_write_timeout）
<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206221157247.png" alt="image-20220622115713183" style="zoom:67%;" />

## DDL语言情况

经验告诉，在MySQL使用触发器，存储过程，函数等存在很多隐患。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206221157858.png" alt="image-20220622115737783" style="zoom:67%;" />

## 连接数（Connects）

```sql
# 最大使用连接数
show status like 'Max_used_connections';
# 当前打开的连接数
show status like 'Threads_connected';
```

## 缓存

- 未从缓冲池读取的次数：show status like ‘Innodb_buffer_pool_reads’
- 从缓冲池读取的次数：show status like ‘Innodb_buffer_pool_read_requests’
- 缓冲池的总页数：show status like ‘Innodb_buffer_pool_pages_total’
- 缓冲池空闲的页数：show status like ‘Innodb_buffer_pool_pages_free’
- 缓存命中率计算：（1-Innodb_buffer_pool_reads/Innodb_buffer_pool_read_requests）*100%
- 缓存池使用率为：((Innodb_buffer_pool_pages_total-Innodb_buffer_pool_pages_free）/Innodb_buffer_pool_pages_total）*100%

## 吞吐（Database throughputs）

- 发送吞吐量：show status like 'Bytes_sent'
- 接收吞吐量：show status like 'Bytes_received'
- 总吞吐量：Bytes_sent+Bytes_received

## 其他

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206221158957.png" alt="image-20220622115800875" style="zoom:67%;" />





























































































