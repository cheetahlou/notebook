





# 常用缓存技术

> 俗话说，**计算机编程的任何问题，都可以通过增加一个抽象层来解决**，这句话用在我身上就太合适了。 我是缓存(Cache)，今天我给大家聊聊我这个抽象层是怎么工作的。 提到我的名字，你可能立刻会想到到Redis， 因为它实在是太普及了，但是如果你只想到Redis，那视野未必有点狭窄，Redis仅仅是我在应用层小试牛刀而已。 

> Wikipedia上说我是一种用来保存数据的硬件或者软件，这样以后的访问请求就可以更快地返回。 这个定义还真是挺抽象的，抽象的东西让人感觉不好理解，我得给大家举几个例子。 为了突出我的位置， 在下面的图片中，缓存都用蓝色来表示。 首先来看大家日常使用很多，但是又不太在意的浏览器缓存。 

## 浏览器缓存

> 浏览器面对的问题是**网络访问的速度远远低于本地访问的速度**，**每次都访问网络开销太大。**于是它就请我增加了一个中间层：**开辟“缓存”区域，缓存JS, HTML, CSS，图片等各种文件**。 

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202303061038627.png" alt="image-20230306103837543" style="zoom:80%;" />

> 当然，浏览器这家伙也不能乱来，得遵循一定的规则来判断什么时候用缓存中的文件，什么时候不辞辛苦地去访问服务器的新文件。 这其中的关键点就是HTTP协议： 

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202303061039217.png" alt="image-20230306103905135" style="zoom:80%;" />

> 在服务器发给浏览器的响应中，有expires, max-age, last-modified, Etag等Header， 粗略来说，**expires 和 max-age 定义了一个资源的过期时间， last-modified和Etag用来检查一个资源在服务器端有没有变化**。 

> 对于它们的含义和详细用法，网上资料多如牛毛，我这里就不再展开了。 我觉得有趣的事情是这些： 

1. 当你在地址栏中输入网址，按回车以后 浏览器会使用Expires，max-age来查看本地缓存的内容是否失效，如果没有，就直接使用  

2. 当你按F5或者按浏览器刷新按钮的时候 浏览器不再考虑Expires，max-age， 而是把Last-Modified / ETag 发到服务器去，问问服务器，这个文件有更新没有？如果没有，那就用本地缓存的文件，如果有更新，用服务器端最新的。 

3. 当你用Ctrl + F5强制刷新的时候 不使用任何缓存，向服务器发出全新请求。 

## CDN

> 说起CDN，可能很多人都意识不到它的存在，这也难怪，它对于大家来说几乎是透明的，魔法发生在DNS的域名解析的过程。 但是CDN也是不折不扣的缓存。 **由于网络情况复杂，如果客户端离服务器比较远，网速慢，体验会很差；海量的用户给后端服务器带来巨大压力**，所以CDN就采用了就近访问的方案： 

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202303061040514.png" alt="image-20230306104011373" style="zoom:80%;" />

> 把**后端服务器的数据数据复制多份，挪到离客户端比较近的“边缘”服务器中，就近访问**，不但减少了访问的时间，还大大降低了 “中央”服务器的负载。 

> 浏览器缓存和CDN是配合使用的， 浏览器的本地缓存失效以后，就需要向后端服务器来获取了，但是如果一个系统有CDN，那浏览器还可以就近访问CDN。 

## Linux Page Cache

> 在操作系统的世界中，时间是按纳秒，微秒为单位的，虽然内存和硬盘都在同一台机器中，没有网络开销，**但是硬盘实在是太慢，比内存慢几万倍， 内存等不及**。 所以Linux也增加了一个抽象层：**Page cache** ， 把慢如蜗牛的硬盘的文件缓存在其中。 

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202303061040267.png" alt="image-20230306104043210" style="zoom:80%;" />

> 有了这个抽象层， 在Linux当中，几乎所有的文件读写操作都依赖Page Cache，在向硬盘写入文件的时候，并不是直接把文件内容写入硬盘以后才返回的，而是写入到内核的Page Cache就直接返回了。 

> 这个Page Cache会被标记为“Dirty”，随后由内核线程写入硬盘（也可以通过手工用sync命令写入）。 各位看官可以想想，如果Page cache 的数据还没有写入硬盘，就断电了，会发生什么事情？ 该怎么处理？

> 当从硬盘读取文件时，也不是直接把数据从硬盘复制到用户态的内存，而是先复制到内核的Page Cache ，然后再复制到用户态的内存。 正是由于这样复制来复制去，在多个进程中间进行数据传输很麻烦，例如（一个进程读取文件，然后通过Socket发送） ，所以后来就出现了零复制技术， 参见文章《[操作系统和Web服务器那点儿事儿](http://mp.weixin.qq.com/s?__biz=MzAxOTc0NzExNg==&mid=2665515079&idx=1&sn=ad7a5a0cb4d85fdb90ef3cb42fde0d63&chksm=80d67004b7a1f912556d87c79b76df162d0e31094caf02bf1bcbb9cb6ff96c4b4c47806e9059&scene=21#wechat_redirect)》 

## 应用程序缓存

> 终于来到了大家熟悉的应用程序缓存， 这个就不用我多说了， 因为数据库访问速度慢，无法应对大量的并发访问，所以增加一个缓存中间层，把热点数据从数据库中取出，放到可以快速访问的内存当中。 

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202303061041516.png" alt="image-20230306104143457" style="zoom:80%;" />

大名鼎鼎的Redis干的就是这个活。 可是应用程序的缓存也是个双刃剑，提升了访问的效率， 但是带来了很多复杂性：

> 1. 代码变复杂 
>
> 2. 需要处理缓存和数据库之间的数据一致性的问题 
>
> 3. 处理缓存的穿透，雪崩等问题 
>
> 4. 应用程序缓存现在已经变成了分布式的集群形式，数据的管理越来越麻烦。 

## CPU缓存

> 前面刚说到内存比硬盘快几万倍， **可是在CPU面前，内存也只能屈居下风，CPU比内存快100多倍，数据和指令必须从内存加载到CPU才能执行， 这次轮到CPU等不及了**。 

> 那就在CPU内增加缓存中间层，不过这次必须用硬件来实现。 CPU的缓存包括L1，L2, L3这三级Cache，把最热点的数据和指令放入到其中。 

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202303061042764.png" alt="image-20230306104254688" style="zoom:80%;" />

> 我猜CPU Cache可能是最“底层”的Cache了。 在L1 Cache 最靠近CPU，速度最快，可以分为指令Cache (CPU要执行的指令)和数据Cache（指令要操作的数据）。 

> CPU Cache 和上面提到的各种Cache比起来，小得可怜，也就是几百K到几M。 所以这些Cache要想发挥真正的作用，必须得依赖上帝的规矩局部性原理：

>  (1)  **时间局部性**：如果程序中的某条指令一旦执行，则不久之后该指令可能再次被执行；如果某数据被访问，则不久之后该数据可能再次被访问。 

> (2) **空间局部性**：指一旦程序访问了某个存储单元，则不久之后。其附近的存储单元也将被访问。 

最后总结一下放置在我这里的数据的特点，大家可以感受下： 

> （1）对数据的读操作远大于写操作 
>
> （2）数据可能是之前的计算结果（计算过程比较耗时）
>
> （3）数据是某个（速度较慢的）数据源的数据备份。
>
> （4）数据访问遵循上帝的规矩“局部性原理” 

如果你在工作中也遇到了问题，不妨考虑一下，看看能不能用我来解决问题：**增加一个中间层， 用空间来换取时间**。





# Lua语法入门

Nginx编程需要用到Lua语言，因此我们必须先入门Lua的基本语法。

## 初识Lua

Lua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。官网：https://www.lua.org/

![image-20210821091437975](https://edu-8673.oss-cn-beijing.aliyuncs.com/img/image-20210821091437975.png)

Lua经常嵌入到C语言开发的程序中，例如游戏开发、游戏插件等。

Nginx本身也是C语言开发，因此也允许基于Lua做拓展。

### Lua的安装

在linux上安装Lua非常简单，只需要下载源码包并在终端解压、编译即可使用。

> Lua的官网地址为:`https://www.lua.org`

![1604649954522](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204301712888.png)

1. 点击download可以找到对应版本的下载地址，我们本次课程采用的是lua-5.3.5,其对应的资源链接地址为https://www.lua.org/ftp/lua-5.4.1.tar.gz,也可以使用wget命令直接下载:

```apl
wget https://www.lua.org/ftp/lua-5.4.1.tar.gz --no-check-certificate
```

2. 编译安装

```apl
tar -xvf lua-5.4.1.tar.gz
cd lua-5.4.1
make linux test
make install
```

如果在执行make linux test失败

说明当前系统缺少libreadline-dev依赖包，需要通过命令来进行安装

```apl
yum install -y readline-devel
```

### 验证是否安装成功

```apl
lua -v
```



## HelloWorld

**CentOS7默认已经安装了Lua语言环境，所以可以直接运行Lua代码**。

1）在Linux虚拟机的任意目录下，新建一个hello.lua文件

![image-20210821091621308](https://edu-8673.oss-cn-beijing.aliyuncs.com/img/image-20210821091621308.png)

2）添加下面的内容

```lua
print("Hello World!")  
```

3）运行

![image-20210821091638140](https://edu-8673.oss-cn-beijing.aliyuncs.com/img/image-20210821091638140.png)



# Lua基础语法

## 数据类型

### 基本类型

Lua中支持的常见数据类型包括：

![image-20210821091835406](https://edu-8673.oss-cn-beijing.aliyuncs.com/img/image-20210821091835406.png)

### 判断类型type

> 另外，Lua提供了type()函数来判断一个变量的数据类型

![image-20210821091904332](https://edu-8673.oss-cn-beijing.aliyuncs.com/img/image-20210821091904332.png)

```lua
print(type("Hello world"))      --> string
print(type(10.4*3))             --> number
print(type(print))              --> function
print(type(type))               --> function
print(type(true))               --> boolean
print(type(nil))                --> nil
print(type(type(X)))            --> string
```



## 变量和循环⭐⭐

学习任何语言必然离不开变量，而变量的声明必须先知道数据的类型。

### 声明变量

Lua声明变量的时候**无需指定数据类型**，而是**用local来声明变量为局部变量**：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209151252846.png" alt="image-20220915125233770" style="zoom:80%;" />

```lua
-- 声明字符串，可以用单引号或双引号，
local str = 'hello'
-- 字符串拼接可以使用 ..
local str2 = 'hello' .. 'world'
-- 声明数字
local num = 21
-- 声明布尔类型
local flag = true
```

Lua中的table类型既可以作为数组，又可以作为Java中的map来使用。数组就是特殊的table，key是数组角标而已：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209151254921.png" alt="image-20220915125416882" style="zoom:80%;" />

```lua
-- 声明数组 ，key为角标的 table
local arr = {'java', 'python', 'lua'}
-- 声明table，类似java的map
local map =  {name='Jack', age=21}
```

Lua中的数组角标是从1开始，访问的时候与Java中类似：

```lua
-- 访问数组，lua数组的角标从1开始
print(arr[1])
```

Lua中的table可以用key来访问：

```lua
-- 访问table
print(map['name'])
print(map.name)
```



### 循环⭐

对于table，我们可以利用for循环来遍历。不过数组和普通table遍历略有差异。

#### 遍历数组

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209151255612.png" alt="image-20220915125511570" style="zoom:80%;" />

```lua
-- 声明数组 key为索引的 table
local arr = {'java', 'python', 'lua'}
-- 遍历数组
for index,value in ipairs(arr) do
    print(index, value) 
end
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5/202205031341737.png" alt="image-20220503134132663" style="zoom:80%;" />

#### 遍历table

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209151255225.png" alt="image-20220915125544178" style="zoom:80%;" />

```lua
-- 声明map，也就是table
local map = {name='Jack', age=21}
-- 遍历table
for key,value in pairs(map) do
   print(key, value) 
end
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5/202205031342974.png" alt="image-20220503134200897" style="zoom:80%;" />



#### 普通for循环

数值型for循环

语法

```apl
for param=exp1,exp2,exp3 do
 循环体
end
```

param的值从exp1变化到exp2之前的每次循环会执行 循环体，并在每次循环结束后将步长(step)exp3增加到param上。exp3可选，如果不设置默认为1

```apl
for i = 1,100,10 do
	print(i)
end
```



#### while循环

顾名思义，当条件为真时 while 循环会重复执行其循环体。 Lua 语言先测试 while 语句 的条件，若条件为假则循环结束；否则， Lua 会执行循环体并不断地重复这个过程。

语法：

```apl
while 条件 do
  循环体
end
```

例子:实现数组的循环

```lua
function testWhile()
    local i = 1
    while i<=10 do
    print(i)
    i=i+1
  end
end
```



## 注释

关于Lua的注释要分两种，第一种是单行注释，第二种是多行注释。

单行注释的语法为：

```apl
--注释内容
```

多行注释的语法为:

```apl
--[[
	注释内容
	注释内容
--]]
```

如果想取消多行注释，只需要在第一个--之前在加一个-即可，如：

```apl
---[[
	注释内容
	注释内容
--]]
```



## 关键字

下列是Lua的关键字，大家在定义常量、变量或其他用户自定义标识符都要避免使用以下这些关键字：

| and      | break | do    | else   |
| -------- | ----- | ----- | ------ |
| elseif   | end   | false | for    |
| function | if    | in    | local  |
| nil      | not   | or    | repeat |
| return   | then  | true  | until  |
| while    | goto  |       |        |

一般约定，以下划线开头连接一串大写字母的名字（比如 _VERSION）被保留用于 Lua 内部全局变量。这个也是上面我们不建议这么定义标识符的原因。

## 运算符

Lua中支持的运算符有算术运算符、关系运算符、逻辑运算符、其他运算符。

### 算术运算符

```apl
+   加法
-	减法
*	乘法
/	除法
%	取余
^	乘幂
-	负号
```

例如:

```apl
10+20	-->30
20-10	-->10
10*20	-->200
20/10	-->2
3%2		-->1
10^2	-->100
-10		-->-10
```

### 关系运算符

```apl
==	等于
~=	不等于
>	大于
<	小于
>=	大于等于
<=	小于等于
```

例如:

```apl
10==10		-->true
10~=10		-->false
20>10		-->true
20<10		-->false
20>=10		-->true
20<=10		-->false
```

### 逻辑运算符

```apl
and	逻辑与	 A and B     &&   
or	逻辑或	 A or B     ||
not	逻辑非  取反，如果为true,则返回false  !
```

逻辑运算符可以作为if的判断条件，返回的结果如下:

```apl
A = true
B = true

A and B	-->true
A or  B -->true
not A 	-->false

A = true
B = false

A and B	-->false
A or  B -->true
not A 	-->false

A = false
B = true

A and B	-->false
A or  B -->true
not A 	-->true

```

### 其他运算符

```apl
..	连接两个字符串
#	一元预算法，返回字符串或表的长度
```

例如:

```apl
> "HELLO ".."WORLD"		-->HELLO WORLD
> #"HELLO"			-->5
```

## 全局变量&局部变量

在Lua语言中，全局变量无须声明即可使用。在默认情况下，变量总是认为是全局的，如果未提前赋值，默认为nil:

![1604650220670](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204301712247.png)

要想声明一个局部变量，需要使用local来声明

![1604650235860](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022/202204301712252.png)





## 条件控制、函数

> Lua中的条件控制和函数声明与Java类似

### 函数

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209151301889.png" alt="image-20220915130140850" style="zoom:80%;" />

```lua
function 函数名(argument1, argument2..., argumentn)
    -- 函数体
    return 返回值
end
```

例如，定义一个函数，用来打印数组：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209151302859.png" alt="image-20220915130203819" style="zoom:80%;" />

```lua
function printArr(arr)
    for index, value in ipairs(arr) do
        print(index,value)
    end
end

local arr = {'java', 'python', 'lua'}
printArr(arr)
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5/202205031522551.png" alt="image-20220503152225482" style="zoom:80%;" />

### if条件控制

类似Java的条件控制，例如if、else语法：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209151302617.png" alt="image-20220915130226577" style="zoom:80%;" />

```lua
if(布尔表达式)
then
   --[ 布尔表达式为 true 时执行该语句块 --]
else
   --[ 布尔表达式为 false 时执行该语句块 --]
end
```

与java不同，布尔表达式中的逻辑运算是基于英文单词：

![image-20210821092657918](https://edu-8673.oss-cn-beijing.aliyuncs.com/img/image-20210821092657918.png)

### 案例

> 需求：自定义一个函数，可以打印table，当参数为nil时，打印错误信息

```lua
function printArr(arr)
    if not arr then
        print('数组不能为空！')
    end
    for index, value in ipairs(arr) do
        print(value)
    end
end
```



# Java 本地缓存技术

## 1 HashMap

通过Map的底层方式，直接将需要缓存的对象放在内存中。

- 优点：简单粗暴，不需要引入第三方包，比较适合一些比较简单的场景。
- 缺点：没有缓存淘汰策略，定制化开发成本高。

```java
import java.util.LinkedHashMap;
import java.util.Map;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantReadWriteLock;

public class LRUCache extends LinkedHashMap {

    /**
     * 可重入读写锁，保证并发读写安全性
     */
    private ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock();
    private Lock readLock = readWriteLock.readLock();
    private Lock writeLock = readWriteLock.writeLock();

    /**
     * 缓存大小限制
     */
    private int maxSize;

    public LRUCache(int maxSize) {
        super(maxSize + 1, 1.0f, true);
        this.maxSize = maxSize;
    }

    @Override
    public Object get(Object key) {
        readLock.lock();
        try {
            return super.get(key);
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public Object put(Object key, Object value) {
        writeLock.lock();
        try {
            return super.put(key, value);
        } finally {
            writeLock.unlock();
        }
    }

    @Override
    protected boolean removeEldestEntry(Map.Entry eldest) {
        return this.size() > maxSize;
    }
}
```

## 2 Guava Cache

Guava Cache是由Google开源的基于LRU替换算法的缓存技术。但Guava Cache由于被下面即将介绍的Caffeine全面超越而被取代，因此不特意编写示例代码了，有兴趣的读者可以访问Guava Cache主页。

- 优点：支持最大容量限制，两种过期删除策略（插入时间和访问时间），支持简单的统计功能。
- 缺点：springboot2和spring5都放弃了对Guava Cache的支持。

## 3 Caffeine

Caffeine采用了W-TinyLFU（LUR和LFU的优点结合）开源的缓存技术。缓存性能接近理论最优，属于是Guava Cache的增强版。

```java
import com.github.benmanes.caffeine.cache.Cache;
import com.github.benmanes.caffeine.cache.Caffeine;
import java.util.concurrent.TimeUnit;

public class CaffeineCacheTest {

    public static void main(String[] args) throws Exception {
        //创建guava cache
        Cache<String, String> loadingCache = Caffeine.newBuilder()
                //cache的初始容量
                .initialCapacity(5)
                //cache最大缓存数
                .maximumSize(10)
                //设置写缓存后n秒钟过期
                .expireAfterWrite(17, TimeUnit.SECONDS)
                //设置读写缓存后n秒钟过期,实际很少用到,类似于expireAfterWrite
                //.expireAfterAccess(17, TimeUnit.SECONDS)
                .build();
        String key = "key";
        // 往缓存写数据
        loadingCache.put(key, "v");

        // 获取value的值，如果key不存在，获取value后再返回
        String value = loadingCache.get(key, CaffeineCacheTest::getValueFromDB);

        // 删除key
        loadingCache.invalidate(key);
    }

    private static String getValueFromDB(String key) {
        return "v";
    }
}
```

## 4 Encache

Ehcache是一个纯java的进程内缓存框架，具有快速、精干的特点。是hibernate默认的cacheprovider。

- 优点：支持多种缓存淘汰算法，包括LFU，LRU和FIFO；缓存支持堆内缓存，堆外缓存和磁盘缓存；支持多种集群方案，解决数据共享问题。
- 缺点：性能比Caffeine差

```java
public class EncacheTest {

    public static void main(String[] args) throws Exception {
        // 声明一个cacheBuilder
        CacheManager cacheManager = CacheManagerBuilder.newCacheManagerBuilder()
                .withCache("encacheInstance", CacheConfigurationBuilder
                        //声明一个容量为20的堆内缓存
                        .newCacheConfigurationBuilder(String.class,String.class, 
                                                      ResourcePoolsBuilder.heap(20)))
                .build(true);
        // 获取Cache实例
        Cache<String,String> myCache =  cacheManager.getCache("encacheInstance", 
                                                              String.class, String.class);
        // 写缓存
        myCache.put("key","v");
        // 读缓存
        String value = myCache.get("key");
        // 移除换粗
        cacheManager.removeCache("myCache");
        cacheManager.close();
    }
}
```

## 5 性能比对

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.12.30/202212042125668.png" alt="image-20221204212549584" style="zoom:80%;" />

在Caffeine的官网介绍中，Caffeine在性能和功能上都与其他几种方案相比具有优势，因此接下来主要探讨Caffeine的性能和实现原理。



# 本地缓存之王——Caffeine

[Java 本地缓存选它就对了：Caffeine 永远的王者！还没整理，到这个再说](https://mp.weixin.qq.com/s?__biz=MzI4Njc5NjM1NQ==&mid=2247536713&idx=2&sn=453a8c3b69a72d61c05f9370ff6fa0d1&chksm=ebd56f65dca2e67346ae10166bd451dc7aa53f040ac8db947e557314e62f2d03272735021bbc&mpshare=1&scene=23&srcid=0304aIPCnaGURJv4rAf5G94i&sharer_sharetime=1677907544770&sharer_shareid=29b8a04db1dbd975e3bf4e9f47e7ac67#rd)

> 结论：**Caffeine 是目前性能最好的本地缓存，因此，在考虑使用本地缓存时，直接选择 Caffeine 即可。**

## 初识Caffeine

先看一个小例子，明白如何创建一个 Caffeine 缓存实例。

```xml
<dependency>
    <groupId>com.github.ben-manes.caffeine</groupId>
    <artifactId>caffeine</artifactId>
</dependency>
```

```java
@Test
void init() {
    Caffeine<Object, Object> caffeine = Caffeine.newBuilder()
            .initialCapacity(3)
            .maximumSize(4);
    Cache<Object, Object> cache = caffeine.build();
    cache.put("aa", 13);
    System.out.println(cache.getIfPresent("aa"));
}
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.12.30/202212021047915.png" alt="image-20221202104745849" style="zoom:80%;" />

> Caffeine 相当于一个缓存工厂，可以创建出多个缓存实例 Cache。这些缓存实例都继承了 Caffeine 的参数配置，Caffeine 是如何配置的，这些缓存实例就具有什么样的特性和功能。

## 1. Caffeine 可以设置的属性

### 1. 缓存初始容量

**initialCapacity**：整数，表示能存储多少个缓存对象。

> 为什么要设置初始容量呢？因为如果提前能预估缓存的使用大小，那么可以设置缓存的初始容量，以免缓存不断地进行扩容，致使效率不高。

### 2. 最大容量 最大权重

**maximumSize**：最大容量，如果缓存中的数据量超过这个数值，Caffeine 会有一个异步线程来专门负责清除缓存，按照指定的清除策略来清除掉多余的缓存。

> 注意：比如最大容量是 2，此时已经存入了2个数据了，此时存入第3个数据，触发异步线程清除缓存，在清除操作没有完成之前，缓存中仍然有3个数据，且 3 个数据均可读，缓存的大小也是 3，只有当缓存操作完成了，缓存中才只剩 2 个数据，至于清除掉了哪个数据，这就要看清除策略了。

**maximumWeight**：最大权重，存入缓存的每个元素都要有一个权重值，当缓存中所有元素的权重值超过最大权重时，就会触发异步清除。

下面给个例子：

```java
@Data
@NoArgsConstructor
@AllArgsConstructor
public class Person1 {
    public Integer age;
    public String name;
}
```

```java
@Test
void init() throws InterruptedException {
    Caffeine<String, Person1> caffeine = Caffeine.newBuilder()
            .maximumWeight(30)
            .weigher((String key, Person1 value)-> value.getAge());

    Cache<String, Person1> cache = caffeine.build();
    cache.put("one", new Person1(12, "one"));
    cache.put("two", new Person1(18, "two"));
    cache.put("three", new Person1(1, "three"));

    Thread.sleep(10);
    System.out.println(cache.estimatedSize());
    System.out.println(cache.getIfPresent("two"));
}
```

运行结果：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.12.30/202212021055478.png" alt="image-20221202105551431" style="zoom:80%;" />

要使用权重来衡量的话，就要规定权重是什么，每个元素的权重怎么计算，weigher 方法就是设置权重规则的，它的参数是一个函数，函数的参数是 key 和 value，函数的返回值就是元素的权重，比如上述代码中，caffeine 设置了最大权重值为 30，然后将每个 Person 对象的 age 年龄作为权重值，所以整个意思就是：**缓存中存储的是 Person 对象，但是限制所有对象的 age 总和不能超过 30，否则就触发异步清除缓存。**

> 特别要注意一点：最大容量 和 最大权重 只能二选一作为缓存空间的限制。

### 3. 缓存状态

#### 1 初识缓存状态

> 默认情况下，缓存的状态会用一个 CacheStats 对象记录下来，通过访问 CacheStats 对象就可以知道当前缓存的各种状态指标，那究竟有哪些指标呢？

> 先说一下什么是“加载”，当查询缓存时，缓存未命中，那就需要去第三方数据库中查询，然后将查询出的数据先存入缓存，再返回给查询者，这个过程就是加载。

```java
Cache<String, Object> cache = Caffeine.newBuilder()
    .maximumSize(10_000)
    .recordStats()
    .build();
```

通过使用`Caffeine.recordStats()`, 可以转化成一个统计的集合。通过 `Cache.stats()` 返回一个CacheStats。CacheStats提供以下统计方法：

> - hitRate()：返回缓存命中率
> - evictionCount()：缓存回收数量
> - averageLoadPenalty()：加载新值的平均时间

#### 2 获取统计信息初体验

```java
@Test
public void testEvictByTime() throws InterruptedException {
    // 创建缓存对象
    Cache<String, String> cache = Caffeine.newBuilder()
            // 初始的缓存空间大小
            .initialCapacity(5)
            // 缓存的最大条数
            .maximumSize(10)
            // 获取统计信息
            .recordStats()
            .build();
    // 存数据
    cache.put("gf1", "柳岩");
    cache.put("gf2", "柳岩");
    cache.put("gf3", "柳岩");
    cache.put("gf4", "柳岩");
    cache.put("gf5", "柳岩");
    cache.put("gf6", "柳岩");

    // 获取数据
    System.out.println("gf1: " + cache.getIfPresent("gf1"));
    // 休眠一会儿
    Thread.sleep(1200L);
    System.out.println("gf: " + cache.getIfPresent("gf"));
    // 获取缓存统计信息
    log.info("缓存命中率：{}", cache.stats().hitRate());
    log.info("缓存回收数量：{}", cache.stats().evictionCount());
    log.info("缓存时间：{}", cache.stats().totalLoadTime());
    log.info("加载新值的平均时间：{}", cache.stats().averageLoadPenalty());
    log.info("丢失缓存数量：{}", cache.stats().missCount());
}
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.12.30/202212021114392.png" alt="image-20221202111444304" style="zoom:80%;" />

#### 3 可以获得的状态

- **totalLoadTime**：总共加载时间。
- **loadFailureRate**：加载失败率，= 总共加载失败次数 / 总共加载次数
- **averageLoadPenalty**：平均加载时间，单位-纳秒
- **evictionCount**：被淘汰出缓存的数据总个数
- **evictionWeight**：被淘汰出缓存的那些数据的总权重
- **hitCount**：命中缓存的次数
- **hitRate**：命中缓存率
- **loadCount**：加载次数
- **loadFailureCount**：加载失败次数
- **loadSuccessCount**：加载成功次数
- **missCount**：未命中次数
- **missRate**：未命中率
- **requestCount**：用户请求查询总次数

CacheStats 类包含了 2 个方法，了解一下：

- `CacheStats minus(@Nonnull CacheStats other)`：当前 CacheStats 对象的各项指标减去参数 other 的各项指标，差值形成一个新的 CacheStats 对象。
- `CacheStats plus(@Nonnull CacheStats other)`：当前 CacheStats 对象的各项指标加上参数 other 的各项指标，和值形成一个新的 CacheStats 对象。

#### 4 自定义的缓存状态收集器

自定义的缓存状态收集器的作用：每当缓存有操作发生时，不管是查询，加载，存入，都会使得缓存的某些状态指标发生改变，哪些状态指标发生了改变，就会自动触发收集器中对应的方法执行，如果我们在方法中自定义的代码是收集代码，比如将指标数值发送到 kafka，那么其它程序从kafka读取到数值，再进行分析与可视化展示，就能实现对缓存的实时监控了。收集器接口为 StatsCounter ，我们只需实现这个接口的所有抽象方法即可。下面举例说明。

```java
public class MyStatsCounter implements StatsCounter {
    @Override
    public void recordHits(int i) {
        System.out.println("命中次数：" + i);
    }

    @Override
    public void recordMisses(int i) {
        System.out.println("未命中次数：" + i);
    }

    @Override
    public void recordLoadSuccess(long l) {
        System.out.println("加载成功次数：" + l);
    }

    @Override
    public void recordLoadFailure(long l) {
        System.out.println("加载失败次数：" + l);
    }

    @Override
    public void recordEviction() {
        System.out.println("因为缓存大小限制，执行了一次缓存清除工作");
    }

    @Override
    public void recordEviction(int weight) {
        System.out.println("因为缓存权重限制，执行了一次缓存清除工作，清除的数据的权重为：" + weight);
    }

    @Override
    public CacheStats snapshot() {
        return null;
    }
}
```

> 上述代码为自定义的缓存状态收集器，收集到的状态指标只是简单地打印出来，snapshot 方法有什么作用，暂时不清楚。

> 特别需要注意的是：收集器中那些方法得到的状态值，只是当前缓存操作所产生的结果，比如当前 `cache.getIfPresent() `查询一个值，查询到了，说明命中了，但是 `recordHits(int i)` 方法的参数 i = 1，因为本次操作命中了 1 次。

再将收集器与某个缓存挂钩，如下：

```java
MyStatsCounter myStatsCounter = new MyStatsCounter();
Caffeine<String, Person> caffeine = Caffeine.newBuilder()
        .maximumWeight(30)
        .recordStats(()->myStatsCounter)
        .weigher((String key, Person value)-> value.getAge());
Cache<String, Person> cache = caffeine.build();
cache.put("one", new Person(12, "one"));
cache.put("two", new Person(18, "two"));
cache.put("three", new Person(1, "three"));
cache.getIfPresent("ww");
CacheStats stats = myStatsCounter.snapshot();
Thread.sleep(1000);
```

最后的执行结果为：

```java
未命中次数：1
因为缓存权重限制，执行了一次缓存清除工作，清除的数据的权重为：18
```



### 4. 线程池

Caffeine 缓冲池总有一些异步任务要执行，所以它包含了一个线程池，用于执行这些异步任务，默认使用的是 `ForkJoinPool.commonPool()` 线程池，个人觉得没有必要去自定义线程池，或者使用其它的线程池，因为 Caffeine 的作者在设计的时候就考虑了线程池的选择，既然别人选择了，就有一定道理。

如果一定要用其它的线程池，可以通过 `executor() `方法设置，方法参数是一个 线程池对象。

### 5. 数据过期策略

#### 1 expireAfterAccess

最后一次访问之后，隔多久没有被再次访问的话，就过期。访问包括了 读 和 写。举个例子：

```java
Caffeine<String, Person> caffeine = Caffeine.newBuilder()
        .maximumWeight(30)
        .expireAfterAccess(2, TimeUnit.SECONDS)
        .weigher((String key, Person value)-> value.getAge());
Cache<String, Person> cache = caffeine.build();
cache.put("one", new Person(12, "one"));
cache.put("two", new Person(18, "two"));
Thread.sleep(3000);
System.out.println(cache.getIfPresent("one"));
System.out.println(cache.getIfPresent("two"));
```

运行结果：

```
null
null
```

`expireAfterAccess` 包含两个参数，第二个参数是时间单位，第一个参数是时间大小，比如上述代码中设置过期时间为 2 秒，在过了 3 秒之后，再次访问数据，发现数据不存在了，即触发过期清除了。

#### 2 expireAfterWrite

某个数据在多久没有被更新后，就过期。举个例子

```java
Caffeine<String, Person> caffeine = Caffeine.newBuilder()
        .maximumWeight(30)
        .expireAfterWrite(2, TimeUnit.SECONDS)
        .weigher((String key, Person value)-> value.getAge());
Cache<String, Person> cache = caffeine.build();
cache.put("one", new Person(12, "one"));
cache.put("two", new Person(18, "two"));
Thread.sleep(1000);
System.out.println(cache.getIfPresent("one").getName());
Thread.sleep(2000);
System.out.println(cache.getIfPresent("one"));
```

运行结果：

```
one
null
```

只能是被更新，才能延续数据的生命，即便是数据被读取了，也不行，时间一到，也会过期。

#### 3 expireAfter

实话实说，关于这个设置项，官网没有说明白，网上其它博客更是千篇一律，没有一个讲明白的。此处简单讲讲我个人的测试用例与理解，如果有误，欢迎评论指正。

```java
Caffeine<String, Person> caffeine = Caffeine.newBuilder()
        .maximumWeight(30)
        .expireAfter(new Expiry<String, Person>() {
            @Override
            public long expireAfterCreate(String s, Person person, long l) {
                if(person.getAge() > 60){ //首次存入缓存后，年龄大于 60 的，过期时间为 4 秒
                    return 4000000000L;
                }
                return 2000000000L; // 否则为 2 秒
            }

            @Override
            public long expireAfterUpdate(String s, Person person, long l, long l1) {
                if(person.getName().equals("one")){ // 更新 one 这个人之后，过期时间为 8 秒
                    return 8000000000L;
                }
                return 4000000000L; // 更新其它人后，过期时间为 4 秒
            }

            @Override
            public long expireAfterRead(String s, Person person, long l, long l1) {
                return 3000000000L; // 每次被读取后，过期时间为 3 秒
            }
        })
        .weigher((String key, Person value)-> value.getAge());
Cache<String, Person> cache = caffeine.build();
```

expireAfter 方法的参数是一个 Expiry 对象，Expiry 是一个接口，上述代码用了匿名类。需要实现 Expiry 的三个方法。

- `expireAfterCreate(String s, Person person, long l) `：此方法为数据`<s , person>` 创建之后，过期时间是多久（可以理解为生命周期），单位为纳秒，方法的返回值就是过期时间，这个时间设置为多久，怎么设置，可以自定义的，比如上述代码，60 岁以上的过期时间为 4 秒，如果 4 秒内数据没有被操作，就过期。另外还有一个参数 long l，l 表示创建时间的系统时间戳，单位为纳秒。
- `expireAfterUpdate(String s, Person person, long l, long l1)`：此方法表示更新某个数据后，过期时间是多久（刷新生命周期），个人认为：参数 l 表示更新前的系统时间戳，l1 表示更新成功后的系统时间戳，因为在多线程下，更新操作可能会阻塞。
- `expireAfterRead(String s, Person person, long l, long l1)` ： 与 `expireAfterUpdate` 同理。

### 6. refreshAfterWrite 延迟刷新

```
refreshAfterWrite(long duration, TimeUnit unit)
```

写操作完成后多久才将数据刷新进缓存中，两个参数只是用于设置时间长短的。

只适用于 `LoadingCache` 和 `AsyncLoadingCache`，如果刷新操作没有完成，读取的数据只是旧数据。 

### 7. removalListener 清除、更新监听

当缓存中的数据发送更新，或者被清除时，就会触发监听器，在监听器里可以自定义一些处理手段，比如打印出哪个数据被清除，原因是什么。这个触发和监听的过程是异步的，就是说可能数据都被删除一小会儿了，监听器才监听到。

举个例子：

```java
MyStatsCounter myStatsCounter = new MyStatsCounter();
Caffeine<String, Person> caffeine = Caffeine.newBuilder()
        .maximumWeight(30)
        .removalListener((String key, Person value, RemovalCause cause)->{
            System.out.println("被清除人的年龄：" + value.getAge() + ";  清除的原因是:" + cause);
        })
        .weigher((String key, Person value)-> value.getAge());
Cache<String, Person> cache = caffeine.build();
cache.put("one", new Person(12, "one"));
cache.put("two", new Person(18, "two"));
cache.put("one", new Person(14, "one"));
cache.invalidate("one");
cache.put("three", new Person(31, "three"));
Thread.sleep(2000);
```

运行结果：

```
被清除人的年龄：12;  清除的原因是:REPLACED
被清除人的年龄：14;  清除的原因是:EXPLICIT
被清除人的年龄：18;  清除的原因是:SIZE
```

`removalListener` 方法的参数是一个 `RemovalListener` 对象，但是可以函数式传参，如上述代码，当数据被更新或者清除时，会给监听器提供三个内容，（键，值，原因）分别对应代码中的三个参数，（键，值）都是更新前，清除前的旧值， 这样可以了解到清除的详细了。

清除的原因有 5 个，存储在枚举类 RemovalCause 中：

- `EXPLICIT` ： 表示显式地调用删除操作，直接将某个数据删除。
- `REPLACED`：表示某个数据被更新。
- `EXPIRED`：表示因为生命周期结束（过期时间到了），而被清除。
- `SIZE`：表示因为缓存空间大小受限，总权重受限，而被清除。
- `COLLECTED` ： 这个不明白。

### 8. 缓存的数据使用弱引用，软引用

AsyncCache 缓存不支持软引用和弱引用。

- `weakKeys()`：将缓存的 key 使用弱引用包装起来，只要 GC 的时候，就能被回收。
- `weakValues()`：将缓存的 value 使用弱引用包装起来，只要 GC 的时候，就能被回收。
- `softValues()`：将缓存的 value使用软引用包装起来，只要 GC 的时候，有必要，就能被回收。

关于软引用，弱引用，强引用，虚引用，可以参考：

> https://blog.csdn.net/dgh112233/article/details/107288545

因此，弱引用 ，软引用的设置，只是为了方便回收空间，节省空间，但是使用的时候注意一点，缓存查询时，是用 == 来判断两个 key 是否相等，比较的是地址，不是 key 本身的内容，很容易造成一种现象：命名 key 是对的，但就是无法命中，因为 key 的内容相等，但是地址却不同，会被认为是两个 key。

### 9. 时间源 ticker

不了解，感觉默认用系统的时钟就好了。

### 10. 同步监听器

之前的 `removalListener` 是异步监听，此处的 writer 方法可以设置同步监听器，同步监听器一个实现了接口 CacheWriter 的实例化对象，我们需要自定义接口的实现类，比如：

```java
public class MyCacheWriter implements CacheWriter<String, Application.Person> {
    @Override
    public void write(String s, Application.Person person) {
        System.out.println("新增/更新了一个新数据：" + person.getName());
    }

    @Override
    public void delete(String s, Application.Person person, RemovalCause removalCause) {
        System.out.println("删除了一个数据：" + person.getName());
    }
}
```

关键是要实现 CacheWriter 接口的两个方法，当新增，更新某个数据时，会同步触发 write 方法的执行。当删除某个数据时，会触发 delete 方法的执行。

```java
Caffeine<String, Person> caffeine = Caffeine.newBuilder()
        .maximumWeight(30)
        .writer(new MyCacheWriter())
        .weigher((String key, Person value)-> value.getAge());
Cache<String, Person> cache = caffeine.build();
cache.put("one", new Person(12, "one"));
cache.put("two", new Person(18, "two"));
cache.invalidate("two");
```

运行结果：

```java
新增/更新了一个新数据：one
新增/更新了一个新数据：two
删除了一个数据：two
```

## 2. Cache 可以有的操作

- `V getIfPresent(K key)` ：如果缓存中 key 存在，则获取 value，否则返回 null。
- `void put( K key, V value)`：存入一对数据 `<key, value>`。
- `Map<K, V> getAllPresent(Iterable<?> var1)` ：参数是一个迭代器，表示可以批量查询缓存。
- `void putAll( Map<? extends K, ? extends V> var1)`： 批量存入缓存。
- `void invalidate(K var1)`：删除某个 key 对应的数据。
- `void invalidateAll(Iterable<?> var1)`：批量删除数据。
- `void invalidateAll()`：清空缓存。
- `long estimatedSize()`：返回缓存中数据的个数。
- `CacheStats stats()`：返回缓存当前的状态指标集。
- `ConcurrentMap<K, V> asMap()`：将缓存中所有的数据构成一个 map。
- `void cleanUp()`：会对缓存进行整体的清理，比如有一些数据过期了，但是并不会立马被清除，所以执行一次 cleanUp 方法，会对缓存进行一次检查，清除那些应该清除的数据。
- `V get( K var1, Function<? super K, ? extends V> var2)`：第一个参数是想要获取的 key，第二个参数是函数，例子如下：

```java
Caffeine<String, Person> caffeine = Caffeine.newBuilder()
        .maximumWeight(30)
        .weigher((String key, Person value)-> value.getAge());
Cache<String, Person> cache = caffeine.build();
cache.put("one", new Person(12, "one"));
cache.get("hello", (k)-> new Person(13, k));
System.out.println(cache.getIfPresent("hello").getName());
```

可以着重考虑一下第二个参数的写法，如果写成从数据库查询的话，那就很完整了。

还有另外两种缓存：LoadingCache， AsyncLoadingCache。



## 3. SpringBoot整合实战

> 按照Caffeine Github官网文档的描述，Caffeine是基于Java8的高性能缓存库。并且在Spring5（SpringBoot2.x)官方放弃了Guava，而使用了性能更优秀的Caffeine作为默认的缓存方案。

SpringBoot使用Caffeine有两种方式：

> - 方式一：直接引入Caffeine依赖，然后使用Caffeine的函数实现缓存
> - 方式二：引入Caffeine和Spring Cache依赖，使用SpringCache注解方法实现缓存

### 1 Caffeine 

首先引入maven相关依赖：

```xml
<dependency>   
    <groupId>com.github.ben-manes.caffeine</groupId>    
    <artifactId>caffeine</artifactId>
</dependency>
```

其次，设置缓存的配置选项

```java
@Configuration
public class CacheConfig {
    @Bean
    public Cache<String, Object> caffeineCache() {
        return Caffeine.newBuilder()
             // 设置最后一次写入或访问后经过固定时间过期
             .expireAfterWrite(60, TimeUnit.SECONDS)
             // 初始的缓存空间大小
             .initialCapacity(100)
             // 缓存的最大条数
             .maximumSize(1000)
             .build();
    }
}
```

最后给服务添加缓存功能

```java
@Slf4j
@Service
public class UserInfoServiceImpl {
    /**
     * 模拟数据库存储数据
     */
    private HashMap<Integer, UserInfo> userInfoMap = new HashMap<>();

    @Autowired // 引入caffeine配置类
    Cache<String, Object> caffeineCache;
	// 添加用户
    public void addUserInfo(UserInfo userInfo) {
        userInfoMap.put(userInfo.getId(), userInfo);
        // 加入缓存
        caffeineCache.put(String.valueOf(userInfo.getId()),userInfo);
    }

    public UserInfo getByName(Integer id) { // 获取姓名
        // 先从缓存读取
        caffeineCache.getIfPresent(id);
        UserInfo userInfo = (UserInfo) caffeineCache.asMap().get(String.valueOf(id));
        if (userInfo != null){
            return userInfo;
        }
        // 如果缓存中不存在，则从库中查找
        userInfo = userInfoMap.get(id);
        // 如果用户信息不为空，则加入缓存
        if (userInfo != null){
            caffeineCache.put(String.valueOf(userInfo.getId()),userInfo);
        }
        return userInfo;
    }

    public UserInfo updateUserInfo(UserInfo userInfo) {
        if (!userInfoMap.containsKey(userInfo.getId())) {
            return null;
        }
        // 取旧的值
        UserInfo oldUserInfo = userInfoMap.get(userInfo.getId());
        // 替换内容
        if (!StringUtils.isEmpty(oldUserInfo.getAge())) {
            oldUserInfo.setAge(userInfo.getAge());
        }
        if (!StringUtils.isEmpty(oldUserInfo.getName())) {
            oldUserInfo.setName(userInfo.getName());
        }
        if (!StringUtils.isEmpty(oldUserInfo.getSex())) {
            oldUserInfo.setSex(userInfo.getSex());
        }
        // 将新的对象存储，更新旧对象信息
        userInfoMap.put(oldUserInfo.getId(), oldUserInfo);
        // 替换缓存中的值
        caffeineCache.put(String.valueOf(oldUserInfo.getId()),oldUserInfo);
        return oldUserInfo;
    }

    @Override
    public void deleteById(Integer id) {
        userInfoMap.remove(id);
        // 从缓存中删除
        caffeineCache.asMap().remove(String.valueOf(id));
    }

}
```

### 2 Caffeine+Spring Cache

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-cache</artifactId>
</dependency>
<dependency>
    <groupId>com.github.ben-manes.caffeine</groupId>
    <artifactId>caffeine</artifactId>
</dependency>
```

其次，配置缓存管理类

```java
@Configuration
public class CacheConfig {

    // 配置缓存管理器
    @Bean("caffeineCacheManager")
    public CacheManager cacheManager() {
        CaffeineCacheManager cacheManager = new CaffeineCacheManager();
        cacheManager.setCaffeine(Caffeine.newBuilder()
                // 设置最后一次写入或访问后经过固定时间过期
                .expireAfterAccess(60, TimeUnit.SECONDS)
                // 初始的缓存空间大小
                .initialCapacity(100)
                // 缓存的最大条数
                .maximumSize(1000));
        return cacheManager;
    }
}
```

最后给服务添加缓存功能

```java
@Slf4j
@Service
@CacheConfig(cacheNames = "caffeineCacheManager")
public class UserInfoServiceImpl {

    /**
     * 模拟数据库存储数据
     */
    private HashMap<Integer, UserInfo> userInfoMap = new HashMap<>();

    @CachePut(key = "#userInfo.id")
    public void addUserInfo(UserInfo userInfo) {
        userInfoMap.put(userInfo.getId(), userInfo);
    }

    @Cacheable(key = "#id")
    public UserInfo getByName(Integer id) {
        return userInfoMap.get(id);
    }

    @CachePut(key = "#userInfo.id")
    public UserInfo updateUserInfo(UserInfo userInfo) {
        if (!userInfoMap.containsKey(userInfo.getId())) {
            return null;
        }
        // 取旧的值
        UserInfo oldUserInfo = userInfoMap.get(userInfo.getId());
        // 替换内容
        if (!StringUtils.isEmpty(oldUserInfo.getAge())) {
            oldUserInfo.setAge(userInfo.getAge());
        }
        if (!StringUtils.isEmpty(oldUserInfo.getName())) {
            oldUserInfo.setName(userInfo.getName());
        }
        if (!StringUtils.isEmpty(oldUserInfo.getSex())) {
            oldUserInfo.setSex(userInfo.getSex());
        }
        // 将新的对象存储，更新旧对象信息
        userInfoMap.put(oldUserInfo.getId(), oldUserInfo);
        // 返回新对象信息
        return oldUserInfo;
    }

    @CacheEvict(key = "#id")
    public void deleteById(Integer id) {
        userInfoMap.remove(id);
    }
}
```





### 3 实战

#### 1 需求分析

利用Caffeine实现下列需求：

> - 给根据id查询商品的业务添加缓存，缓存未命中时查询数据库
> - 给根据id查询商品库存的业务添加缓存，缓存未命中时查询数据库
> - 缓存初始大小为100
> - 缓存上限为10000

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206091211460.png" alt="image-20220609121101377" style="zoom:80%;" />

#### 2 代码实现

首先，我们需要定义两个Caffeine的缓存对象，分别保存商品、库存的缓存数据。

在item-service的`com.heima.item.config`包下定义`CaffeineConfig`类：

```java
import com.github.benmanes.caffeine.cache.Cache;
import com.github.benmanes.caffeine.cache.Caffeine;
import com.heima.item.pojo.Item;
import com.heima.item.pojo.ItemStock;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class CaffeineConfig {

    @Bean
    //Item对应商品实体类
    public Cache<Long, Item> itemCache(){
        return Caffeine.newBuilder()
                .initialCapacity(100) // 初始化大小
                .maximumSize(10_000)  // 上限大小
                .build();
    }

    @Bean
    //ItemStock对应库存实体类
    public Cache<Long, ItemStock> stockCache(){
        return Caffeine.newBuilder()
                .initialCapacity(100)
                .maximumSize(10_000)
                .build();
    }
}
```

然后，修改item-service中的`com.heima.item.web`包下的ItemController类，添加缓存逻辑：

这样多次查询就不查数据库，就走缓存了

```java
@RestController
@RequestMapping("item")
public class ItemController {

    @Autowired
    private IItemService itemService;
    @Autowired
    private IItemStockService stockService;
    //注入上面两个对象
    @Autowired
    private Cache<Long, Item> itemCache;
    
    @Autowired
    private Cache<Long, ItemStock> stockCache;
    
    // ...其它略
    
    @GetMapping("/{id}")
    public Item findById(@PathVariable("id") Long id) {
        // 原始逻辑
        // return itemService.query()
        //         .ne("status", 3).eq("id", id)
        //         .one();
        // 加上caffine，第一个参数表示根据id查缓存内有没有，
        // 没有就根据第二个参数查数据库,key就是id的值
        // 以后就会把数据放入缓存中，不再去查数据库了
        return itemCache.get(id, key -> itemService.query()
                .ne("status", 3).eq("id", key)
                .one()
        );
    }

    @GetMapping("/stock/{id}")
    public ItemStock findStockById(@PathVariable("id") Long id) {
        // 原始逻辑
        // return stockService.getById(id);
        //加上caffine
        return stockCache.get(id, key -> stockService.getById(key));
    }
}
```



# 本地缓存

## 本地缓存和缓存分类

传统的缓存策略一般是请求到达Tomcat后，先查询Redis，如果未命中则查询数据库，如图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img/image-20210821075259137.png" alt="image-20210821075259137" style="zoom:80%;" />

存在下面的问题

- 请求要经过Tomcat处理，Tomcat的性能成为整个系统的瓶颈


- Redis缓存失效时，会对数据库产生冲击

> 缓存在日常开发中启动至关重要的作用，由于是存储在内存中，数据的读取速度是非常快的，能大量减少对数据库的访问，减少数据库的压力。我们把缓存分为两类

**分布式缓存，例如Redis**

- 优点：存储容量更大、可靠性更好、可以在集群间共享，更好的可靠性
- 缺点：访问缓存有网络开销，性能取决于网络
- 场景：缓存数据量较大、可靠性要求较高、需要在集群间共享

**进程本地缓存，例如HashMap、GuavaCache**

- 优点：读取本地内存，没有网络开销，速度更快
- 缺点：存储容量有限、可靠性较低、无法在多台Tomcat间共享
- 场景：性能要求较高，缓存数据量较小



## JVM进程缓存

为了演示多级缓存的案例，我们先准备一个商品查询的业务。

### 初识Caffeine

**Caffeine**是一个基于Java8开发的，提供了近乎最佳命中率的高性能的本地缓存库。目前Spring内部的缓存使用的就是Caffeine。GitHub地址：https://github.com/ben-manes/caffeine/wiki/Home-zh-CN

Caffeine的性能非常好，下图是官方给出的性能对比：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img/image-20210821081826399.png" alt="image-20210821081826399" style="zoom:80%;" />

可以看到Caffeine的性能遥遥领先！

#### 引入依赖

```xml
<dependency>
    <groupId>com.github.ben-manes.caffeine</groupId>
    <artifactId>caffeine</artifactId>
</dependency>
```

#### 基本API使用

```java
@Test
public void testBasicOps() {
    // 构建cache对象
    Cache<String, String> cache = Caffeine.newBuilder().build();
    // 存数据
    cache.put("name", "迪丽热巴");
    // 方法一：取数据
    String name = cache.getIfPresent("name");
    System.out.println("name = " + name);
    
    // 方法二：取数据，包含两个参数：
    // 参数一：缓存的key
    // 参数二：Lambda表达式，表达式参数就是缓存的key，方法体是查询数据库的逻辑
    // 优先根据key查询JVM缓存，如果未命中，则执行参数二的Lambda表达式
    String name1 = cache.get("name1", key -> {
        // 根据key去数据库查询数据(第一个参数defaultGF)查询value
        return "柳岩";
    });
    System.out.println("name1 = " + name1);
}
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206142103356.png" alt="image-20220614210301257" style="zoom: 80%;" />

### 缓存清理策略⭐⭐

Caffeine既然是缓存的一种，肯定需要有缓存的清除策略，不然的话内存总会有耗尽的时候。

#### 基于容量

基于大小驱逐，有两种方式：一种是基于缓存大小，一种是基于权重

> 使用Caffeine.maximumSize(long)方法来指定缓存的最大容量。当缓存超出这个容量的时候，会使用Window TinyLfu策略来删除缓存。也可以使用权重的策略来进行驱逐，可以使用Caffeine.weigher(Weigher)函数来指定权重，使用Caffeine.maximumWeight(long)函数来指定缓存最大权重值。

> maximumWeight 与 maximumSize 不可以同时使用

```java
//基于大小设置驱逐策略：
@Test
public void testEvictByNum() throws InterruptedException {
    // 创建缓存对象
    Cache<String, String> cache = Caffeine.newBuilder()
            // 设置缓存大小上限为 1
            .maximumSize(1)
            .build();
    // 存数据
    cache.put("gf1", "柳岩");
    cache.put("gf2", "范冰冰");
    cache.put("gf3", "迪丽热巴");
    // 延迟10ms，给清理线程一点时间
    Thread.sleep(10L);
    // 获取数据,可以发现：前两个都是null，只能查到第三个
    System.out.println("gf1: " + cache.getIfPresent("gf1"));
    System.out.println("gf2: " + cache.getIfPresent("gf2"));
    System.out.println("gf3: " + cache.getIfPresent("gf3"));
}
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206142119885.png" alt="image-20220614211913807" style="zoom: 67%;" />

#### 基于时间

Caffeine提供了三种定时驱逐策略

- expireAfterAccess(long, TimeUnit)：在最后一次访问或者写入后开始计时，在指定的时间后过期。假如一直有请求访问该key，那么这个缓存将一直不会过期。
- expireAfterWrite(long, TimeUnit)：在最后一次写入缓存后开始计时，在指定的时间后过期。
- expireAfter(Expiry)：自定义策略，过期时间由`Expiry`实现独自计算。

```java
//基于时间设置驱逐策略
@Test
public void testEvictByTime() throws InterruptedException {
    // 创建缓存对象
    Cache<String, String> cache = Caffeine.newBuilder()
            // 设置缓存有效期为 10 秒，从最后一次写入开始计时 
            .expireAfterWrite(Duration.ofSeconds(10)) 
            .build();
    // 存数据
    cache.put("gf", "柳岩");
    // 获取数据
    System.out.println("gf: " + cache.getIfPresent("gf"));
    // 休眠一会儿
    Thread.sleep(12000L);
    System.out.println("gf: " + cache.getIfPresent("gf"));
}
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206142120321.png" alt="image-20220614212057231" style="zoom:80%;" />

#### 基于引用

设置缓存为软引用或弱引用，利用GC来回收缓存数据。性能较差，不建议使用

> **注意**：在默认情况下，当一个缓存元素过期的时候，Caffeine不会自动立即将其清理和驱逐。而是在一次读或写操作后，或者在空闲时间完成对失效数据的驱逐。

#### 手动删除缓存

任何时候，你都可以主动使缓存失效，而不用等待缓存被驱逐

```java
// 单个key
cache.invalidate(key)
// 批量key
cache.invalidateAll(keys)
// 所有key
cache.invalidateAll()
```



# Redis+Caffeine 两级缓存实战

项目源码地址：https://github.com/trunks2008/double-cache

[Redis+Caffeine 两级缓存实战！性能爆表！ (qq.com)](https://mp.weixin.qq.com/s?__biz=MzU1Nzg4NjgyMw==&mid=2247499027&idx=2&sn=509c83b61301f73f3d0e46888488ee12&chksm=fc2c411bcb5bc80da0bfd4023972c869aaeff5602d8a9a728af5889eb0c8bc9b6f43d9fa5600&mpshare=1&scene=23&srcid=0408F9hFu7b5CA6perJAPWVc&sharer_sharetime=1649397821458&sharer_shareid=29b8a04db1dbd975e3bf4e9f47e7ac67#rd)

在高性能的服务架构设计中，缓存是一个不可或缺的环节。在实际的项目中，我们通常会将一些热点数据存储到`Redis`或`MemCache`这类缓存中间件中，只有当缓存的访问没有命中时再查询数据库。在提升访问速度的同时，也能降低数据库的压力。

随着不断的发展，这一架构也产生了改进，在一些场景下可能单纯使用`Redis`类的远程缓存已经不够了，还需要进一步配合本地缓存使用，例如`Guava cache`或`Caffeine`，从而再次提升程序的响应速度与服务性能。于是，就产生了使用本地缓存作为一级缓存，再加上远程缓存作为二级缓存的**两级缓存**架构。

在先不考虑并发等复杂问题的情况下，两级缓存的访问流程可以用下面这张图来表示：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img/image-20220408210935888.png" alt="image-20220408210935888" style="zoom:67%;" />



## 优点与问题

那么，使用两级缓存相比单纯使用远程缓存，具有什么优势呢？

- 本地缓存基于本地环境的内存，访问速度非常快，对于一些变更频率低、实时性要求低的数据，可以放在本地缓存中，提升访问速度
- 使用本地缓存能够减少和`Redis`类的远程缓存间的数据交互，减少网络I/O开销，降低这一过程中在网络通信上的耗时

但是在设计中，还是要考虑一些问题的，例如数据一致性问题。首先，两级缓存与数据库的数据要保持一致，一旦数据发生了修改，在修改数据库的同时，本地缓存、远程缓存应该同步更新。

另外，如果是分布式环境下，一级缓存之间也会存在一致性问题，当一个节点下的本地缓存修改后，需要通知其他节点也刷新本地缓存中的数据，否则会出现读取到过期数据的情况，这一问题可以通过类似于Redis中的发布/订阅功能解决。

此外，缓存的过期时间、过期策略以及多线程访问的问题也都需要考虑进去，不过我们今天暂时先不考虑这些问题，先看一下如何简单高效的在代码中实现两级缓存的管理。

## 准备工作

在简单梳理了一下要面对的问题后，下面开始两级缓存的代码实战，我们整合号称最强本地缓存的`Caffeine`作为一级缓存、性能之王的`Redis`作为二级缓存。首先建一个springboot项目，引入缓存要用到的相关的依赖：

```xml
<dependency>
    <groupId>com.github.ben-manes.caffeine</groupId>
    <artifactId>caffeine</artifactId>
    <version>2.9.2</version>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-cache</artifactId>
</dependency>
<dependency>
    <groupId>org.apache.commons</groupId>
    <artifactId>commons-pool2</artifactId>
    <version>2.8.1</version>
</dependency>
```

在`application.yml`中配置`Redis`的连接信息：

```yml
spring:
  redis:
    host: 127.0.0.1
    port: 6379
    database: 0
    timeout: 10000ms
    lettuce:
      pool:
        max-active: 8
        max-wait: -1ms
        max-idle: 8
        min-idle: 0
```

在下面的例子中，我们将使用`RedisTemplate`来对`redis`进行读写操作，`RedisTemplate`使用前需要配置一下`ConnectionFactory`和序列化方式，这一过程比较简单就不贴出代码了，有需要本文全部示例代码的可以在**文末获取**。

下面我们在单机环境下，将按照对业务侵入性的不同程度，分三个版本来实现两级缓存的使用。

## V1.0版本

我们可以通过手动操作`Caffeine`中的`Cache`对象来缓存数据，它是一个类似`Map`的数据结构，以`key`作为索引，`value`存储数据。在使用`Cache`前，需要先配置一下相关参数：

```java
@Configuration
public class CaffeineConfig {
    @Bean
    public Cache<String,Object> caffeineCache(){
        return Caffeine.newBuilder()
                .initialCapacity(128)//初始大小
                .maximumSize(1024)//最大数量
                .expireAfterWrite(60, TimeUnit.SECONDS)//过期时间
                .build();
    }
}
```

简单解释一下`Cache`相关的几个参数的意义：

- `initialCapacity`：初始缓存空大小
- `maximumSize`：缓存的最大数量，设置这个值可以避免出现内存溢出
- `expireAfterWrite`：指定缓存的过期时间，是最后一次写操作后的一个时间，这里

此外，缓存的过期策略也可以通过`expireAfterAccess`或`refreshAfterWrite`指定。

在创建完成`Cache`后，我们就可以在业务代码中注入并使用它了。在没有使用任何缓存前，一个只有简单的`Service`层代码是下面这样的，只有crud操作：

```java
@Service
@AllArgsConstructor
public class OrderServiceImpl implements OrderService {
    private final OrderMapper orderMapper;

    @Override
    public Order getOrderById(Long id) {  
        Order order = orderMapper.selectOne(new LambdaQueryWrapper<Order>()
              .eq(Order::getId, id));    
        return order;
    }
    
    @Override
    public void updateOrder(Order order) {      
        orderMapper.updateById(order);
    }
    
    @Override
    public void deleteOrder(Long id) {
        orderMapper.deleteById(id);
    }
}
```

接下来，对上面的`OrderService`进行改造，在执行正常业务外再加上操作两级缓存的代码，先看改造后的查询操作：

```java
public Order getOrderById(Long id) {
    String key = CacheConstant.ORDER + id;
    Order order = (Order) cache.get(key,
            k -> {
                //先查询 Redis
                Object obj = redisTemplate.opsForValue().get(k);
                if (Objects.nonNull(obj)) {
                    log.info("get data from redis");
                    return obj;
                }

                // Redis没有则查询 DB
                log.info("get data from database");
                Order myOrder = orderMapper.selectOne(new LambdaQueryWrapper<Order>()
                        .eq(Order::getId, id));
                redisTemplate.opsForValue().set(k, myOrder, 120, TimeUnit.SECONDS);
                return myOrder;
            });
    return order;
}
```

在`Cache`的`get`方法中，会先从缓存中进行查找，如果找到缓存的值那么直接返回。如果没有找到则执行后面的方法，并把结果加入到缓存中。

因此上面的逻辑就是先查找`Caffeine`中的缓存，没有的话查找`Redis`，`Redis`再不命中则查询数据库，写入`Redis`缓存的操作需要手动写入，而`Caffeine`的写入由`get`方法自己完成。

在上面的例子中，设置`Caffeine`的过期时间为60秒，而`Redis`的过期时间为120秒，下面进行测试，首先看第一次接口调用时，进行了数据库的查询：

![图片](https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicavLowA4CZwo5SwAiamkiax319ZIPEJ1EicUYJDbI8KIc2qwoGXUGS0k3e6ZB9HicUOTfplcdhYAVamvA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

而在之后60秒内访问接口时，都没有打印打任何sql或自定义的日志内容，说明接口没有查询`Redis`或数据库，直接从`Caffeine`中读取了缓存。

等到距离第一次调用接口进行缓存的60秒后，再次调用接口：

![图片](https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicavLowA4CZwo5SwAiamkiax31ib32JXjfUDgibSziaVIldpw8QSZfDOia2YbzxS40N3Hb7w4CLKkiadR49AA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

可以看到这时从`Redis`中读取了数据，因为这时`Caffeine`中的缓存已经过期了，但是`Redis`中的缓存没有过期仍然可用。

下面再来看一下修改操作，代码在原先的基础上添加了手动修改`Redis`和`Caffeine`缓存的逻辑：

```java
public void updateOrder(Order order) {
    log.info("update order data");
    String key=CacheConstant.ORDER + order.getId();
    orderMapper.updateById(order);
    //修改 Redis
    redisTemplate.opsForValue().set(key,order,120, TimeUnit.SECONDS);
    // 修改本地缓存
    cache.put(key,order);
}
```

看一下下面图中接口的调用、以及缓存的刷新过程。可以看到在更新数据后，同步刷新了缓存中的内容，再之后的访问接口时不查询数据库，也可以拿到正确的结果：

![图片](https://mmbiz.qpic.cn/mmbiz_gif/zpom4BeZSicavLowA4CZwo5SwAiamkiax31yShjOocDHNAG7x0qSLbn7GVtyYBwsLia5QPiaBWriarcfXYDC7KZCZhiaA/640?wx_fmt=gif&wxfrom=5&wx_lazy=1)

最后再来看一下删除操作，在删除数据的同时，手动移除`Reids`和`Caffeine`中的缓存：

```java
public void deleteOrder(Long id) {
    log.info("delete order");
    orderMapper.deleteById(id);
    String key= CacheConstant.ORDER + id;
    redisTemplate.delete(key);
    cache.invalidate(key);
}
```

我们在删除某个缓存后，再次调用之前的查询接口时，又会出现重新查询数据库的情况：

![图片](https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicavLowA4CZwo5SwAiamkiax316033QMvIJxAh1jSptz5WMyjWgAufib9e6eFaWjTjTMAXTuiaiagDA4Xibg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

简单的演示到此为止，可以看到上面这种使用缓存的方式，虽然看起来没什么大问题，但是对代码的入侵性比较强。在业务处理的过程中要由我们频繁的操作两级缓存，会给开发人员带来很大负担。那么，有什么方法能够简化这一过程呢？我们看看下一个版本。

## V2.0版本

在`spring`项目中，提供了`CacheManager`接口和一些注解，允许让我们通过注解的方式来操作缓存。先来看一下常用几个注解说明：

- `@Cacheable`：根据键从缓存中取值，如果缓存存在，那么获取缓存成功之后，直接返回这个缓存的结果。如果缓存不存在，那么执行方法，并将结果放入缓存中。
- `@CachePut`：不管之前的键对应的缓存是否存在，都执行方法，并将结果强制放入缓存
- `@CacheEvict`：执行完方法后，会移除掉缓存中的数据。

如果要使用上面这几个注解管理缓存的话，我们就不需要配置V1版本中的那个类型为`Cache`的`Bean`了，而是需要配置`spring`中的`CacheManager`的相关参数，具体参数的配置和之前一样：

```java
@Configuration
public class CacheManagerConfig {
    @Bean
    public CacheManager cacheManager(){
        CaffeineCacheManager cacheManager=new CaffeineCacheManager();
        cacheManager.setCaffeine(Caffeine.newBuilder()
                .initialCapacity(128)
                .maximumSize(1024)
                .expireAfterWrite(60, TimeUnit.SECONDS));
        return cacheManager;
    }
}
```

然后在启动类上再添加上`@EnableCaching`注解，就可以在项目中基于注解来使用`Caffeine`的缓存支持了。下面，再次对`Service`层代码进行改造。

首先，还是改造查询方法，在方法上添加`@Cacheable`注解：

```java
@Cacheable(value = "order",key = "#id")
//@Cacheable(cacheNames = "order",key = "#p0")
public Order getOrderById(Long id) {
    String key= CacheConstant.ORDER + id;
    //先查询 Redis
    Object obj = redisTemplate.opsForValue().get(key);
    if (Objects.nonNull(obj)){
        log.info("get data from redis");
        return (Order) obj;
    }
    // Redis没有则查询 DB
    log.info("get data from database");
    Order myOrder = orderMapper.selectOne(new LambdaQueryWrapper<Order>()
            .eq(Order::getId, id));
    redisTemplate.opsForValue().set(key,myOrder,120, TimeUnit.SECONDS);
    return myOrder;
}
```

`@Cacheable`注解的属性多达9个，好在我们日常使用时只需要配置两个常用的就可以了。其中`value`和`cacheNames`互为别名关系，表示当前方法的结果会被缓存在哪个`Cache`上，应用中通过`cacheName`来对`Cache`进行隔离，每个`cacheName`对应一个`Cache`实现。`value`和`cacheNames`可以是一个数组，绑定多个`Cache`。

而另一个重要属性`key`，用来指定缓存方法的返回结果时对应的`key`，这个属性支持使用`SpringEL`表达式。通常情况下，我们可以使用下面几种方式作为`key`：

```
#参数名
#参数对象.属性名
#p参数对应下标
```

在上面的代码中，我们看到添加了`@Cacheable`注解后，在代码中只需要保留原有的业务处理逻辑和操作`Redis`部分的代码即可，`Caffeine`部分的缓存就交给spring处理了。

下面，我们再来改造一下更新方法，同样，使用`@CachePut`注解后移除掉手动更新`Cache`的操作：

```java
@CachePut(cacheNames = "order",key = "#order.id")
public Order updateOrder(Order order) {
    log.info("update order data");
    orderMapper.updateById(order);
    //修改 Redis
    redisTemplate.opsForValue().set(CacheConstant.ORDER + order.getId(),
            order, 120, TimeUnit.SECONDS);
    return order;
}
```

注意，这里和V1版本的代码有一点区别，在之前的更新操作方法中，是没有返回值的`void`类型，但是这里需要修改返回值的类型，否则会缓存一个空对象到缓存中对应的`key`上。当下次执行查询操作时，会直接返回空对象给调用方，而不会执行方法中查询数据库或`Redis`的操作。

最后，删除方法的改造就很简单了，使用`@CacheEvict`注解，方法中只需要删除`Redis`中的缓存即可：

```java
@CacheEvict(cacheNames = "order",key = "#id")
public void deleteOrder(Long id) {
    log.info("delete order");
    orderMapper.deleteById(id);
    redisTemplate.delete(CacheConstant.ORDER + id);
}
```

可以看到，借助`spring`中的`CacheManager`和`Cache`相关的注解，对V1版本的代码经过改进后，可以把全手动操作两级缓存的强入侵代码方式，改进为本地缓存交给`spring`管理，`Redis`缓存手动修改的半入侵方式。那么，还能进一步改造，使之成为对业务代码完全无入侵的方式吗？

## V3.0版本

模仿`spring`通过注解管理缓存的方式，我们也可以选择自定义注解，然后在切面中处理缓存，从而将对业务代码的入侵降到最低。

首先定义一个注解，用于添加在需要操作缓存的方法上：

```java
@Target(ElementType.METHOD)
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface DoubleCache {
    String cacheName();
    String key(); //支持springEl表达式
    long l2TimeOut() default 120;
    CacheType type() default CacheType.FULL;
}
```

我们使用`cacheName + key`作为缓存的真正`key`（仅存在一个`Cache`中，不做`CacheName`隔离），`l2TimeOut`为可以设置的二级缓存`Redis`的过期时间，`type`是一个枚举类型的变量，表示操作缓存的类型，枚举类型定义如下：

```java
public enum CacheType {
    FULL,   //存取
    PUT,    //只存
    DELETE  //删除
}
```

因为要使`key`支持`springEl`表达式，所以需要写一个方法，使用表达式解析器解析参数：

```java
public static String parse(String elString, TreeMap<String,Object> map){
    elString=String.format("#{%s}",elString);
    //创建表达式解析器
    ExpressionParser parser = new SpelExpressionParser();
    //通过evaluationContext.setVariable可以在上下文中设定变量。
    EvaluationContext context = new StandardEvaluationContext();
    map.entrySet().forEach(entry->
        context.setVariable(entry.getKey(),entry.getValue())
    );

    //解析表达式
    Expression expression = parser.parseExpression(elString, new TemplateParserContext());
    //使用Expression.getValue()获取表达式的值，这里传入了Evaluation上下文
    String value = expression.getValue(context, String.class);
    return value;
}
```

参数中的`elString`对应的就是注解中`key`的值，`map`是将原方法的参数封装后的结果。简单进行一下测试：

```java
public void test() {
    String elString="#order.money";
    String elString2="#user";
    String elString3="#p0";   

    TreeMap<String,Object> map=new TreeMap<>();
    Order order = new Order();
    order.setId(111L);
    order.setMoney(123D);
    map.put("order",order);
    map.put("user","Hydra");

    String val = parse(elString, map);
    String val2 = parse(elString2, map);
    String val3 = parse(elString3, map);

    System.out.println(val);
    System.out.println(val2);
    System.out.println(val3);
}
```

执行结果如下，可以看到支持按照参数名称、参数对象的属性名称读取，但是不支持按照参数下标读取，暂时留个小坑以后再处理。

```java
123.0
Hydra
null
```

至于`Cache`相关参数的配置，我们沿用V1版本中的配置即可。准备工作做完了，下面我们定义切面，在切面中操作`Cache`来读写`Caffeine`的缓存，操作`RedisTemplate`读写`Redis`缓存。

```java
@Slf4j @Component @Aspect 
@AllArgsConstructor
public class CacheAspect {
    private final Cache cache;
    private final RedisTemplate redisTemplate;

    @Pointcut("@annotation(com.cn.dc.annotation.DoubleCache)")
    public void cacheAspect() {
    }

    @Around("cacheAspect()")
    public Object doAround(ProceedingJoinPoint point) throws Throwable {
        MethodSignature signature = (MethodSignature) point.getSignature();
        Method method = signature.getMethod();

        //拼接解析springEl表达式的map
        String[] paramNames = signature.getParameterNames();
        Object[] args = point.getArgs();
        TreeMap<String, Object> treeMap = new TreeMap<>();
        for (int i = 0; i < paramNames.length; i++) {
            treeMap.put(paramNames[i],args[i]);
        }

        DoubleCache annotation = method.getAnnotation(DoubleCache.class);
        String elResult = ElParser.parse(annotation.key(), treeMap);
        String realKey = annotation.cacheName() + CacheConstant.COLON + elResult;

        //强制更新
        if (annotation.type()== CacheType.PUT){
            Object object = point.proceed();
            redisTemplate.opsForValue().set(realKey, object,annotation.l2TimeOut(), TimeUnit.SECONDS);
            cache.put(realKey, object);
            return object;
        }
        //删除
        else if (annotation.type()== CacheType.DELETE){
            redisTemplate.delete(realKey);
            cache.invalidate(realKey);
            return point.proceed();
        }

        //读写，查询Caffeine
        Object caffeineCache = cache.getIfPresent(realKey);
        if (Objects.nonNull(caffeineCache)) {
            log.info("get data from caffeine");
            return caffeineCache;
        }

        //查询Redis
        Object redisCache = redisTemplate.opsForValue().get(realKey);
        if (Objects.nonNull(redisCache)) {
            log.info("get data from redis");
            cache.put(realKey, redisCache);
            return redisCache;
        }

        log.info("get data from database");
        Object object = point.proceed();
        if (Objects.nonNull(object)){
            //写入Redis
            redisTemplate.opsForValue().set(realKey, object,annotation.l2TimeOut(), TimeUnit.SECONDS);
            //写入Caffeine
            cache.put(realKey, object);        
        }
        return object;
    }
}
```

切面中主要做了下面几件工作：

- 通过方法的参数，解析注解中`key`的`springEl`表达式，组装真正缓存的`key`
- 根据操作缓存的类型，分别处理存取、只存、删除缓存操作
- 删除和强制更新缓存的操作，都需要执行原方法，并进行相应的缓存删除或更新操作
- 存取操作前，先检查缓存中是否有数据，如果有则直接返回，没有则执行原方法，并将结果存入缓存

修改`Service`层代码，代码中只保留原有业务代码，再添加上我们自定义的注解就可以了：

```java
@DoubleCache(cacheName = "order", key = "#id",
        type = CacheType.FULL)
public Order getOrderById(Long id) {
    Order myOrder = orderMapper.selectOne(new LambdaQueryWrapper<Order>()
            .eq(Order::getId, id));
    return myOrder;
}

@DoubleCache(cacheName = "order",key = "#order.id",
        type = CacheType.PUT)
public Order updateOrder(Order order) {
    orderMapper.updateById(order);
    return order;
}

@DoubleCache(cacheName = "order",key = "#id",
        type = CacheType.DELETE)
public void deleteOrder(Long id) {
    orderMapper.deleteById(id);
}
```

到这里，基于切面操作缓存的改造就完成了，`Service`的代码也瞬间清爽了很多，让我们可以继续专注于业务逻辑处理，而不用费心去操作两级缓存了。

## 总结

本文按照对业务入侵的递减程度，依次介绍了三种管理两级缓存的方法。至于在项目中是否需要使用二级缓存，需要考虑自身业务情况，如果Redis这种远程缓存已经能够满足你的业务需求，那么就没有必要再使用本地缓存了。毕竟实际使用起来远没有那么简单，本文中只是介绍了最基础的使用，实际中的并发问题、事务的回滚问题都需要考虑，还需要思考什么数据适合放在一级缓存、什么数据适合放在二级缓存等等的其他问题。



# 本地缓存Guava(不熟)

[Spring Boot 集成 本地缓存Guava框架 (qq.com)](https://mp.weixin.qq.com/s?__biz=Mzg2NzYyNjQzNg==&mid=2247484909&idx=1&sn=2a7e5027bd69bb4a1501c1744fa2cfc1&chksm=ceb9f946f9ce705036ca31fcd4366033e5ae53acd088dea113723322239221339a6377fe7173&scene=21#wechat_redirect)

### 什么是 Guava

Guava 是 Google 开发的一款java 开源框架。提供了一些 JDK 没有提供的功能，以及对 JDK 已有功能的增强功能。

包括：集合（Collections）、缓存（Caching）、原生类型支持（Primitives Support）、并发库（Concurrency Libraries）、通用注解（Common Annotation）、字符串处理（Strings Processing）、数学计算（Math）、I/O、事件总线（EventBus）等等。

### 项目集成

在 pom.xml 文件引入相应的二方包依赖

```xml
<dependency>
    <groupId>com.google.guava</groupId>
    <artifactId>guava</artifactId>
    <version>23.0</version>
</dependency>
```

初始化本地缓存类实例，并设置各种参数，满足个性化业务场景需求。

```java
import com.google.common.cache.*;
import com.it.entity.log;
import java.time.LocalDateTime;
import java.util.concurrent.TimeUnit;

public class LocalCacheService {
    // 缓存接口这里是LoadingCache，LoadingCache在缓存项不存在时可以自动加载缓存
    public static LoadingCache<Integer, log> useCache
            = CacheBuilder.newBuilder()
            //设置缓存初始大小，应该合理设置，后续会扩容
            .initialCapacity(10)
            //最大值
            .maximumSize(100)
            //并发数设置
            .concurrencyLevel(5)
            //缓存过期时间，写入后10分钟过期
            .expireAfterWrite(600,TimeUnit.SECONDS)
            // 此缓存对象经过多少秒没有被访问则过期。
            .expireAfterAccess(10,TimeUnit.SECONDS)
            //统计缓存命中率
            .recordStats()
            .removalListener(new RemovalListener<Object, Object>() {
                @Override
                public void onRemoval(RemovalNotification<Object, Object> notification) {
                    System.out.println(notification.getKey() + " 被移除了，原因： " +
                                       notification.getCause());
                }
            })
            .build(
                    new CacheLoader<Integer, log>() {
                        @Override
                        public log load(Integer id) throws Exception {
                            System.out.println("缓存未命中，从数据库加载，日志id：" + id);
                            return log.builder().id(id)
                                   .info("Lily").createDate(LocalDateTime.now()).build();
                        }
                    }
            );
}
```

**参数解释：**

- expireAfterWrite  指定key在一定时间内没有创建/覆盖时，会移除该key，下次取的时候从loading中取
- expireAfterAccess 指定key在一定时间内没有读写，会移除该key，下次取的时候从loading中取
- refreshAfterWrite 指定key在一定时间内没有创建/覆盖时，则指定时间过后，再次访问时，会去刷新该缓存，在新值没有到来之前，始终返回旧值

> 主要区别：指定时间后，expire是remove该key，下次访问时同步去获取返回新值。而refresh则是指定时间后，不会remove该key，下次访问会触发刷新，新值没有拿到前返回旧值

- concurrencyLevel(8)  设置并发级别为8，并发级别是指可以同时写缓存的线程数
- initialCapacity(5)  缓存容器的初始容量为5
- maximumSize(10)  缓存最大容量为 10，超过之后就会按照LRU 移除缓存项
- recordStats()  统计缓存的命中率，线上环境一般不需要
- removalListener(new RemovalListener<Object, Object>()  设置缓存的移除通知
- build()  指定CacheLoader，在缓存不存在时通过CacheLoader的实现自动加载缓存

**构造LoadingCache对象，里面提供了很多方法来操作缓存，比如 `getIfPresent` 、`put`、`invalidate`等，详细可以参考下图：**

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.11/202206141924573.png" alt="image-20220614192428403" style="zoom:50%;" />

**Guava 缓存失效的方法：**

- invalidate(key)：废弃缓存中 key对应的 value值。
- invalidateAll()：废弃缓存中所有的value值。
- invalidateAll(Iterable<?> keys)：废弃传入key集合对应的所有缓存中的value值。

**CacheStats 支持的监控统计维度：**

- requestCount()：返回Cache的lookup方法查找缓存的次数，不论查找的值是否被缓存。
- hitCount()：返回Cache的lookup方法命中缓存的次数。
- hitRate()：返回缓存请求的命中率，命中次数除以请求次数。
- missCount()：返回缓存请求的未命中的次数。
- missRate()：返回缓存请求未命中的比率，未命中次数除以请求次数。
- loadCount()：返回缓存调用load方法加载新值的次数。
- loadSuccessCount()：返回缓存加载新值的成功次数。
- loadExceptionCount()：返回缓存加载新值出现异常的次数。
- loadExceptionRate()：返回缓存加载新值出现异常的比率。
- totalLoadTime()：返回缓存加载新值所耗费的总时间。
- averageLoadPenalty()：缓存加载新值耗费的平均时间，加载的总时间除以加载的次数。
- evictionCount()：返回缓存中条目被移除的次数。
- minus(CacheStats other)：返回一个新的表示当前CacheStats与传入CacheStats之间差异的CacheStats实例。
- plus(CacheStats other)：返回一个新的表示当前CacheStats与传入CacheStats之间总计的CacheStats实例。

# 本地缓存和分布式缓存，怎么选

**缓存**，消息队列，分库分表是高并发解决方案三剑客。

缓存之所以能够让系统“更快”，本质上做到了如下两点：

- 减小 CPU 消耗

  将原来需要实时计算的内容提前算好、把一些公用的数据进行复用，这可以减少 CPU 消耗，从而提升响应性能。

- 减小 I/O 消耗

  将原来对网络、磁盘等较慢介质的读写访问变为对内存等较快介质的访问，从而提升响应性能。

对于**应用系统**来讲，我们经常将缓存划分为**本地缓存**和**分布式缓存**。

**本地缓存** ：应用中的缓存组件，缓存组件和应用在同一进程中，缓存的读写非常快，没有网络开销。但各应用或集群的各节点都需要维护自己的单独缓存，无法共享缓存。

**分布式缓存**：和应用分离的缓存组件或服务，与本地应用隔离，多个应用可直接共享缓存。

这篇文章，聊聊本地缓存和分布式缓存，希望大家读完之后，在面对不同的业务场景时，能够做出合理的缓存选型。

## 1 本地缓存 JDK Map

JDK Map 经常用于缓存实现：

- HashMap是一种基于哈希表的集合类，它提供了快速的插入、查找和删除操作。可以将键值对作为缓存项的存储方式，将键作为缓存项的唯一标识符，值作为缓存项的内容。
- ConcurrentHashMap是线程安全的 HashMap，它在多线程环境下可以保证高效的并发读写操作。
- LinkedHashMap是一种有序的 HashMap ，它保留了元素插入的顺序，可以按照插入顺序或者访问顺序进行遍历。
- TreeMap是一种基于红黑树的有序 Map，它可以按照键的顺序进行遍历。

笔者曾经负责艺龙红包系统，**红包活动**就是**存储在** **ConcurrentHashMap** 中 ，通过**定时任务刷新缓存** 。

![图片](https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n284ibDPWJU5KZLDFibX01NEYiaK3dVGuCvGuulo7WUiafKVKiaqb3H3L7VIjF3gXOTIaKrOHMAibjRxsDXw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

核心流程：

1、红包系统启动后，初始化一个 ConcurrentHashMap 作为红包活动缓存 ；

2、数据库查询所有的红包活动 , 并将活动信息存储在 Map 中 ;

3、定时任务每隔 30 秒 ，执行缓存加载方法，刷新缓存。

为什么红包系统会将红包活动信息存储在本地内存 ConcurrentHashMap 呢 ？

- 红包系统是高并发应用，快速将请求结果响应给前端，大大提升用户体验；
- 红包活动数量并不多，就算全部放入到 Map 里也不会产生内存溢出的问题；
- 定时任务刷新缓存并不会影响红包系统的业务。

笔者见过很多**单体应用**都使用这种方案，该方案的特点是简洁易用，工程实现也容易 。

## 2 本地缓存框架

虽然使用 JDK Map 能快捷构建缓存，但缓存的功能还是比较孱弱的。

因为现实场景里，我们可能需要给缓存添加**缓存统计**、**过期失效**、**淘汰策略**等功能。

于是，**本地缓存框架**应运而生。

流行的 Java 缓存框架包括：Ehcache , Google Guava ,  Caffeine Cache 。

![图片](https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n284ibDPWJU5KZLDFibX01NEYia1mJicDsOGHaVicHelGa3ma5icBzay0pakbibovZ277uuSnkVOykkyN2IIA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

下图展示了 Caffeine 框架的使用示例。

![图片](https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n284ibDPWJU5KZLDFibX01NEYiaRGtOgz6oT4lPICMu2G5n1ZibRhFs11O3AzRra8J2zqquiaoFELtfPPAQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

虽然本地缓存框架的功能很强大，但是本地缓存的缺陷依然明显。

1、高并发的场景，**应用重启之后，本地缓存就失效了，系统的负载就比较大**，需要花较长的时间才能恢复；

2、每个应用节点都会维护自己的单独缓存，**缓存同步比较头疼**。

## 3 分布式缓存

分布式缓存是指将缓存数据分布在多台机器上，以提高缓存容量和并发读写能力的缓存系统。分布式缓存通常由多台机器组成一个集群，每台机器上都运行着相同的缓存服务进程，缓存数据被均匀地分布在集群中的各个节点上。

Redis 是分布式缓存的首选，甚至我们一提到缓存，很多后端工程师首先想到的就它。

下图是神州专车订单的 Redis 集群架构 。将 Redis 集群拆分成四个分片，每个分片包含一主一从，主从可以切换。应用 A 根据不同的缓存 key 访问不同的分片。

![图片](https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n284ibDPWJU5KZLDFibX01NEYiaVGgFqer7oa0SCL6iaiamwgZHleEMv1LgAtI8X3ohNGww7stl82RpNong/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

与本地缓存相比，分布式缓存具有以下优点：

**1、容量和性能可扩展**

通过增加集群中的机器数量，可以扩展缓存的容量和并发读写能力。同时，缓存数据对于应用来讲都是共享的。

**2、高可用性**

由于数据被分布在多台机器上，即使其中一台机器故障，缓存服务也能继续提供服务。

但是分布式缓存的缺点同样不容忽视。

**1、网络延迟**

分布式缓存通常需要通过网络通信来进行数据读写，可能会出现网络延迟等问题，相对于本地缓存而言，响应时间更长。

**2、复杂性**

分布式缓存需要考虑序列化、数据分片、缓存大小等问题，相对于本地缓存而言更加复杂。

------

举一个真实的案例，这次案例让笔者对于分布式缓存的认知提上了另一个台阶。

2014年，同事开发了比分直播的系统，所有的请求都是从分布式缓存 Memcached 中获取后直接响应。常规情况下，从缓存中查询数据非常快，但在线用户稍微多一点，整个系统就会特别卡。

通过 jstat 命令发现 GC 频率极高，几次请求就将新生代占满了，而且 CPU 的消耗都在 GC 线程上。初步判断是缓存值过大导致的，果不其然，缓存大小在 300k 到 500k 左右。

解决过程还比较波折，分为两个步骤：

1. **修改新生代大小**，从原来的 2G 修改成 4G，并精简缓存数据大小 (从平均 300k 左右降为 80k 左右)；
2. 把**缓存拆成两个部分**，第一部分是**全量数据**，第二部分是**增量数据**（数据量很小）。页面第一次请求拉取全量数据，当比分有变化的时候，通过 websocket 推送增量数据。

经过这次优化，笔者理解到：缓存虽然可以提升整体速度，但是在高并发场景下，缓存对象大小依然是需要关注的点，稍不留神就会产生事故。另外我们也需要合理地控制读取策略，最大程度减少 GC 的频率 , 从而提升整体性能。

## 4 多级缓存

开源中国网站最开始完全是用本地缓存框架 Ehcache 。后来随着访问量的激增，出现了一个可怕的问题：“因为 Java 程序更新很频繁，每次更新的时候都要重启。一旦重启后，整个 Ehcache 缓存里的数据都被清掉。重启后若大量访问进来的话，开源中国的数据库基本上很快就会崩掉”。

于是，开源中国开发了多级缓存框架  **J2Cache**，使用了多级缓存 **Ehcache + Redis** 。

多级缓存有如下优势：

1. 离用户越近，速度越快；
2. 减少分布式缓存查询频率，降低序列化和反序列化的 CPU 消耗；
3. 大幅度减少网络 IO 以及带宽消耗。

本地缓存做为一级缓存，分布式缓存做为二级缓存，首先从一级缓存中查询，若能查询到数据则直接返回，否则从二级缓存中查询，若二级缓存中可以查询到数据，则回填到一级缓存中，并返回数据。若二级缓存也查询不到，则从数据源中查询，将结果分别回填到一级缓存，二级缓存中。

![图片](https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n284ibDPWJU5KZLDFibX01NEYiayQALMNZRUdOux1gLmOIlcxGb3wls1Z7foNJrgbEX8ZwWcy9VWZemhA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

2018年，笔者服务的一家电商公司需要进行 app 首页接口的性能优化。笔者花了大概两天的时间完成了整个方案，采取的是两级缓存模式，同时利用了 Guava 的惰性加载机制，整体架构如下图所示：

![图片](https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n284ibDPWJU5KZLDFibX01NEYiaWcxxvDd9n1wwf7yTA6hpdWIJNaG5jXydvAE4wO9IHZ9QEnOvYdfURA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

缓存读取流程如下：

1、业务网关刚启动时，本地缓存没有数据，读取 Redis 缓存，如果 Redis 缓存也没数据，则通过 RPC 调用导购服务读取数据，然后再将数据写入本地缓存和 Redis 中；若 Redis 缓存不为空，则将缓存数据写入本地缓存中。

2、由于步骤1已经对本地缓存预热，后续请求直接读取本地缓存，返回给用户端。

3、Guava 配置了 refresh 机制，每隔一段时间会调用自定义 LoadingCache 线程池（5个最大线程，5个核心线程）去导购服务同步数据到本地缓存和 Redis 中。

优化后，性能表现很好，平均耗时在 5ms 左右。最开始我以为出现问题的几率很小，可是有一天晚上，突然发现 app 端首页显示的数据时而相同，时而不同。

也就是说：虽然 LoadingCache 线程一直在调用接口更新缓存信息，但是各个 服务器本地缓存中的数据并非完成一致。说明了两个很重要的点：

1、惰性加载仍然可能造成多台机器的数据不一致

2、LoadingCache 线程池数量配置的不太合理,  导致了线程堆积

最终，我们的解决方案是：

1、惰性加载结合消息机制来更新缓存数据，也就是：当导购服务的配置发生变化时，通知业务网关重新拉取数据，更新缓存。

2、适当调大 LoadigCache 的线程池参数，并在线程池埋点，监控线程池的使用情况，当线程繁忙时能发出告警，然后动态修改线程池参数。

## 5 总结

Fred Brooks 在 1987 年所发表的一篇关于软件工程的经典论文《**没有银弹：软件工程的本质性与附属性工作**》。

论文强调真正的银弹并不存在，而所谓的银弹则是指没有任何一项技术或方法可以能让软件工程的生产力在十年内提高十倍。

通俗来讲：**在技术领域中没有一种通用的解决方案可以解决所有问题**。技术本质上是为了解决问题而存在的，每个问题都有其独特的环境和限制条件，没有一种通用的技术或工具可以完美地解决所有问题。

**缓存是把双刃剑**，一方面我们享受缓存带来的系统性能提升，另一方面引入缓存会提高系统复杂度，因为你要考虑缓存的失效、更新、一致性等问题。

在面临缓存选型时，一定要结合业务场景，研发效率，运维成本，人力模型，技术储备等因素，做出合理的选择。











































