



# 安装、启动、配置

官网：https://prometheus.io/

下载地址：https://prometheus.io/download/

## 二进制版安装

### 最简安装

https://gitee.com/linge365/prometheus

```sh
cd /opt
git clone https://gitee.com/linge365/prometheus.git
cd prometheus
# 移动systemd 服务到/etc/systemd/system/目录下
mv *.service /etc/systemd/system/
#检查
ls -l /etc/systemd/system/
```

```sh
# 创建一个专门的 prometheus 用户：
useradd -M -s /usr/sbin/nologin prometheus
# 更改 prometheus 用户的文件夹权限：
chown prometheus:prometheus -R /opt/prometheus
```

### 启动命令

```sh
systemctl daemon-reload
systemctl start prometheus.service
systemctl start grafana-server.service
systemctl start node_exporter.service
systemctl start alertmanager.service
```

### 设置开机自启

```sh
systemctl enable prometheus.service
systemctl enable grafana-server.service
systemctl enable node_exporter.service
systemctl enable alertmanager.service
```

### 检查启动状态

```sh
systemctl status node_exporter.service
systemctl status prometheus.service
systemctl status grafana-server.service
systemctl status alertmanager.service
ss -lntp|egrep "3000|9090|9100|9093"
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011102670.png" alt="image-20230501110215582" style="zoom:80%;" />

## Docker版安装

### 安装Docker

```json
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<-'EOF'
{
   "registry-mirrors": ["http://hub-mirror.c.163.com"]
}
EOF
```

```sh
export DOWNLOAD_URL="http://mirrors.163.com/docker-ce"
curl -fsSL https://get.docker.com/ | sh
```

```sh
docker -v
systemctl start docker
systemctl enable docker
systemctl status docker
```

### 安装Docker-compose

```sh
# Compose目前已经完全支持Linux、Mac OS和Windows，在我们安装Compose之前，需要先安装Docker。下面我 们以编译好的二进制包方式安装在Linux系统中。 
curl -L "https://github.com/docker/compose/releases/download/1.28.6/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
# 设置文件可执行权限 
sudo chmod +x /usr/local/bin/docker-compose
# 查看版本信息 
docker-compose -version
```

### 查看最新版本

https://hub.docker.com/r/prom/prometheus/tags

https://hub.docker.com/r/prom/alertmanager/tags

https://hub.docker.com/r/prom/node-exporter/tags

### 最简安装⭐

https://gitee.com/linge365/docker-prometheus

注意：此时所有内容均放在Gitee仓库中了，克隆下来即可

```sh
mkdir /data/
cd /data/
yum install -y git
git clone https://gitee.com/linge365/docker-prometheus.git
cd docker-prometheus
```

```sh
# 如果下载没成功，就多试几次
docker-compose up -d
```

### 检查端口

```sh
docker ps
ss -lntp|egrep "3000|9090|9100|9093"
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011102670.png" alt="image-20230501110215582" style="zoom:80%;" />

### 图形展示

> 登录Grafana http://192.168.88.102:3000/
>
> 用户名：admin，密码：password

在 Grafana 中创建 Prometheus 数据源：

单击边栏中的“齿轮”，打开“配置”菜单。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011114421.png" alt="image-20230501111415294" style="zoom:67%;" />

选择“Prometheus”作为类型。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011114900.png" alt="image-20230501111434779" style="zoom:80%;" />

url填入： http://prometheus:9090 注：docker容器一般通过主机名链接，因为ip会变。单击“保存并测试”

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011115756.png" alt="image-20230501111509634" style="zoom:80%;" />

导入仪表盘：https://grafana.com/grafana/dashboards/

打开grafana的dashboards官网，在搜索栏输入node exporter回车，点击下载量大的dashboards如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011116933.png" alt="image-20230501111613771" style="zoom:67%;" />

打开grafana web控制台--点击dashbord图标--在点import导入--粘贴之前复制的id, 1860 --在点load加载

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011116142.png" alt="image-20230501111634967" style="zoom:67%;" />

name填写“服务器监控”（根据实际修改），选择“prometheus”--在点import导入

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011116949.png" alt="image-20230501111653790" style="zoom:67%;" />

导入dashbord完成后，如下图

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011117333.png" alt="image-20230501111709195" style="zoom:80%;" />

### 内容详解

> Prometheus 采集数据
>
> Grafana 用于图表展示
>
> alertmanager 用于接收 Prometheus 发送的告警信息
>
> node-exporter 用于收集操作系统和硬件信息的metrics
>
> cadvisor 用于收集docker的相关metrics

#### docker-compose.yml

```yml
version: '3.3'

volumes:
  prometheus_data: {}
  grafana_data: {}

networks:
  monitoring:
    driver: bridge

services:
  prometheus:
    image: prom/prometheus:v2.37.6
    container_name: prometheus
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./prometheus/:/etc/prometheus/
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      #热加载配置
      - '--web.enable-lifecycle'
      #api配置
      #- '--web.enable-admin-api'
      #历史数据最大保留时间，默认15天
      - '--storage.tsdb.retention.time=30d'  
    networks:
      - monitoring
    links:
      - alertmanager
      - cadvisor
      - node_exporter
    expose:
      - '9090'
    ports:
      - 9090:9090
    depends_on:
      - cadvisor

  alertmanager:
    image: prom/alertmanager:v0.25.0
    container_name: alertmanager
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./alertmanager/:/etc/alertmanager/
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
    networks:
      - monitoring
    expose:
      - '9093'
    ports:
      - 9093:9093

  cadvisor:
    image: google/cadvisor:latest
    container_name: cadvisor
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    networks:
      - monitoring
    expose:
      - '8080'

  node_exporter:
    image: prom/node-exporter:v1.5.0
    container_name: node-exporter
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command: 
      - '--path.procfs=/host/proc' 
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc|rootfs/var/lib/docker)($$|/)'
    networks:
      - monitoring
    ports:
      - '9100:9100'

  grafana:
    image: grafana/grafana:9.4.3
    container_name: grafana
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning/:/etc/grafana/provisioning/
    env_file:
      - ./grafana/config.monitoring
    networks:
      - monitoring
    links:
      - prometheus
    ports:
      - 3000:3000
    depends_on:
      - prometheus
```

#### prometheus/alert.yml

```yml
groups:
- name: Prometheus alert
  rules:
  # 对任何实例超过30秒无法联系的情况发出警报
  - alert: 服务告警
    expr: up == 0
    for: 30s
    labels:
      severity: critical
    annotations:
      summary: "服务异常,实例:{{ $labels.instance }}"
      description: "{{ $labels.job }} 服务已关闭"
```

#### prometheus/prometheus.yml

```yml
# 全局配置
global:
  scrape_interval:     15s # 将搜刮间隔设置为每15秒一次。默认是每1分钟一次。
  evaluation_interval: 15s # 每15秒评估一次规则。默认是每1分钟一次。

# Alertmanager 配置
alerting:
  alertmanagers:
  - static_configs:
    - targets: ['alertmanager:9093']

# 报警(触发器)配置
rule_files:
  - "alert.yml"

# 搜刮配置
scrape_configs:
  - job_name: 'prometheus'
    # 覆盖全局默认值，每15秒从该作业中刮取一次目标
    scrape_interval: 15s
    static_configs:
    - targets: ['localhost:9090']
  - job_name: 'alertmanager'
    scrape_interval: 15s
    static_configs:
    - targets: ['alertmanager:9093']
  - job_name: 'cadvisor'
    scrape_interval: 15s
    static_configs:
    - targets: ['cadvisor:8080']
      labels:
        instance: Prometheus服务器 

  - job_name: 'node-exporter'
    scrape_interval: 15s
    static_configs:
    - targets: ['node_exporter:9100']
      labels:
        instance: Prometheus服务器 
```

#### grafana/config.monitoring

```sh
GF_SECURITY_ADMIN_PASSWORD=password
GF_USERS_ALLOW_SIGN_UP=false
```

#### alertmanager/config.yml

```yml
global:
  #163服务器
  smtp_smarthost: 'smtp.163.com:465'
  #发邮件的邮箱
  smtp_from: 'cdring@163.com'
  #发邮件的邮箱用户名，也就是你的邮箱　　　　　
  smtp_auth_username: 'cdring@163.com'
  #发邮件的邮箱密码
  smtp_auth_password: 'your-password'
  #进行tls验证
  smtp_require_tls: false

route:
  group_by: ['alertname']
  # 当收到告警的时候，等待group_wait配置的时间，看是否还有告警，如果有就一起发出去
  group_wait: 10s
  #  如果上次告警信息发送成功，此时又来了一个新的告警数据，则需要等待group_interval配置的时间才可以发送出去
  group_interval: 10s
  # 如果上次告警信息发送成功，且问题没有解决，则等待 repeat_interval配置的时间再次发送告警数据
  repeat_interval: 10m
  # 全局报警组，这个参数是必选的
  receiver: email

receivers:
- name: 'email'
  #收邮件的邮箱
  email_configs:
  - to: 'cdring@163.com'
inhibit_rules:
 - source_match:
     severity: 'critical'
   target_match:
     severity: 'warning'
   equal: ['alertname', 'dev', 'instance']
```

## web 页面查看

浏览器输入：http://node1:9090/

### 查看启动情况

点击 Status，选中 Targets：prometheus、pushgateway 和 node exporter 都是 up 状态，表示安装启动成功：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304251019922.png" alt="image-20230425101903809" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304251019419.png" alt="image-20230425101923356" style="zoom:80%;" />

### 查看规则配置

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304251019511.png" alt="image-20230425101949440" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304251020084.png" alt="image-20230425102004982" style="zoom:80%;" />

### 查看告警

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304251017286.png" alt="image-20230425101719191" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304251018295.png" alt="image-20230425101825205" style="zoom:80%;" />



## 动态加载配置

```sh
# prometheus
curl -X POST http://node1:9090/-/reload
# altermanager
curl -X POST http://node1:9093/-/reload     
```

执行命令检查规则配置是否正确

```sh
./promtool check config prometheus.yml
./promtool check rules first_rules.yml
./promtool check rules second_rules.yml
```

## 系统负载工具

### stress

```sh
sudo yum install epel-release
sudo yum update
sudo yum install stress
```

```sh
# 模拟CPU负载，这会模拟4个CPU核心的负载，在60秒后停止。
stress --cpu 4 --timeout 60s
# 模拟内存负载，这会模拟使用512MB内存的虚拟机，持续60秒
stress --vm 1 --vm-bytes 512M --timeout 60s
# 模拟IO负载，这会模拟4个IO操作，在60秒后停止。
stress --io 4 --timeout 60s
# 模拟磁盘负载，这会模拟写入1GB数据的磁盘操作，在60秒后停止
stress --hdd 1 --hdd-bytes 1G --timeout 60s
```

### lookbusy

```sh
# 下载编译安装lookbusy
wget http://www.devin.com/lookbusy/download/lookbusy-1.4.tar.gz
tar -xzf lookbusy-1.4.tar.gz
cd lookbusy-1.4
./configure
make & make install
```

```sh
# 所有的cpu使用率都是30%
lookbusy -c 30
# 占用所有 CPU 核心各 70%
lookbusy -c 70 
# 占用两个 CPU 核心各 70%
lookbusy -c 70 -n 2 
# 占用所有 CPU 核心在 60%-70% 上下浮动
lookbusy -c 60-70 -r curve 
# cpu以60分钟为周期，30分钟是峰值，使用率在60%-70%上下浮动
lookbusy -c 60-70 --cpu-mode curve --cpu-curve-period 60m --cpu-curve-peak 30m 
```

# Prometheus

## 概述

> Prometheus是一个开源系统监控和警报工具包，受启发于Google的Brogmon监控系统（相似的Kubernetes是从Google的Brog系统演变而来），从2012年开始由前Google工程师在Soundcloud以开源软件的形式进行研发，并且于2015年早期对外发布早期版本。2016年5月继Kubernetes之后成为第二个正式加入CNCF基金会的项目，同年6月正式发布1.0版本。2017年底发布了基于全新存储层的2.0版本，能更好地与容器平台、云平台配合。

### 主要特点

> 支持多维数据模型由指标名称和键值对标识的时间序列数据
>
> **内置时间序列库TSDB（Time Serices Database）**
>
> **支持PromQL（Promethues Query Language），对数据的查询和分析、图形展示和监控告警**。
>
> **不依赖分布式存储**；单个服务器节点是自治的
>
> **支持HTTP 的拉取(pull)方式收集时间序列数据**
>
> 通过中间网关**Pushgateway推送时间序列**
>
> **通过服务发现或静态配置2种方式发现目标**
>
> **支持多种可视化和仪表盘**，如：grafana

### 核心组件

> Prometheus Server， 主要用于抓取数据和存储时序数据，另外还提供查询和 Alert Rule 配置管理。
>
> client libraries，用于检测应用程序代码的客户端库。
>
> push gateway ，用于批量，短期的监控数据的汇总节点，主要用于业务数据汇报等。
>
> exporters 收集监控样本数据，并以标准格式向 Prometheus 提供。例如：收集服务器系统数据的
>
> node_exporter, 收集 MySQL 监控样本数据的是 MySQL exporter 等等。
>
> alertmanager，用于告警通知管理的 。

### 基础架构

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304262023960.png" alt="image-20230426202349845" style="zoom:80%;" />

架构图看出 Prometheus 主要模块包含， Server, Exporters, Pushgateway, PromQL,Alertmanager, WebUI 

它大致使用逻辑是这样：

> Prometheus server 定期从静态配置的 targets 或者服务发现的 targets 拉取数据（Targets是Prometheus采集Agent需要抓取的采集目标）

> 当新拉取的数据大于配置内存缓存区的时候，Prometheus 会将数据持久化到磁盘（如果使用 remote storage 将持久化到云端）。

> Prometheus 可以配置 rules，然后定时查询数据，当条件触发的时候，会将 alerts 推送到配置的 Alertmanager
>
> Alertmanager 收到警告的时候，可以根据配置（163，钉钉等），聚合，去重，降噪，最后发送警告。
>
> 可以使用 API， Prometheus Console 或者 Grafana 查询和聚合数据。

### Prometheus VS Zabbix

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304262026608.png" alt="image-20230426202611516" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304262026077.png" alt="image-20230426202628979" style="zoom:80%;" />

> 监控系统没有绝对的谁好谁不好，最重要的是适合自己的公司团队，能够合理利用最小的成本解决问题。
>
> prometheus，zabbix 都只是工具，监控思想才是最重要的。实在不知道怎么选？参考如下：

> 物理机、硬件设备的监控推荐使用Zabbix
>
> 而Docker容器，Kubernetes监控推荐用Prometheus
>
> 云服务器厂商自带有监控系统，有的监控不全面，也可以搭配zabbix和Prometheus来一起使用

## 相关概念

### 时间序列

> 安装好prometheus后会暴露一个/metrics的HTTP服务（相当于安装了prometheus_exporter），通过配置（默认会加上/metrics），Prometheus就可以采集到这个/metrics里面所有监控样本数据。例如：

```sh
# HELP process_open_fds Number of open file descriptors.
# TYPE process_open_fds gauge
process_open_fds 25
```

### 样本

> Prometheus 会将所有采集到的监控样本数据以时间序列的方式保存在**内存数据库**中，并且定时保存到硬盘上。时间序列是按照时间戳和值的序列顺序存放的，我们称之为向量(vector)，每条时间序列通过指标名称(metrics name)和一组标签集(label)命名。如下所示，可以将时间序列理解为一个以时间为 X 轴的数字矩阵：

```sh
^
│ . . . . . . . . . . . . . . . . . . . process_open_fds
│ . . . . . . . . . . . . . . . . . . .
node_cpu_seconds_total{cpu="cpu0",mode="system"}
│ . . . . . . . . . . . . . . . . . . node_load1{}
│ . . . . . . . . . . . . . . . . . .
v
<------------------ 时间 ---------------->
```

在时间序列中的每一个点称为一个样本（sample），样本由以下三部分组成：

> 指标(metric)：指标名和描述当前样本特征的标签集合
>
> 时间戳(timestamp)：一个精确到毫秒的时间戳
>
> 样本值(value)： 一个 float64 的浮点型数据表示当前样本的值

```sh
process_open_fds 27
```

```sh
<--------------------- metric ------------------------------><-timestamp -><-value->
process_open_fds{instance="localhost:9090", job="prometheus"} @1434417560938 39
process_open_fds{instance="localhost:9090", job="prometheus"} @1434417561287 33
process_open_fds{instance="localhost:9090", job="prometheus"} @1434417560938 35
process_open_fds{instance="localhost:9090", job="prometheus"} @1434417561287 37
process_open_fds{instance="localhost:9090", job="prometheus"} @1434417560938 36
process_open_fds{instance="localhost:9090", job="prometheus"} @1434417561287 25
<--metric_name-><----------------lable---------------------->
<--metric_name-><--name--><----value----> <name><--value--->
```

### 指标(Metric)

在形式上，所有的指标(Metric)都通过如下格式标示：

```sh
<metric name>{<label name>=<label value>, ...}
```

> 指标的名称(metric name)可以反映被监控样本的含义（比如， process_open_fds - 表示当前系统打开的文件描述符）。指标名称只能由ASCII字符、数字、下划线以及冒号组成并必须符合正则表达式 [a-zA-Z\_:] [a-zA-Z0-9_:]* 。

> 标签(label)反映了当前样本的特征维度，通过这些维度Prometheus可以对样本数据进行过滤，聚合等。标签的名称只能由ASCII字符、数字以及下划线组成并满足正则表达式 \[a-zA-Z\_][a-zA-Z0-9_]* 。

> 其中以 __ 作为前缀的标签，是系统保留的关键字，只能在系统内部使用。标签的值则可以包含任何Unicode编码的字符。在Prometheus的底层实现中指标名称实际上是以 __name__=\<metric name> 的形式保存在数据库中的，因此以下两种方式均表示的同一条time-series：

```sh
process_open_fds{instance="localhost:9090", job="prometheus"}
{__name__="process_open_fds",instance="localhost:9090",job="prometheus"}
```

### 指标类型

> Prometheus 底层存储上其实并没有对指标做类型的区分，都是以时间序列的形式存储，但是为了方便用户的使用和理解不同监控指标之间的差异，Prometheus 定义了 counter（计数器） 、gauge（仪表盘） 、histogram（直方图） 以及 summary （摘要）这四种 Metrics 类型。

> **Gauge/Counter** **是数值指标，代表数据的变化情况，Histogram/Summary是统计类型的指标，表示数据的分布情况**。在Exporter返回的样本数据中，其注释中也包含了该样本的类型。例如：

```sh
# HELP process_resident_memory_bytes Resident memory size in bytes.
# TYPE process_resident_memory_bytes gauge
process_resident_memory_bytes 1.3586432e+08
```

#### Counter：只增不减的计数器

> Counter类型的指标其工作方式和计数器一样，只增不减（除非系统发生重置）。常见的监控指标，如node_cpu，http_requests_total都是Counter类型的监控指标。 一般在定义Counter类型指标的名称时推荐使用_total作为后缀。

> 通过 Counter 指标可以统计 HTTP 请求数量，请求错误数，接口调用次数等单调递增的数据，同时可结合increase 和 rate 等函数统计变化速率

```sh
# 通过PromQL内置的聚合rate()函数获取HTTP请求量的评价增长率
rate(prometheus_http_requests_total[5m])
# 查询当前系统中，访问量前10的HTTP地址
topk(10, prometheus_http_requests_total)
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304262147824.png" alt="image-20230426214732686" style="zoom:80%;" />

#### Gauge：可增可减的仪表盘

> 与Counter不同，Gauge类型的指标侧重于反应系统的当前状态。因此这类指标的样本数据可增可减。常见指标如：node_memory_MemFree_bytes（主机当前空闲的物理内存大小）、node_memory_MemAvailable_bytes （可用内存大小）都是Gauge类型的监控指标。

```sh
# 通过Gauge指标，通过PromQL可以直接查看系统的当前空闲物理内存大小
node_memory_MemFree_bytes
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304262148547.png" alt="image-20230426214826417" style="zoom:80%;" />

> 对于Gauge类型的监控指标，通过PromQL内置函数delta()可以获取样本在一段时间返回内的变化情况。例如，计算CPU温度在两个小时内的差异：

```sh
delta(cpu_temp_celsius{host="zeus"}[2h])
```

> 还可以使用deriv()计算样本的线性回归模型，甚至是直接使用predict_linear()对数据的变化趋势进行预测。例如，预测系统磁盘空间在4个小时之后的剩余情况：

```sh
predict_linear(node_filesystem_avail_bytes{}[1h], 4 * 3600)
```

#### 分析数据分布情况

> 除了Counter和Gauge类型的监控指标以外，Prometheus还定义了Histogram和Summary的指标类型。Histogram和Summary主用用于统计和分析样本的分布情况。

> 在大多数情况下人们都倾向于使用某些量化指标的平均值，例如CPU的平均使用率、页面的平均响应时间。这种方式的问题很明显，以系统API调用的平均响应时间为例：如果大多数API请求都维持在100ms的响应时间范围内，而个别请求的响应时间需要5s，那么就会导致某些WEB页面的响应时间落到中位数的情况，这种现象被称为长尾问题

> 为了区分是平均的慢还是长尾的慢，最简单的方式就是按照请求延迟的范围进行分组。例如，统计延迟在0~10ms之间的请求数有多少而10~20ms之间的请求数又有多少。通过这种方式可以快速分析系统慢的原因。Histogram和Summary都是为了能够解决这样问题的存在，通过Histogram和Summary类型的监控指标，我们可以快速了解监控样本的分布情况。

> 例如，指标prometheus_tsdb_wal_fsync_duration_seconds的指标类型为Summary。 它记录了Prometheus Server中wal_fsync处理的处理时间，通过访问Prometheus Server的/metrics地址，可以获取到以下监控样本数据：

```sh
# HELP prometheus_tsdb_wal_fsync_duration_seconds Duration of WAL fsync.
# TYPE prometheus_tsdb_wal_fsync_duration_seconds summary
prometheus_tsdb_wal_fsync_duration_seconds{quantile="0.5"} 0.012352463
prometheus_tsdb_wal_fsync_duration_seconds{quantile="0.9"} 0.014458005
prometheus_tsdb_wal_fsync_duration_seconds{quantile="0.99"} 0.017316173
prometheus_tsdb_wal_fsync_duration_seconds_sum 2.888716127000002
prometheus_tsdb_wal_fsync_duration_seconds_count 216
```

从上面的样本中可以得知当前Prometheus Server进行wal_fsync操作的总次数为216次，耗时2.888716127000002s。其中中位数（quantile=0.5）的耗时为0.012352463，9分位数（quantile=0.9）的耗时为0.014458005s。

在Prometheus Server自身返回的样本数据中，我们还能找到类型为Histogram的监控指标

```sh
# HELP prometheus_tsdb_compaction_chunk_range_seconds Final time range of chunks on
their first compaction
# TYPE prometheus_tsdb_compaction_chunk_range_seconds histogram
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="100"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="400"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="1600"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="6400"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="25600"} 61
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="102400"} 1095
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="409600"} 1208
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="1.6384e+06"} 3184
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="6.5536e+06"} 217665
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="2.62144e+07"} 217695
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="+Inf"} 217695
prometheus_tsdb_compaction_chunk_range_seconds_sum 3.91254640158e+11
prometheus_tsdb_compaction_chunk_range_seconds_count 217695
```

> 与Summary类型的指标相似之处在于Histogram类型的样本同样会反应当前指标的记录的总数(以\_count作为后缀)以及其值的总量（以\_sum作为后缀）。不同在于Histogram指标直接反应了在不同区间内样本的个数，区间通过标签len进行定义。

> 同时对于Histogram的指标，我们还可以通过histogram_quantile()函数计算出其值的分位数。不同在于Histogram通过histogram_quantile函数是在服务器端计算的分位数。 而Sumamry的分位数则是直接在客户端计算完成。因此对于分位数的计算而言，Summary在通过PromQL进行查询时有更好的性能表现，而Histogram则会消耗更多的资源。反之对于客户端而言Histogram消耗的资源更少。在选择这两种方式时用户应该按照自己的实际场景进行选择。

需要特别注意的是，假设采样数据 metric 叫做 x(指标名) , 如果 x 是 histogram 或 summary 类型必需满足以下条件：

> 采样数据的总和应表示为 x_sum 。
>
> 采样数据的总量应表示为 x_count 。
>
> summary 类型的采样数据的 quantile 应表示为 x{quantile="y"} 。
>
> histogram 类型的采样分区统计数据将表示为 x_bucket{le="y"} 。
>
> histogram 类型的采样必须包含 x_bucket{le="+Inf"} , 它的值等于 x_count 的值。summary 和 historam 中 quantile 和 le 必需按从小到大顺序排列。

### job（任务）和instances（实例）

> 在Prometheus中，任何被采集的目标，即每一个暴露监控样本数据的HTTP服务都称为一个实例（Instance）,例如在当前主机上运行的node exporter可以被称为一个实例(Instance)。而具有相同采集目的的实例集合称为任务Job

#### job（任务）

例如，以下2个复制实例的node作业：

```sh
* job: node
  * instance 2: 1.2.3.4:9100
  * instance 4: 5.6.7.8:9100
```

#### instances（实例）

> 通过在prometheus.yml配置文件中，添加如下配置。我们让Prometheus可以从node exporter暴露的服务中获取监控指标数据。

```yml
scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['prometheus:9090']
  - job_name: 'alertmanager'
    static_configs:
      - targets: ['alertmanager:9093']
  - job_name: 'node-exporter'
    static_configs:
      - targets:
          - 'node-exporter:9100'
          - '192.168.11.62:9100'
```

当我们需要采集不同的监控指标(例如：主机、MySQL、Nginx)时，我们只需要运行相应的监控采集程序，在Prometheus Server配置这些Exporter实例的访问地址。

#### 实例状态

除了通过使用“up”表达式查询当前所有Instance的状态以外，还可以通过Prometheus UI中的Targets页面查看当前所有的监控采集任务，以及各个任务下所有实例的状态:

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304262156085.png" alt="image-20230426215654952" style="zoom:80%;" />

## Exporter

https://prometheus.io/docs/instrumenting/exporters/#databases

https://github.com/prometheus-community

### 概述

> 所有可以向Prometheus提供监控样本数据的程序都可以被称为⼀个Exporter。⽽Exporter的⼀个实例称为target，如下所示，Prometheus通过轮询的⽅式定期从这些target中获取样本数据:

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261717029.png" alt="image-20230426171704919" style="zoom:80%;" />

> 注：安装好Exporter后会暴露⼀个 http://ip:端⼝/metrics 的HTTP服务
>
> 通过Prometheus添加配置 -targets: ['node_exporter:9100'] （默认会加上/metrics）
>
> Prometheus就可以采集到这个http://ip:端⼝/metrics ⾥⾯所有监控样本数据

### 来源

从Exporter的来源上来讲，主要分为两类：社区提供的、⽤户⾃定义的

社区提供的( https://prometheus.io/docs/instrumenting/exporters/ )

#### 社区提供

> Prometheus社区提供了丰富的Exporter实现，涵盖了从基础设施，中间件以及⽹络等各个⽅⾯的监控功能。这些Exporter可以实现⼤部分通⽤的监控需求。下表列举⼀些社区中常⽤的Exporter：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209092016928.png" alt="image-20220909201647860" style="zoom:80%;" />

#### 用户自定义

> 除了直接使⽤社区提供的Exporter程序以外，⽤户还可以基于Prometheus提供的Client Library创建⾃⼰的Exporter程序，⽬前Promthues社区官⽅提供了对以下编程语⾔的⽀持：Go、Java/Scala、Python、Ruby。同时还有第三⽅实现的如：Bash、C++、Common Lisp、Erlang,、Haskeel、Lua、Node.js、PHP、Rust等。

### Exporter 类型

通常来说可以将Exporter分为两类：

#### 直接采集型

> 这类Exporter直接内置了相应的应⽤程序，⽤于向Prometheus直接提供Target数据⽀持。这样设计的好处是，可以更好地监控各⾃系统的内部运⾏状态，同时也适合更多⾃定义监控指标的项⽬实施。例如cAdvisor、Kubernetes等，它们均内置了⽤于向Prometheus提供监控数据的端点。

#### 间接采集型

> 原始监控⽬标并不直接⽀持Prometheus，需要我们使⽤Prometheus提供的Client Library编写该监控⽬标的监控采集程序，⽤户可以将该程序独⽴运⾏，去获取指定的各类监控数据值。例如，由于Linux操作系统⾃身并不能直接⽀持Prometheus，⽤户⽆法从操作系统层⾯上直接提供对Prometheus的⽀持，因此单独安装Node exporter，还有数据库或⽹站HTTP应⽤类等Exporter。

### Exporter 规范

> 所有的Exporter程序都需要按照Prometheus的规范，返回监控的样本数据。以Node Exporter为例，当访问：http://192.168.11.61:9100/metrics地址时会返回以下内容：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261722470.png" alt="image-20230426172235347" style="zoom:67%;" />

- 以#开始的⾏通常都是注释内容。这些样本数据集合说明如下：
- 以#HELP开始的⾏，表示metric的帮助与说明注释，可以包含当前监控指标名称和对应的说明信息。
- 以#TYPE开始的⾏，表示定义metric类型，可以包含当前监控指标名称和类型，类型有Counter、Gauge、Histogram、Summary和Untyped。
- ⾮#开头的⾏，就是监控样本数据

### 监控样本数据规范

```sh
metric_name [
 "{" label_name "=" `"` label_value `"` { "," label_name "=" `"`
label_value `"` } [ "," ] "}"
] value [ timestamp ]
```

> 其中metric_name和label_name必须遵循PromQL的格式规范要求。value是⼀个float格式的数据，timestamp的类型为int64（从1970-01-01 00:00:00以来的毫秒数），timestamp为可选默认为当前时间。具有相同metric_name的样本必须按照⼀个组的形式排列，并且每⼀⾏必须是唯⼀的指标名称和标签键值对组合。

```sh
go_memstats_mcache_sys_bytes{} 15600
go_memstats_mcache_sys_bytes{instance="localhost:9090", job="prometheus"} timestamp VALUE
```



# PromQL

> Prometheus 通过指标名称（metrics name）以及对应的一组标签（labelset）唯一定义一条时间序列。指标名称反映了监控样本的基本标识，而 label 则在这个基本特征上为采集到的数据提供了多种特征维度。用户可以基于这些特征维度过滤，聚合，统计从而产生新的计算后的一条时间序列。PromQL 是 Prometheus **内置的数据查询语言**，其提供对时间序列数据丰富的查询，聚合以及逻辑运算能力的支持。并且被广泛应用在 Prometheus的日常应用当中，包括对数据查询、可视化、告警处理当中。可以这么说，PromQL 是Prometheus 所有应用场景的基础，理解和掌握 PromQL 是 Prometheus 入门的第一课。[HTTP API中使用PromQL](https://prometheus.io/docs/prometheus/latest/querying/api/)

[官网地址](https://prometheus.io/docs/prometheus/latest/querying/basics/)

## 数据类型

在Prometheus的表达式语言中，PromQL数据类型归类为以下四种：

> **瞬时向量（instant vector）**，是指同一时刻的一组时间序列，每个时间序列包含一个样本，所有样本共享相同的时间戳，即每个时序只有一个点。
>
> **区间向量（range vector）**，是指在任何一个时间范围内的一组时间序列，包含每个时间序列随时间变化的一系列数据点，这时每个时序有多个点。
>
> **标量（scalar）**，即纯量数据，一个简单的数字浮点值，只有一个数字，没有时序。
>
> **字符串（string）**，一个目前未被使用的简单字符串值。

### 瞬时向量（Instant vector）

我们在Prometheus的查询页面输入指标 node_memory_Active_bytes 进行查询。返回如下的结果：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304270918730.png" alt="image-20230427091832593" style="zoom:80%;" />

### 区间向量（Range vector）

我们在Prometheus的查询页面输入一个查询语句 node_memory_Active_bytes[1m] 进行查询。返回如下的结果：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304270919770.png" alt="image-20230427091907621" style="zoom:80%;" />

> 以上的查询语句是查询 最近一分钟数据，因为采集的周期是 15s 所以[1m]每一个时序会有4个数据。区间向量（Range vector）类型数据是指时序有一个时间区间的数据，这种类型的数据成为区间向量（Range vector）。
>

### 标量（Scalar）

标量只有一个数字，没有时序。

```
1024
```

> 需要注意的是，当使用表达式count(http_requests_total)，返回的数据类型，依然是瞬时向量。用户可以通过内置函数scalar()将单个瞬时向量转换为标量。

### 字符串（String）

直接使用字符串，作为PromQL表达式，则会直接返回字符串。(目前未被使用)

```sh
"this is a string"
'these are unescaped: \n \\ \t'
`these are not unescaped: \n ' " \t`
```

## 时间序列过滤器

### 瞬时向量过滤器

> 瞬时向量过滤器允许在指定的时间戳内选择一组时间序列和每个时间序列的单个样本值。在最简单的形式中，近指定指标（metric）名称。这将生成包含此指标名称的所有时间序列的元素的瞬时向量。

例如：选择指标名称为 node_cpu_seconds_total 的所有时间序列：

```
node_cpu_seconds_total
```

可以通过向花括号 {} 里附加一组标签来进一步过滤时间序列。

例：选择指标名称为 node_cpu_seconds_total ， instance 标签值为 Prometheus服务器 ， mode 标签值为 idle 的时间序列

```
node_cpu_seconds_total{ instance="Prometheus服务器", mode="idle"}
```

PromQL 还支持用户根据时间序列的标签匹配模式来对时间序列进行过滤，目前主要支持两种匹配模式：完全匹配和正则匹配。总共有以下几种标签匹配运算符：

> = : 选择与提供的字符串完全相同的标签。
>
> != : 选择与提供的字符串不相同的标签。
>
> =~ : 选择正则表达式与提供的字符串（或子字符串）相匹配的标签。
>
> !~ : 选择正则表达式与提供的字符串（或子字符串）不匹配的标签。

例如：选择指标名称为 node_cpu_seconds_total ，mode为 idle 、 user 或 system ， cpu!=0 的时间序列：

```
node_cpu_seconds_total{mode=~"idle|user|system",cpu!="0"}
node_cpu_seconds_total{cpu="0"}
```

> 没有指定标签的标签过滤器会选择该指标名称的所有时间序列。Prometheus 中的所有正则表达式都使用 RE2语法。所有的 PromQL 表达式必须至少包含一个指标名称，或者一个不会匹配到空字符串的标签过滤器。

> 除了使用 \<metric name>{label=value} 的形式以外，我们还可以使用内置的 __name__ 标签来指定监控指标名称。例如：表达式 node_cpu_seconds_total 等效于 {__name__="node_cpu_seconds_total"}

### 区间向量过滤器

区间向量与瞬时向量的工作方式类似，唯一的差异在于在区间向量表达式中我们需要定义时间选择的范围，时间范围通过时间范围选择器 [] 进行定义，以指定应为每个返回的区间向量样本值中提取多长的时间范围。时间范围通过数字来表示，单位可以使用以下其中之一的时间单位：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304270924085.png" alt="image-20230427092423949" style="zoom:80%;" />

例如：选择在过去 5 分钟内指标名称为 node_cpu_seconds_total ， job 标签值为 prometheus 的所有时间序列：

```sh
node_cpu_seconds_total{ instance="Prometheus服务器", mode="idle"}[5m]
```

### 时间位移操作

在瞬时向量表达式或者区间向量表达式中，都是以当前时间为基准：

```sh
node_cpu_seconds_total{} # 瞬时向量表达式，选择当前最新的数据
node_cpu_seconds_total{}[5m] # 区间向量表达式，选择以当前时间为基准，5分钟内的数据
```

而如果我们想查询，5 分钟前的瞬时样本数据，或昨天一天的区间内的样本数据呢? 这个时候我们就可以使用位移操作，位移操作的关键字为 offset 。例如，以下表达式返回相对于当前查询时间过去 5 分钟的 node_cpu_seconds_total 值：

```sh
node_cpu_seconds_total{ instance="Prometheus服务器", mode="idle"} offset 5m
node_cpu_seconds_total{ instance="node1:9100", mode="idle"} offset 5m
```

**注意：** offset 关键字需要紧跟在选择器 {} 后面。以下表达式是正确的：

```sh
sum(node_cpu_seconds_total{ instance="Prometheus服务器", mode="idle"} offset 5m)
# 下面的表达式是不合法的：
sum(node_cpu_seconds_total{ instance="Prometheus服务器", mode="idle"}) offset 5m
```

该操作同样适用于区间向量。以下表达式返回指标 node_cpu_seconds_total 一周前的 5 分钟之内的 cpu空闲率：

```sh
# 最后的1w表示一周
rate(node_cpu_seconds_total{ instance="Prometheus服务器", mode="idle"}[5m] offset 1w)
```

sum是聚合运算符，rate是内置函数，后面会讲

## 操作符

Prometheus 的查询语言支持基本的逻辑运算和算术运算。对于两个瞬时向量, 匹配行为可以被改变。

### 二元运算符

> 在 Prometheus 系统中支持下面的二元算术运算符：\+ 加法、\- 减法、\* 乘法、/ 除法、% 模、^ 幂等。二元运算操作符支持 scalar/scalar(标量/标量) 、 vector/scalar(瞬时向量/标量) 、和vector/vector(瞬时向量/瞬时向量) 之间的操作。在两个标量之间进行数学运算，得到的结果也是标量。
>

```sh
(63+3)*3 ---> scalar 198
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301047628.png" alt="image-20230430104701523" style="zoom:80%;" />

瞬时向量和标量之间进行算数运算时，算术运算符会一次作用与瞬时向量中的每一个样本值，得到一组新的时间序列

```sh
# 例如：我们通过监控指标node_memory_MemTotal_bytes（主机内存总大小）单位为byte,如果换成mb时
node_memory_MemTotal_bytes/(1024*1024)
# 结果
{instance="Prometheus服务器", job="node-exporter"} 3901.07421875
{instance="test服务器", job="node-exporter"} 3901.04296875
```

瞬时向量与瞬时向量之间进行数学运算时，过程会相对复杂一点，运算符会依次找到与左边向量元素匹配（标签完全一致）的右边向量元素进行运算，如果没找到匹配元素，则直接丢弃。同时新的时间序列将不会包含指标名称。

例如，如果我们 node_memory_MemAvailable_bytes （可用内存） 和 node_memory_MemTotal_bytes（总内存） 获取内存可用率%，可以使用如下表达式：

```sh
node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100
# 结果
{instance="Prometheus服务器", job="node-exporter"} 73.19077778055924
{instance="test服务器", job="node-exporter"} 69.0442359665434
# 案例 幂运算
process_open_fds ^ 3
```

### 关系运算符

目前，Prometheus 支持以下关系运算符：

== (相等)

!= (不相等)

\> (大于)

< (小于)

\>= (大于等于)

<= (小于等于)

> 关系运算符被应用于 scalar/scalar（标量/标量） 、 vector/scalar（瞬时向量/标量） ，和vector/vector（瞬时向量/向量） 。默认情况下关系运算符只会根据时间序列中样本的值，对时间序列进行过滤。我们可以通过在运算符后面使用 bool 修饰符来改变关系运算的默认行为。使用 bool 修改符后，关系运算不会对时间序列进行过滤，而是直接依次瞬时向量中的各个样本数据与标量的比较结果 0 或者 1 。

> 在两个标量之间进行关系运算，必须提供 bool 修饰符，得到的结果也是标量，即 0 （ false ）或 1（ true ）。

```sh
2 > bool 1 # 结果为 1
```

> 瞬时向量和标量之间的关系运算，这个运算符会应用到某个当前时刻的每个时序数据上，如果一个时序数据的样本值与这个标量比较的结果是 false ，则这个时序数据被丢弃掉，如果是 true , 则这个时序数据被保留在结果中。如果提供了 bool 修饰符，那么比较结果是 0 的时序数据被丢弃掉，而比较结果是 1 的时序数据被保留。

```sh
node_load1 > 1 # 结果为 true 或 false
node_load1 > bool 1 # 结果为 1 或 0
up == 1
up !=1
```

> 瞬时向量与瞬时向量直接进行关系运算时，同样遵循默认的匹配模式：依次找到与左边向量元素匹配（标签完全一致）的右边向量元素进行相应的操作，如果没找到匹配元素，或者计算结果为 false，则直接丢弃。如果匹配上了，则将左边向量的度量指标和标签的样本数据写入瞬时向量。如果提供了 bool 修饰符，那么比较结果是 0 的时序数据被丢弃掉，而比较结果是 1 的时序数据（只保留左边向量）被保留。

```sh
node_memory_MemAvailable_bytes > bool node_memory_MemTotal_bytes
或
node_memory_MemAvailable_bytes < bool node_memory_MemTotal_bytes
```

### 逻辑运算符

> 使用瞬时向量表达式能够获取到一个包含多个时间序列的集合，我们称为瞬时向量。 通过集合运算，可以在两个瞬时向量与瞬时向量之间进行相应的集合操作。目前，Prometheus 支持以下集合运算符：and、or 、unless (排除)

> **vector1 and vector2** 会产生一个由vector1的元素组成的新的向量。该向量包含vector1中完全匹配vector2中的元素

> **vector1 or vector2** 会产生一个新的向量，该向量包含vector1的所有原始元素（标签集+值）的向量，以及vector2中没有与vector1匹配标签集的所有元素。

> **vector1 unless vector2** 会产生一个由vector1的元素组成的向量，而这些元素在vector2中没有与标签集完全匹配的元素，两个向量中的所有匹配元素都被删除。

and表达式

```sh
node_cpu_seconds_total{mode=~"idle|user|system"} and
node_cpu_seconds_total{mode=~"user|system|iowait"}
```

时钟不同步触发器

```sh
min_over_time(node_timex_sync_status[1m]) == 0 and node_timex_maxerror_seconds >=16
```

or表达式

```sh
node_cpu_seconds_total{mode=~"idle|user|system"} or
node_cpu_seconds_total{mode=~"user|system|iowait"}
```

状态码非200-399触发器

```sh
probe_http_status_code <= 199 OR probe_http_status_code >= 400
```

unless表达式

```sh
node_cpu_seconds_total{mode=~"idle|user|system"} unless
node_cpu_seconds_total{mode=~"user|system|iowait"}
```

### 优先级

在 Prometheus 系统中，二元运算符优先级从高到低的顺序为：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304270912029.png" alt="image-20230427091234898" style="zoom:80%;" />

> 具有相同优先级的运算符是满足结合律的（左结合）。例如， 2 * 3 % 2 等价于 (2 * 3) % 2 。运算符^ 例外， ^ 满足的是右结合，例如， 2 ^ 3 ^ 2 等价于 2 ^ (3 ^ 2) 。

## 向量匹配

在标量和瞬时向量之间使用运算符可以满足很多需求，但是在两个瞬时向量之间使用运算符时，哪些样本应该适用于哪些其他样本？这种瞬时向量的匹配称为向量匹配。Prometheus提供了两种基本的向量匹配模式：one-to-one向量匹配和many-to-one（one-to-many）向量匹配。接下来将介绍在 PromQL 中有两种典型的匹配模式：一对一（one-to-one）,多对一（many-to-one）或一对多（one-to-many）。

###  一对一（one-to-one）

一对一匹配模式会从操作符两边表达式获取的瞬时向量依次比较并找到唯一匹配(标签完全一致)的样本值。默认情况下，使用表达式：

```
vector1 <operator> vector2
```

例如当存在样本：

```
process_open_fds{instance="Prometheus服务器", job="node-exporter"} 9
process_max_fds{instance="Prometheus服务器", job="node-exporter"} 1048576
```

使用 PromQL 案例：

```
process_open_fds{instance="Prometheus服务器", job="node-exporter"} /
process_max_fds{instance="Prometheus服务器", job="node-exporter"}
```

因此结果如下：

```
{instance="Prometheus服务器", job="node-exporter"} 0.00000858306884765625
```

在操作符两边表达式标签不一致的情况下，可以使用 on(label list) 或者 ignoring(label list） 来修改便签的匹配行为。使用 ignoreing 可以在匹配时忽略某些便签。而 on 则用于将匹配行为限定在某些便签之内。

```
<vector expr> <bin-op> ignoring(<label list>) <vector expr>
<vector expr> <bin-op> on(<label list>) <vector expr>
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304270906942.png" alt="image-20230427090646778" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304270907358.png" alt="image-20230427090701209" style="zoom:80%;" />

```
sum by(instance, job)(rate(node_cpu_seconds_total{mode="idle"}[5m]))
sum by(instance)(rate(node_cpu_seconds_total[5m]))
```

使用on表达式：

```
sum by(instance, job)(rate(node_cpu_seconds_total{mode="idle"}[5m])) / on(instance)
sum by(instance)(rate(node_cpu_seconds_total[5m]))
```

结果

```
{instance="Prometheus服务器"} 1.0199580591510582
{instance="test服务器"} 1.0159356093344827
```

### 多对一和一对多

> 多对一和一对多的匹配模式，可以理解为向量元素中的一个样本数据匹配到了多个样本数据标签。在使用该匹配模式时，需要使用group_left或group_right修饰符明确指定哪一个向量具有更高的基数，也就是说左或者右决定了哪边的向量具有较高的子集。此表达格式为：

```sql
<vector expr> <bin-op> ignoring(<label list>) group_left(<label list>) <vector expr>
<vector expr> <bin-op> ignoring(<label list>) group_right(<label list>) <vector expr>
<vector expr> <bin-op> on(<label list>) group_left(<label list>) <vector expr>
<vector expr> <bin-op> on(<label list>) group_right(<label list>) <vector expr>
```

多对一和一对多两种模式一定是出现在操作符两侧表达式返回的向量标签不一致的情况。因此需要使用 ignoring 和 on 修饰符来排除或者限定匹配的标签列表。使用group_left指定左侧操作数组中可以有多个匹配样本，例如

```
sum without(cpu)(rate(node_cpu_seconds_total[5m])) / ignoring(mode) group_left sum
without(mode, cpu)(rate(node_cpu_seconds_total[5m]))
```

结果：

```sh
{instance="Prometheus服务器", job="node-exporter", mode="idle"} 0.9802134676075311
{instance="Prometheus服务器", job="node-exporter", mode="iowait"}0.000035459735470373514
{instance="Prometheus服务器", job="node-exporter", mode="irq"} 0
{instance="Prometheus服务器", job="node-exporter", mode="nice"} 0.000017729867735189905
{instance="Prometheus服务器", job="node-exporter", mode="softirq"} 0.0003368674869685515
{instance="Prometheus服务器", job="node-exporter", mode="steal"} 0
{instance="Prometheus服务器", job="node-exporter", mode="system"} 0.008049359951775699
{instance="Prometheus服务器", job="node-exporter", mode="user"} 0.01134711535051912
{instance="test服务器", job="node-exporter", mode="idle"} 0.9848852662354926
{instance="test服务器", job="node-exporter", mode="iowait"} 0.00001771950031008937
{instance="test服务器", job="node-exporter", mode="irq"} 0
{instance="test服务器", job="node-exporter", mode="nice"} 0
{instance="test服务器", job="node-exporter", mode="softirq"} 0.0007796580136441839
{instance="test服务器", job="node-exporter", mode="steal"} 0
{instance="test服务器", job="node-exporter", mode="system"} 0.00425268007442165
{instance="test服务器", job="node-exporter", mode="user"} 0.010064676176131668
```

左右两边的瞬时向量标签不一致：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304270911847.png" alt="image-20230427091116682" style="zoom:80%;" />





## 内置函数

### 数学函数

> 数学函数对瞬时向量执⾏标准的数学运算，如计算绝对值或取对数。瞬时向量中的每个样本都是独⽴处理的，并且在返回值中删除指标名称。

abs：绝对值

```sh
# abs该函数输⼊,瞬时向量，返回其每个值的绝对值。例如，对于表达式process_open_fds，调试后返回信息为：49
process_open_fds{instance="localhost:9090",job="prometheus"}

#  使⽤函数表达式求绝对值后返回信息为，72
abs(process_open_fds{instance="localhost:9090",job="prometheus"}-119)
```

sqrt：该函数返回瞬时向量中值的平⽅根，例如表达式 sqrt(vector(25)) ，返回结果为5

round：该函数将瞬时向量中的值四舍五⼊到最近的整数。例如表达式 round(vector(7.5)) ，返回结果为：8

### 时间函数

> Prometheus使⽤的是协调世界时（UTC），没有时区的概念。为了使⽤户在使⽤中不⽤⾃⼰实现与⽇期相关的逻辑，Prometheus提供了⼀些时间函数。该函数是最基本的时间函数，它将查询的计算时间以秒为单位返回。

```sh
# 例如，查看进程运⾏了多⻓时间，可以使⽤表达式：
time()-process_start_time_seconds
# 结果
{instance="localhost:9090", job="prometheus"} 3137.62700009346
{instance="node_exporter:9100", job="node-exporter"} 3138.367000102997
```

```sh
# 触发器案例:证书还有30天到期
probe_ssl_earliest_cert_expiry - time() < 86400 * 30
```

### 计算Counter指标增⻓率函数

> 我们知道Counter类型的监控指标其特点是只增不减，在没有发⽣重置（如服务器重启，应⽤重启）的情况下其样本值应该是不断增⼤的。为了能够更直观++的表示样本数据的变化剧烈情况，需要计算样本的增⻓速率。

如下图所示，样本增⻓率反映出了样本变化的剧烈程度：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304262206458.png" alt="image-20230426220610311" style="zoom:80%;" />

通过增⻓率表示样本的变化情况

increase(v range-vector)函数是PromQL中提供的众多内置函数之⼀。其中参数v是⼀个区间向量，

increase函数获取区间向量中的第⼀个后最后⼀个样本并返回其增⻓量。因此，可以通过以下表达式

Counter类型指标的增⻓率：

```sh
increase(node_load1[2m]) / 120
```

> 这⾥通过node_cpu[2m]获取时间序列最近两分钟的所有样本，increase计算出最近两分钟的增⻓量，最后除以时间120秒得到node_cpu样本在最近两分钟的平均增⻓率。这个值也近似于主机节点最近两分钟内的平均CPU使⽤率

> 除了使⽤increase函数以外，PromQL中还直接内置了rate(v range-vector)函数，rate函数可以直接计算区间向量v在时间窗⼝内平均增⻓速率。因此，通过以下表达式可以得到与increase函数相同的结果：

```sh
rate(node_load1[2m])
```

> 需要注意的是使⽤rate或者increase函数去计算样本的平均增⻓速率，容易陷⼊“⻓尾问题”当中，其⽆法反应在时间窗⼝内样本数据的突发变化。 例如，对于主机⽽⾔在2分钟的时间窗⼝内，可能在某⼀个由于访问量或者其它问题导致CPU占⽤100%的情况，但是通过计算在时间窗⼝内的平均增⻓率却⽆法反应出该问题。

> 为了解决该问题，PromQL提供了另外⼀个灵敏度更⾼的函数irate(v range-vector)。irate同样⽤于计算区间向量的计算率，但是其反应出的是瞬时增⻓率。irate函数是通过区间向量中最后两个样本数据来计算区间向量的增⻓速率。这种⽅式可以避免在时间窗⼝范围内的“⻓尾问题”，并且体现出更好的灵敏度，通过irate函数绘制的图标能够更好的反应样本数据的瞬时变化状态。

```
irate(node_load1[2m])
```

> irate函数相⽐于rate函数提供了更⾼的灵敏度，不过当需要分析⻓期趋势或者在告警规则中，irate的这种灵敏度反⽽容易造成⼲扰。因此在⻓期趋势分析或者告警中更推荐使⽤rate函数。

### 预测Gauge指标变化趋势函数

> 在⼀般情况下，系统管理员为了确保业务的持续可⽤运⾏，会针对服务器的资源设置相应的告警阈值。例如，当磁盘空间只剩512MB时向相关⼈员发送告警通知。 这种基于阈值的告警模式对于当资源⽤量是平滑增⻓的情况下是能够有效的⼯作的。 但是如果资源不是平滑变化的呢？ ⽐如有些某些业务增⻓，存储空间的增⻓速率提升了⾼⼏倍。这时，如果基于原有阈值去触发告警，当系统管理员接收到告警以后可能还没来得及去处理问题，系统就已经不可⽤了。 

> 因此阈值通常来说不是固定的，需要定期进⾏调整才能保证该告警阈值能够发挥去作⽤。 那么还有没有更好的⽅法吗？PromQL中内置的predict_linear(v range-vector, t scalar) 函数可以帮助系统管理员更好的处理此类情况，

> predict_linear函数可以预测时间序列v在t秒后的值。它基于简单线性回归的⽅式，对时间窗⼝内的样本数据进⾏统计，从⽽可以对时间序列的变化趋势做出预测。例如，基于1⼩时的样本数据，来预测主机可⽤磁盘空间的是否在24个⼩时候被占满，可以使⽤如下表达式：

```sh
predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs"}[1h], 24 * 3600) < 0
```

node_exporter触发器解释

```sh
(node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint)
predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs"}[1h], 24 * 3600)
< 0 and ON (instance, device, mountpoint) node_filesystem_readonly == 0
```

磁盘可⽤率<10% 并且 基于1⼩时的样本数据，来预测主机可⽤磁盘空间的是否在24个⼩时候被占满 并且 ⽂件系统不等于只读

```
node_filesystem_readonly ：只读⽂件系统
node_filesystem_avail_bytes : 磁盘剩余空间⼤⼩（字节）
node_filesystem_size_bytes : 磁盘总⼤⼩（字节）
```

### 标签操作函数

⼀般来说来说，使⽤PromQL查询到时间序列后，可视化⼯具会根据时间序列的标签来渲染图表。例如通过up指标可以获取到当前所有运⾏的Exporter实例以及其状态：

```sh
up
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301214269.png" alt="image-20230430121423076" style="zoom:80%;" />

这是可视化⼯具渲染图标时可能根据，instance和job的值进⾏渲染，为了能够让客户端的图标更具有可读性，可以通过**label_replace标签为时间序列添加额外的标签**。label_replace的具体参数如下：

```sh
label_replace(v instant-vector, dst_label string, replacement string, src_label string, regex string)
```

该函数会依次对v中的每⼀条时间序列进⾏处理，通过regex匹配src_label的值，并将匹配部分relacement 写⼊到dst_label标签中。如下所示：

```sh
# 新增host标签名
label_replace(up, "host", "$1", "instance", "(.*):.*")
```

函数处理后，时间序列将包含⼀个host标签，host标签的值为Exporter实例的IP地址：

```sh
up{instance="192.168.11.61", job="blackbox_icmp"} 1
up{host="192.168.11.61", instance="192.168.11.61:22", job="blackbox_tcp"} 1
up{host="192.168.11.61", instance="192.168.11.61:9090", job="blackbox_tcp"} 1
up{instance="192.168.11.62", job="blackbox_icmp"} 1
up{host="192.168.11.62", instance="192.168.11.62:8081", job="springboot-demo"} 1
up{host="192.168.11.62", instance="192.168.11.62:9222", job="domain"} 1
up{host="192.168.11.62", instance="192.168.11.62:9256", job="process"} 1
```

除了label_replace以外，Prometheus还提供了label_join函数，该函数可以将时间序列中v多个标签src_label的值，通过separator作为连接符写⼊到⼀个新的标签dst_label中:

```sh
label_join(v instant-vector, dst_label string, separator string, src_label_1
string, src_label_2 string, ...)
```

表达式:

```sh
up{instance="192.168.11.61", job="blackbox_icmp"}
```

使⽤label_join表达式：

```sh
label_join(up{instance="192.168.11.61", job="blackbox_icmp"},"ip",",","job")
label_join(up,"ip",",","job")
```

label_replace和label_join函数提供了对时间序列标签的⾃定义能⼒，从⽽能够更好的于客户端或者可视化⼯具配合。

### 其它内置函数

> 除了上⽂介绍的这些内置函数以外，PromQL还提供了⼤量的其它内置函数。这⾥就不⼀⼀细讲，感兴趣的同学可以通过阅读Prometheus的官⽅⽂档，了解这些函数的使⽤⽅式。[官方文档](https://prometheus.io/docs/prometheus/latest/querying/functions/)

## 聚合操作

Prometheus 还提供了下列内置的聚合操作符，这些操作符作用域瞬时向量。可以将瞬时表达式返回的样本数据进行聚合，形成一个具有较少样本值的新的时间序列。

```sh
sum (求和)
min (最小值)
max (最大值)
avg (平均值)
stddev (标准差)
stdvar (标准差异)
count (计数)
count_values (对 value 进行计数)
bottomk (样本值最小的 k 个元素)
topk (样本值最大的k个元素)
quantile (分布统计)
```

这些操作符被用于聚合所有标签维度，或者通过 without 或者 by 子语句来保留不同的维度。

```sh
<aggr-op>([parameter,] <vector expression>) [without|by (<label list>)]
```

> 其中只有 count_values , quantile , topk , bottomk 支持参数(parameter)。without（排除标签名称）by（保留标签名称）： 类似sql的：goup by

```sh
# 查询系统所有 http 请求的总量
sum(prometheus_http_requests_total)

# 按照 mode 计算主机 CPU 的平均使用时间
avg(node_cpu_seconds_total) by (mode)

# 按照主机查询各个主机的 CPU 使用率
sum(sum(irate(node_cpu_seconds_total{mode!='idle'}[5m])) / sum(irate(node_cpu_seconds_total [5m]))) by (instance) 
```

### sum结果求和

```sh
# 下面两种相同
sum(node_cpu_seconds_total) without (cpu,job,mode)
sum(node_cpu_seconds_total) by (instance)
```

计算prometheus http请求总量，表达式：

```sh
sum(prometheus_http_requests_total)
```

### **max** 最大值

```
max(node_cpu_seconds_total) by (mode)
```

### avg 平均值

```sh
avg(node_cpu_seconds_total) by (mode)
# cpu负载> 80%触发器
100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[2m])) * 100) > 80
```

### count（统计数量)

```sh
count(prometheus_http_requests_total)
```

### bottomk （统计最小的几个值）

```
bottomk(3, sum(node_cpu_seconds_total) by (mode))
```

### topk （统计最大的几个值)

类似sql：ORDER BY vaule DESC limit 3

```sh
topk(3, sum(node_cpu_seconds_total) by (mode))
```

### 基于时间聚合

> 前面我们已经学习了如何使用 sum() 、 avg() 和相关的聚合运算符从标签维度进行聚合，这些运算符在一个时间内对多个序列进行聚合，但是有时候我们可能想在每个序列中按时间进行聚合，例如，使尖锐的曲线更平滑，或深入了解一个序列在一段时间内的最大值。为了基于时间来计算这些聚合，PromQL 提供了一些与标签聚合运算符类似的函数，但是在这些函数名前面附加了 _over_time() ：

> avg_over_time(range-vector) ：区间向量内每个指标的平均值。
>
> min_over_time(range-vector) ：区间向量内每个指标的最小值。
>
> max_over_time(range-vector) ：区间向量内每个指标的最大值。
>
> sum_over_time(range-vector) ：区间向量内每个指标的求和。
>
> count_over_time(range-vector) ：区间向量内每个指标的样本数据个数。
>
> quantile_over_time(scalar, range-vector) ：区间向量内每个指标的样本数据值分位数。
>
> stddev_over_time(range-vector) ：区间向量内每个指标的总体标准差。
>
> stdvar_over_time(range-vector) ：区间向量内每个指标的总体标准方差。

```sh
# max_over_time
# MySQL运行的线程过多触发器，1分钟最大的值
max_over_time(mysql_global_status_threads_running[1m]) > 20

# avg_over_time
# HTTP请求慢告警触发器，1分钟平均的值
avg_over_time(probe_duration_seconds[1m]) > 1

# min_over_time
# 时钟不同步告警触发器，1分钟最小的值
min_over_time(node_timex_sync_status[1m]) == 0
```



# Grafana

> Grafana 技术应用于海量指标数据的分析和展示场景，它是一个跨平台的开源度量分析和可视化工具，作为云原生可观测性的统一展示解决方案，其主要特性包括灵活且易用性强的客户端图表，丰富的仪表盘插件，具备实时查询海量指标数据并以热图、折线图、图表等多种方式进行展示的能力。这其中包括支持指定指标、图表类型、时间范围以及数据聚合方式的自定义配置以满足各种具体监控场景的需要。包括 Graphite、InfluxDB、OpenTSDB、Prometheus 和 Elasticsearch 等不同时序的数据源接入，并在同一面板展示不同数据源，将来自不同数据源，但同一业务的数据集中展示。通过 Grafana，任何人都可以创建和共享动态仪表盘，以促进协作和透明度，高效协同数据分析、故障排除。

> Grafana官方文档：https://grafana.com/docs/grafana/latest/getting-started/getting-started-prometheus/
>
> node-exporter的使用：https://prometheus.io/docs/guides/node-exporter/
>
> 访问：http://192.168.22.130:3000

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209091259810.png" alt="image-20220909125958707" style="zoom:80%;" />

## 面板

### 面板概述

> ⾯板（Panel）是 Grafana 中基本可视化构建块，每个⾯板都有⼀个特定于⾯板中选择数据源的查询编辑器，每个⾯板都有各种各样的样式和格式选项，⾯板可以在仪表板上拖放和重新排列，它们也可以调整⼤⼩，所以要在 Grafana 上创建可视化的图表，⾯板是我们必须要掌握的知识点。

> Panel 是 Grafana 中最基本的可视化单元，每⼀种类型的⾯板都提供了相应的查询编辑器(Query Editor)，让⽤户可以从不同的数据源（如 Prometheus）中查询出相应的监控数据，并且以可视化的⽅式展现，Grafana 中所有的⾯板均以插件的形式进⾏使⽤。Grafana 提供了各种可视化来⽀持不同的⽤例

> ⽬前内置⽀持的⾯板包括：Time series（时间序列）是默认的也是主要的图形可视化⾯板、State timeline（状态时间表）状态随时间变化 、Status history（状态历史记录）、Bar chart（条形图）、Histogram（直⽅图）、Heatmap（热⼒图）、Pie chart（饼状图）、Stat（统计数据）、Gauge、Bar gauge、Table（表格）、Logs（⽇志）、Node Graph（节点图）、Dashboard list（仪表板列表）、 Alert list（报警列表）、Text panel（⽂本⾯板，⽀持 markdown 和 html）、News Panel（新闻⾯板，可以显示 RSS 摘要）等

> 除此之外，我们还可以通过官⽹的⾯板插件⻚⾯https://grafana.com/grafana/plugins/?type=panel 获取安装其他⾯板进⾏使⽤。https://grafana.com/grafana/dashboards/

### 常见面板⭐

#### 图表

对于基于时间的折线图、⾯积图和条形图，我们建议使⽤默认的 Time series 时间序列进⾏可视化。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261600138.png" alt="image-20230426160027056" style="zoom:80%;" />

#### 条形图

使⽤barchart⾯板进⾏可视化

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261600749.png" alt="image-20230426160048667" style="zoom:80%;" />

#### 数据统计

使⽤ Stat ⾯板进⾏可视化

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261601314.png" alt="image-20230426160120219" style="zoom:80%;" />

#### 仪表盘

如下所示的标准径 Gauge ⾯板。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261611047.png" alt="image-20230426161130958" style="zoom:80%;" />

#### 表格

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261611084.png" alt="image-20230426161150994" style="zoom:80%;" />

#### 饼状图

Grafana 现在⽀持 Pie Chart 饼状图⾯板可视化。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261612396.png" alt="image-20230426161208304" style="zoom:80%;" />

#### 热⼒图

要显示值分布，请使⽤ Heatmap 热⼒图⾯板可视化。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261612532.png" alt="image-20230426161235434" style="zoom:80%;" />

#### 地图

使⽤Goemap⾯板

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261612999.png" alt="image-20230426161253899" style="zoom:80%;" />



## 组成部分

Grafana 主要包括以下几个部分

### 数据源

对于 Grafana 而言，Prometheus 这类为其提供数据的对象均称为数据源（Data Source）。目前，Grafana 官方提供了对 Graphite、InfluxDB、OpenTSDB、Prometheus、Elasticsearch,、CloudWatch 的支持。对于 Grafana 管理员而言，只需要将这些对象以数据源的形式添加到 Grafana 中，Grafana 便可以轻松实现对这些数据的可视化工作。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209091300267.png" alt="image-20220909130029197" style="zoom:67%;" />

### 仪表盘

通过数据源定义好可视化的数据来源之后，可以通过数据看板来组织和管理数据可视化图表。在数据看板中最基本的可视化单元为一个 Panel（面板）。Panel 通过如趋势图，热力图的形式展示可视化数据。并且在数据看板中每个 Panel 是一个完全独立的部分。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209091303098.png" alt="image-20220909130307032" style="zoom:80%;" />

通过 Panel 的 Query Editor（查询编辑器）我们可以为每一个 Panel 自己查询的数据源以及数据查询方式，以 Prometheus 作为数据源举例，那在 Query Editor 中，实际使用的是 PromQL，而 Panel 则会负责从特定的 Prometheus 中查询出相应数据并可视化。由于每个 Panel 完全独立，因此在一个数据看板中，往往可能会包含来自多个数据源的数据。Grafana 通过插件形式提供了多种 Panel 实现如：Graph Panel、Heatmap Panel、SingleStat Panel、Table Panel 等。用户还可通过插件安装更多类型 Panel 面板。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/qdzZBE73hWtgNhRxBcSgdHUbibZzaicZx9aHHhOKY4FtoVxbhYhs3PROo46qH9weO6F9oSQmPN6kIeBhAjzXG0kw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

### 组织管理

作为一个可视化工具，Grafana 除了提供灵活的可视化定制能力以外，还提供面向企业的组织级管理能力。在 Grafana 中，数据看板是属于一个组织。例如企业创建多个组织，用户可以属于一个或多个不同组织。并且在不同组织下，为用户赋予不同的权限，根据企业组织架构定义整个管理模型。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209091303657.png" alt="image-20220909130332595" style="zoom:80%;" />

看到这里，大抵会觉得 Grafana 开源版本简直是最佳选择，但在平台搭建过程中，运维人依旧会遇到很多开源通病

- 搭建前期，购买机器、配置网络、构建环境、安装部署、准备域名和 IP 地址等前期繁琐的准备工作；

- 使用过程中，使用了非常多云服务之后，数据接入困难，不知如何下手；

- 由于 SLA 无法保障，在关键时刻监控平台服务无法使用；

- 想要连接专有网络 VPC 内各自建数据源，并通过邮件、短信等渠道进行告警触达，需要自行详细配置。

### 工作原理

上面说到，Grafana 是一个仪表盘，而仪表盘必然是用来显示数据的。

Grafana 本身并不负责数据层，它只提供了通用的接口，让底层的数据库可以把数据给它。而我们起的另一个服务，叫 Prometheus （中文名普罗米修斯数据库）则是负责存储和查询数据的。

也就是说，Grafana 每次要展现一个仪表盘的时候，会向 Prometheus 发送一个查询请求。

那么配置里的另一个服务 `Prometheus-exporter` 又是什么呢？

这个就是你真正监测的数据来源了，`Prometheus-exporter` 这个服务，会查询你的本地电脑的信息，比如内存还有多少、CPU 负载之类，然后将数据导出至普罗米修斯数据库。

在真实世界中，你的目的是监控你自己的服务，比如你的 Web 服务器，你的数据库之类。

那么你就需要在你自己的服务器中把数据发送给普罗米修斯数据库。当然，你完全可以把数据发送给 MySQL (Grafana 也支持)，但普罗米修斯几乎是标配的时序数据库，强烈建议你用。

用来说明它们之间的关系：

![图片](https://mmbiz.qpic.cn/mmbiz_png/qFG6mghhA4bczBT86snY2mNdj6vHrUCXudPfEriaO4RzpHXaFxrOEG6DhfaB1iaVBamqzwibECmF18PjHq9BTcKFA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

这里，最左边的 Docker 服务会将服务的数据发送给中间的普罗米修斯（对应上文的 `Prometheus-exporter`），而最右边的 Grafana 会查询中间的普罗米修斯，来展示仪表盘。

## 添加数据源

点击配置，点击 Data Sources：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304201558457.png" alt="image-20230420155857337" style="zoom:80%;" />

点击添加按钮：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304201559463.png" alt="image-20230420155925378" style="zoom:80%;" />

找到 Prometheus，点击 Select

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304201559703.png" alt="image-20230420155951618" style="zoom:80%;" />

配置 Prometheus Server 地址：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304201601247.png" alt="image-20230420160100132" style="zoom:80%;" />

点击下方的 Save&Test：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304201601401.png" alt="image-20230420160132315" style="zoom:80%;" />

出现绿色的提示框，表示与 Prometheus 正常联通：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304201601543.png" alt="image-20230420160147459" style="zoom:67%;" />

点击 Back 返回即可，可以看到 Data Sources 页面，出现了添加的 Prometheus:

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304201602307.png" alt="image-20230420160203226" style="zoom:80%;" />

## 创建仪表盘⭐

> ⾯板是属于某⼀个 Dashboard 的，所以我们需要先创建⼀个 Dashboard，在侧边栏点击 + 切换到Dashboard 下⾯开始创建 Dashboard：

### 仪表盘配置⭐

#### 添加CPU面板

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261515276.png" alt="image-20230426151514180" style="zoom:80%;" />

⽐如我们现在就要来查询节点的 CPU 使⽤率，前⾯在 node_exporter 章节中已经学习了该监控数据的查询语句为 

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292101732.png" alt="image-20230429210119634" style="zoom:80%;" />

```sh
(1 - sum(rate(node_cpu_seconds_total{mode="idle"}[5m])) by (instance) / sum(rate(node_cpu_seconds_total[5m])) by (instance) ) * 100 
```

只需要将该语句填充到查询的 PromQL 语句中即可在上⾯显示出监控的结果

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261516273.png" alt="image-20230426151607174" style="zoom:80%;" />

点击右上⻆的 Apply 按钮即可创建成功⼀个 Panel ⾯板。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261516565.png" alt="image-20230426151633467" style="zoom:80%;" />

#### 添加内存面板

⽤同样的⽅式我们可以创建⼀个⽤于查询节点内存使⽤率的⾯板：

![image-20230429210327091](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292103232.png)

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292104350.png" alt="image-20230429210400163" style="zoom:80%;" />

```sh
(1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)*100
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261517048.png" alt="image-20230426151719947" style="zoom:80%;" />

#### 排列位置

创建完成后的⾯板我们也可以拖动他们的排列位置：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261517343.png" alt="image-20230426151737248" style="zoom:80%;" />

如果还想重新编辑⾯板，可以点击标题，在弹出来的下拉框中选择 Edit 编辑即可

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261517843.png" alt="image-20230426151755741" style="zoom:80%;" />

### 下拉框配置

> 现在我们在⼀个 Dashboard 中添加了两个 Panel，我们可以很明显看到会直接将所有的节点信息展示在同⼀个⾯板中，但是如果有⾮常多的节点的话数据量就⾮常⼤了，这种情况下我们最好的⽅式是将节点当成参数，可以让⽤户⾃⼰去选择要查看哪⼀个节点的监控信息，要实现这个功能，我们就需要去添加⼀个以节点为参数的变量来去查询监控数据。就是实现如下下拉框

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292111613.png" alt="image-20230429211103542" style="zoom:80%;" />

点击 Dashboard ⻚⾯右上⽅的 Dashboard settings 按钮，进⼊配置⻚⾯：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261518531.png" alt="image-20230426151842442" style="zoom:80%;" />

在该 Settings ⻚⾯可以来对整个 Dashboard 进⾏配置，⽐如名称、标签、变量等：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261519421.png" alt="image-20230426151905323" style="zoom:80%;" />

这⾥我们点击左边的 Variables 添加⼀个变量，变量⽀持更具交互性和动态性的仪表板，可以在它们的位置使⽤变量，⽽不是在指标查询中硬编码，变量显示为 Dashboard 顶部的下拉列表，这些下拉列表可以轻松更改仪表板中显示数据

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261519258.png" alt="image-20230426151937158" style="zoom:80%;" />

为了能够选择节点数据，这⾥我们定义了⼀个名为 instance 的变量名，在添加变量的⻚⾯中主要包括如下⼀些属性：

> Name ：变量名，在仪表盘中调⽤使⽤ $变量名 的⽅式
>
> Type ：变量类型，变量类型有多种，其中 query 表示这个变量是⼀个查询语句
>
> Hide ：为空是表现为下拉框，选择 label 表示不显示下拉框的名字，选择 variable 表示隐藏该变量，该变量不会在 Dashboard 上⽅显示出来，默认选择为空
>
> Data source ：查询语句的数据源Refresh ：何时去更新变量的值，变量的值是通过查询数据源获取到的，但是数据源本身也会发⽣变化，所以要时不时的去更新变量的值，这样数据源的改变才会在变量对应的下拉框中显示出来。
>
> Refresh 有两个值可以选择： On Dashboard Load （在 Dashboard 加载时更新）、 On Time Range
>
> Change （在时间范围变更的时候更新）
>
> Query ：查询表达式，不同的数据源查询表达式都不同
>
> Regex ：正则表达式，⽤来对抓取到的数据进⾏过滤，默认不过滤
>
> Sort ：排序，对下拉框中的变量值做排序，默认是 disable，表示查询结果是怎样下拉框就怎样显示
>
> Multi-value ：启⽤这个功能，变量的值就可以选择多个，具体表现在变量对应的下拉框中可以选多个值的组合
>
> Include All option ：启⽤这个功能，变量下拉框中就多了⼀个全选 all 的选项

我们还可以使⽤⼀个 label_values() 的函数来直接获取查询结果中的某个 label 标签的值：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261521531.png" alt="image-20230426152111431" style="zoom:80%;" />

```
label_values(up{job="node-exporter"},instance)
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261521321.png" alt="image-20230426152137215" style="zoom:67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261521030.png" alt="image-20230426152149918" style="zoom:80%;" />

回到 Dashboard ⻚⾯就可以看到多了⼀个 选择节点 的下拉框：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261522487.png" alt="image-20230426152208358" style="zoom:80%;" />

但是这个时候的⾯板并不会随着我们下拉框的选择⽽变化，我们需要将 instance 这个变量传⼊查询语句中，⽐如重新修改 CPU使⽤率 的查询语句

```sh
(1 - sum(rate(node_cpu_seconds_total{mode="idle",instance=~"$instance"}[5m])) by (instance) /
sum(rate(node_cpu_seconds_total{instance=~"$instance"}[5m])) by (instance) )* 100
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261523908.png" alt="image-20230426152302798" style="zoom:80%;" />

以同样的⽅式修改内存使⽤率

```sh
(1 - node_memory_MemAvailable_bytes{instance=~"$instance"} / node_memory_MemTotal_bytes{instance=~"$instance" } )* 100
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261523297.png" alt="image-20230426152355206" style="zoom:80%;" />

回到 Dashboard ⻚⾯就可以根据我们的下拉框来选择需要监控的节点数据了，定义参数的时候如果选择了可以选择所有，同样可以查看所有节点的数据

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261524677.png" alt="image-20230426152416586" style="zoom:80%;" />

我们也可以勾选多选框

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261524478.png" alt="image-20230426152455374" style="zoom:67%;" />

可以我们就可以勾选多个

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261525719.png" alt="image-20230426152510629" style="zoom:80%;" />

多个查询

编辑 CPU 使⽤率这个⾯板，在⾯板编辑器下⽅的 Query 区域点击 + Query 按钮新增⼀个查询：

```sh
(sum(rate(node_cpu_seconds_total{mode="user",instance=~"$instance"}[5m])) by
(instance) / sum(rate(node_cpu_seconds_total{instance=~"$instance"}[5m])) by
(instance) ) * 100
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261525263.png" alt="image-20230426152547160" style="zoom:80%;" />

在添加idle的使⽤率的表达式

```
(sum(rate(node_cpu_seconds_total{mode="idle",instance=~"$instance"}[5m])) by
(instance) / sum(rate(node_cpu_seconds_total{instance=~"$instance"}[5m])) by
(instance) ) * 100
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261526946.png" alt="image-20230426152611844" style="zoom:80%;" />

依次在添加iowait和system和其他的使⽤率

```sh
(sum(rate(node_cpu_seconds_total{mode="iowait",instance=~"$instance"}[5m]))
by (instance) / sum(rate(node_cpu_seconds_total{instance=~"$instance"}[5m]))
by (instance) ) * 100

(sum(rate(node_cpu_seconds_total{mode="system",instance=~"$instance"}[5m]))
by (instance) / sum(rate(node_cpu_seconds_total{instance=~"$instance"}[5m]))
by (instance) ) * 100

#其他cpu使⽤
(sum(rate(node_cpu_seconds_total{mode!~"system|user|iowait|idle"}[5m])) by
(instance) / sum(rate(node_cpu_seconds_total{instance=~"$instance"}[5m])) by
(instance) ) * 100
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261527494.png" alt="image-20230426152749327" style="zoom:80%;" />

### 图例配置

> 上⾯转换完成后，可以看到 Legend 部分展示的图例较多，我们可以将 Legend 的模式修改为 Table，此外我们还可以通过 Legend values 来选择⼀些其他的信息进⾏展示，⽐如最⼤值、最⼩值、平均值等等：
>

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261528774.png" alt="image-20230426152816660" style="zoom:80%;" />

### 其他选项

#### 单位

> 由于我们这⾥计算的都是百分⽐，所以可以将单位设置为 % ，位于右侧的 Standard options 下⽅的Unit 中选择 Misc -> Percent(0-100) 即可：
>

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261528928.png" alt="image-20230426152841818" style="zoom:80%;" />

#### 图例样式

此外还可以配置图例的最⼩值、最⼤值、保留⼩数的位数、图形颜⾊配置等等：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261530154.png" alt="image-20230426153014032" style="zoom:67%;" />

### 时间间隔⭐

> 前⾯我们在查询监控数据的时候都是将区间向量的范围固定成了 1m 或者 5m ，这样固定后显然不是⾮常灵活，所以我们可以再添加⼀个时间间隔的参数来灵活选择。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292125926.png" alt="image-20230429212510839" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261530580.png" alt="image-20230426153037483" style="zoom:80%;" />

> 这⾥我们新增了⼀个名为 interval 的参数，不过需要注意该参数的类型为 Interval ，然后我们配置该参数可选的值包括 1m,5m,10m,30m ，添加后在 Dashboard ⻚⾯上就会多⼀个时间间隔的下拉框。然后记得将查询语句中的相关时间间隔替换成 $interval 参数：
>

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261530626.png" alt="image-20230426153058525" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261531648.png" alt="image-20230426153112549" style="zoom:80%;" />

### 覆盖配置⭐

⽤同样的⽅式可以对内存监控图表进⾏修改，⽐如在⼀个图表中展示总内存、已⽤内存、可⽤内存、内存使⽤率等信息

```sh
# 内存使用率
(1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)*100
# 新增总内存的查询
node_memory_MemTotal_bytes{instance=~"$instance"} 
# 已⽤内存的查询
node_memory_MemTotal_bytes{instance=~"$instance"}-node_memory_MemAvailable_bytes{instance=~"$instance"} 
# 以及可⽤内存的查询
node_memory_MemAvailable_bytes{instance=~"$instance"} 
```

依次添加查询

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292143217.png" alt="image-20230429214318116" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292135432.png" alt="image-20230429213551331" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292136569.png" alt="image-20230429213604481" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292136563.png" alt="image-20230429213655467" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292137399.png" alt="image-20230429213736307" style="zoom:80%;" />

如下图所示：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261534969.png" alt="image-20230426153428869" style="zoom:80%;" />

我们可以先将整个⾯板的单位调整为 bytes(IEC) ，该形式的单位会⾃动在 GiB、MiB、KiB 之间进⾏换算

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261534294.png" alt="image-20230426153449188" style="zoom:80%;" />

但是明显使⽤率的单位是不正确的，这个时候就需要我们针对该查询进⾏覆盖配置，点击编辑器右侧Overrides 选项卡进⾏覆盖配置：点击选项卡中的 + Add field override 按钮可以对属性进⾏覆盖操作

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261535850.png" alt="image-20230426153510752" style="zoom:80%;" />

可选的⽅式有很多，⽐如可以设置指定具体属性的值，也可以根据正则表达式来匹配属性的名进⾏配置，还可以根据指定的类型以及指定的 query 查询结果进⾏覆盖，显然我们这⾥选择最后⼀项 Fieldsreturned by query

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261537407.png" alt="image-20230426153758290" style="zoom:80%;" />

直接选择查询使⽤率的 A 这条语句进⾏覆盖

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261540201.png" alt="image-20230426154006094" style="zoom:80%;" />

先加上百分⽐的单位

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261540250.png" alt="image-20230426154028101" style="zoom:80%;" />

选择Misc--Percent（0-100）

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261540421.png" alt="image-20230426154042324" style="zoom:80%;" />

同样还可以把百分⽐显示在图形右侧

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261540375.png" alt="image-20230426154058276" style="zoom:80%;" />

这样我们就在同⼀个图形当中显示出了不同单位的两种图形

## 表格面板

> 接下来我们以统计服务器资源为例，对表格⾯板的使⽤进⾏说明。⽐如通过表格展示Linux服务器总内存、总 CPU 数、带宽等信息，接下来分别添加如下查询：
>

```sh
# 总内存
node_memory_MemTotal_bytes{instance=~"$instance"}

# CPU 核数
count(node_cpu_seconds_total{instance=~"$instance", mode='system'}) by(instance)

# 连接数
node_netstat_Tcp_CurrEstab{instance=~"$instance"}

# 下⾏带宽，注意$interval是前面定义的时间变量，如果没定义，就写5m即可
max(rate(node_network_receive_bytes_total{instance=~"$instance"}[$interval])*8) by (instance)

# 上⾏带宽 ，注意$interval是前面定义的时间变量，如果没定义，就写5m即可
max(rate(node_network_transmit_bytes_total{instance=~"$instance"}[$interval])*8) by (instance)
```

不断增加查询即可

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292148554.png" alt="image-20230429214833446" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292148599.png" alt="image-20230429214859480" style="zoom:80%;" />

后面也一样

如还有其他需要展示的也可以直接添加新的查询即可,在 Dashboard 中添加添加⼀个空的 Panel ⾯板，进⼊⾯板编辑器后在右侧上⽅选择 Table ⾯板：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261548247.png" alt="image-20230426154829154" style="zoom:80%;" />

添加完成后如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261550421.png" alt="image-20230426155011317" style="zoom:80%;" />

可以看到数据是以时间序列展示的，我们需要修改下，注意，每一个都要修改

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261550680.png" alt="image-20230426155025596" style="zoom:80%;" />

当每个query都修改后，就变成了如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261550855.png" alt="image-20230426155042756" style="zoom:80%;" />

### 表格转换

现在我们将所有需要展示的信息都通过 Table 形式展示出来了，但是现在有⼀个很⼤的问题，就是需要

对每⼀个查询切换显示：每⼀个query显示⼀个表格（因为有5个query，所以有5个表格可以选择）

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261551206.png" alt="image-20230426155103108" style="zoom:80%;" />

这显然是⾮常不友好的显示⽅式，我们需要将这些表格内容合并成⼀个表格进⾏展示，这个时候就需要⽤到 Grafana 的 Transform 转换功能了，在 Transform 选项卡中选择 Merge 选项

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261552286.png" alt="image-20230426155242187" style="zoom:80%;" />

Merge 转换器可以合并多个序列或者多个表格为⼀个表格，其中可合并的值将合并到同⼀⾏中，⽤于显示在表格中可视化的多个序列、表格或两者的组合。当我们选择了 Merge 转换器过后就会将上⾯的多个查询结果合并成⼀个表格。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261553642.png" alt="image-20230426155304544" style="zoom:80%;" />

但其实合并后的表格数据有⼀些地⽅没有显示，这是因为我们查询的结果实际上是包含 __name__ 这个标签的，在合并的时候会造成数据丢失，我们可以将所有的查询语句后⾯添加上⼀个 - 0 来去掉这个标签，这样合并的时候就不会丢失数据了。⽐如查询主机信息的语句变成 node_uname_info{job="node-exporter"} - 0 ，其他的语句也都加上 - 0 这个操作。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261553934.png" alt="image-20230426155336842" style="zoom:80%;" />

全部加上-0后，PromQL表达式变成如下：

```sh
# 总内存
node_memory_MemTotal_bytes{instance=~"$instance"} - 0

# CPU 核数
count(node_cpu_seconds_total{instance=~"$instance", mode='system'}) by (instance) - 0

# 连接数
node_netstat_Tcp_CurrEstab{instance=~"$instance"} - 0

# 下载带宽 
max(rate(node_network_receive_bytes_total{instance=~"$instance"}[$interval])*8) by (instance) - 0

# 上传带宽 
max(rate(node_network_transmit_bytes_total{instance=~"$instance"}[$interval])*8) by(instance) - 0
```

数据虽然正确了，但是表头却看不出来是表达的什么意义，有的列还是不需要的，这个时候同样也要⽤到Transform 转换器了，这⾥我们需要⽤到的是 Organize fields 转换器，该转换器允许⽤户重新排序、隐藏或重命名字段或者列。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261554272.png" alt="image-20230426155423173" style="zoom:80%;" />

这⾥我们将不需要的⼀些列隐藏掉了，将表头进⾏了重命名。

### 属性覆盖

上⾯我们将查询的数据结果⽤⼀个表格展示出来了，但是现在我们的数据都是直接的⼀个结果，我们需要进⾏转换加上我们的单位。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261554354.png" alt="image-20230426155448268" style="zoom:80%;" />

⽐如对于总内存这⼀列，我们需要添加覆盖，设置⼀个 bytes 类型的单位，然后会根据我们的结果进⾏⾃动转换：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261555554.png" alt="image-20230426155526452" style="zoom:80%;" />

同样对下⾏和上⾏宽带这两列的数据结果进⾏覆盖，添加 bytes/sec(IEC) 类型的单位：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261555160.png" alt="image-20230426155548056" style="zoom:80%;" />

### 样式配置

此外在定制某列数据的显示效果的时候我们还可以为其配置背景颜⾊，只需要设置 Cell Options>Cell Type ，该属性可以配置⽂本颜⾊、背景等⽅式：如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261556327.png" alt="image-20230426155613219" style="zoom:80%;" />

修改背景颜⾊为绿⾊：

Shandard options > Color scheme 如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261556902.png" alt="image-20230426155648786" style="zoom:80%;" />

## 仪表盘和统计⾯板

### 仪表盘

> 如果想展示与最⼤值和最⼩值相关的数据，我们可以选择使⽤仪表盘⾯板，⽐如我们⽤⼀个仪表盘⾯板来展示内存使⽤率。

#### 标准仪表盘

在 Dashboard ⻚⾯上点击创建⼀个新的空⾯板，在⾯边编辑器右上⽅选择 Gauge 类型的⾯板：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261120999.png" alt="image-20230426112005911" style="zoom:80%;" />

然后添加如下所示的查询语句，获取内存使⽤率：

```sh
(1 -node_memory_MemAvailable_bytes{instance=~"$instance"}/node_memory_MemTotal_
bytes{instance=~"$instance"})*100
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261121092.png" alt="image-20230426112110019" style="zoom:80%;" />

#### 条形仪表盘

除了上⾯标准的仪表盘⾯板之外，还有条形仪表盘，该⾯板可以显示⼀个或多个条形仪表，同样我们可以⽤来展示 CPU 使⽤率、内存使⽤率等。⽐如这⾥我们⽤条形仪表盘来进⾏展示。点击添加⼀个新的空⾯板，在⾯板编辑器右侧选择 Bar gauge ：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261406732.png" alt="image-20230426140650650" style="zoom:80%;" />

```sh
# cpu使⽤率promql表达式
(1 - sum(rate(node_cpu_seconds_total{mode="idle",instance=~"$instance"}[5m])) by(instance) / sum(rate(node_cpu_seconds_total{instance=~"$instance"}[5m])) by (instance)) * 100
# 内存使⽤率promql表达式
(1 -node_memory_MemAvailable_bytes{instance=~"$instance"}/node_memory_MemTotal_b
ytes{instance=~"$instance"} )*100
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261407303.png" alt="image-20230426140737732" style="zoom:80%;" />

### 统计⾯板

统计⾯板可以⽤于显示⼀个⼤的统计值和⼀个可选的背景颜⾊，我们可以使⽤阈值来控制背景或颜⾊值，

效果如下所示：下⾯我们使⽤该⾯板来统计⼏个监控数据，⽐如节点运⾏时间、CPU 核数、总内存⼤⼩等等。

#### ⽂本模式

⾸先创建⼀个空的⾯板，选择使⽤ Stat ⾯板：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261408417.png" alt="image-20230426140840333" style="zoom:80%;" />

我们以显示系统运⾏时间为列：promql表达式为

```sh
avg(time() - node_boot_time_seconds{instance=~"$instance"})
```

我们把设置单位为 seconds (s) ，并且在 Thresholds 根据设置的值展示不同颜⾊，⽐如这⾥我们设置阈值在200 和 300 秒的时候显示不同的颜⾊，因为运⾏时间超过了300s，所以当前显示指定的颜⾊。如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261409160.png" alt="image-20230426140936089" style="zoom:80%;" />

以同样的⽅式，我们在添加总内存的⼤⼩：promql表达式：

```sh
node_memory_MemTotal_bytes{instance=~"$instance"}
```

完成后如下图：我们设置单位为 bytes(IEC) ，并且在 Thresholds 根据设置不同阀值展示不同颜⾊。因为内存总⼤⼩

当前的值超过了3，所以显示深蓝⾊

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261410075.png" alt="image-20230426141021996" style="zoom:80%;" />

#### 背景模式

可以在stat styles⾥⾯设置背景，如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261412089.png" alt="image-20230426141212005" style="zoom:80%;" />

## 仪表盘市场⭐

> Grafana的仪表盘市场下载一个Dashboard，市场地址：https://grafana.com/grafana/dashboards

### 搜索仪表盘

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304192034492.png" alt="image-20230419203425383" style="zoom:80%;" />

> 例如，搜索linux相关图表

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304192048764.png" alt="image-20230419204839647" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304192049421.png" alt="image-20230419204908345" style="zoom:80%;" />

### 导入仪表盘

> 在 Grafana 里，仪表盘的配置可以通过图形化界面进行，但配置好的仪表盘是以 JSON 存储的。这也就是说，如果你把你的 JSON 数据分享出去，别人导入就可以直接导入同样的仪表盘（前提是你们的监测数据一样）。

Grafana 的仪表盘市场：https://grafana.com/grafana/dashboards

比如说针对以下一些服务的标准仪表盘就可以在这里找到

那么，这里我们就用一个标准的仪表盘：https://grafana.com/grafana/dashboards/1860

点击 Grafana 界面左侧 ”+”号，选择 import：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304201607059.png" alt="image-20230420160727901" style="zoom: 67%;" />

上传 JSON 文件：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304201607690.png" alt="image-20230420160747589" style="zoom:80%;" />

配置模板信息：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304201608588.png" alt="image-20230420160804460" style="zoom:80%;" />

导入完，在首页即可看见添加的仪表盘，点击进去查看：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304251107870.png" alt="image-20230425110719709" style="zoom:80%;" />



## 用户和角色

### 新增新⽤户

Grafana 新增新⽤户分为两种⽅式：

> 1，通过管理员账户邀请新⽤户，新⽤户通过邮箱或者浏览器修改其账户信息（需要提前开启，邮件功能）。
>
> 2，通过管理员账户⼿动创建账户。通过管理员账户⼿动创建账户，选择左边的防护墙图标，点击Users

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261542960.png" alt="image-20230426154228859" style="zoom:80%;" />

出来的Server admin⽤户管理界⾯，添加右边的“new user”，创建新⽤户

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261542037.png" alt="image-20230426154245925" style="zoom:80%;" />

填写新⽤户的名字，邮件，以及密码，如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261543003.png" alt="image-20230426154302917" style="zoom:80%;" />

指定⽤户权限

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261543102.png" alt="image-20230426154329998" style="zoom:80%;" />

完成后可以在⽤户管理中查看到刚刚创建的新⽤户

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261543861.png" alt="image-20230426154343766" style="zoom:80%;" />

### ⻆⾊

Grafana需要针对不同⽤户开放不同的 dashboard 权限，根据不同⻆⾊进⾏权限管理。Grafana ⻆⾊分为以下三类：

> **Admin Role（管理员⻆⾊）**：**可以做⼀切操作的组织。例如：添加和编辑数据源。添加和编辑组织⽤户和团队。配置App插件并设置组织设置**。

> **Editor Role（编辑⻆⾊）**：**可以创建和修改仪表板和警报规则。可以在特定⽂件夹和仪表板上禁⽤此功能。⽆法创建或编辑数据源，也⽆法邀请新⽤户**。

> **Viewer Role（查看者⻆⾊）**：**查看任何仪表板。可以在特定⽂件夹和仪表板上禁⽤此功能。⽆法创建或编辑仪表板或数据源**。

## 告警功能

> Grafana 除了支持丰富的数据源和图表功能外，还支持告警功能，该功能也使得 Grafana 从一个数据可视化工具成为了一个真正的监控利器。Grafana 可以通过 Alerting 模块的配置把监控数据中的异常信息进行告警，告警的规则可以直接基于现有的数据图表进行配置，在告警的时候也会把出现异常的图表进行通知，使告警通知更加友好。目前我自生产中使用Grafana的告警功能并不多。可能是因为我自己已经在Prometheus写好了告警规则。所以没必要了

> 1、有的同学觉得在Prometheus添加告警规则配置比较麻烦，你也可以在grafana里面来通过网页端添加
>
> 2、对于不想写脚本或开发语言的同学。又想对数据库的某些关键业务表进行监控（前提添加MySQL数据源），可以使用Grafanfa的告警功能，对数据库的某些重要的表做一个展示并监控报警。

### 修改配置文件

> Grafana Alerting 支持多种告警渠道，比如Alertmanager、钉钉、微信、Discord、Email、Kafka、Pushover、Telegram、Webhook 等等，我们这里使用钉钉和 Email 进行展示说明。

> Email配置：邮箱告警通常是最常见的告警接收方式，通过 Grafana 告警需要在 Grafana 的配置文件中配置 stmp 服务。在配置文件 /etc/grafana/grafana.ini 文件中添加 SMTP/Emailing 配置块并开启 Alerting ：

https://grafana.com/docs/grafana/latest/alerting/

#### Docker版本修改

config.monitoring 配置一定要和我使用docker安装prometheus的方法一致：

注：因为当时docker安装没有把grafana.ini数据持久化，所以通过修改config.monitoring实现

```sh
cat >>grafana/config.monitoring<<"EOF"
GF_SMTP_ENABLED=true
GF_SMTP_HOST=smtp.163.com:465
GF_SMTP_USER=cdring@163.com
GF_SMTP_PASSWORD=MONBUFHOQZPBXHGD
GF_SMTP_FROM_ADDRESS=cdring@163.com
EOF
```

```sh
docker-compose up -d
```

#### 二进制版本修改⭐

```sh
# 修改grafana.ini
vim /opt/module/grafana-9.4.7/conf/defaults.ini
```

```sh
enabled = true
host = smtp.163.com:25
user = 17315118673@163.com
password = HUSBWQHLTSIVPKOC
skip_verify = true
from_address = 17315118673@163.com
from_name = Grafana
```

```sh
# 重启Grafana
lsof -i:3000
kill -9 43383
nohup ./bin/grafana-server web > ./grafana.log 2>&1 &
```

#### 检查配置

http://192.168.11.61:3000/admin/settings

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292226205.png" alt="image-20230429222601113" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292226236.png" alt="image-20230429222647057" style="zoom:80%;" />

**163邮箱开启pop3/smtp**

需要注意的是这里我们使用的是 163 的邮箱进行发送，在配置 smtp 的时候需要在邮箱中开启IMAP/SMTP 和 POP3/SMTP 两个服务，并添加一个授权码，上面的 password 密码使用的就是授权码进行认证：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261504269.png" alt="image-20230426150402141" style="zoom:80%;" />

**修改默认邮件告警渠道**

回到 Grafana 页面中，点击左侧的Alerting在点击Contact points，在Contact point name修改grafana-default-email

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261504191.png" alt="image-20230426150449039" style="zoom:80%;" />

修改接收报警信息的邮箱，测试没问题后，点保存

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261505391.png" alt="image-20230426150538283" style="zoom:80%;" />

### 其他告警渠道

#### 添加钉钉告警渠道

需要提前创建webhook地址和开放ip白名单，回到Contact points页面，点击new contact point，如下图

https://oapi.dingtalk.com/robot/send?access_token=2ac0682516aa8634f3410c08339d21f7effeec5ac180eec60082a3ca66661f29

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261506160.png" alt="image-20230426150613068" style="zoom:80%;" />

在Create contact point页面中，填写名称，以及选择对应对应的告警渠道，填写webhook地址，发送测试消息，完成后保存，如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261506568.png" alt="image-20230426150632460" style="zoom:80%;" />

#### 添加alertmanager告警渠道

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261506695.png" alt="image-20230426150658602" style="zoom:80%;" />

#### 配置默认接收的告警渠道

点击左侧的Alerting在点击 Notification channels ，在default for all alerts默认中点编辑

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261507653.png" alt="image-20230426150719566" style="zoom:80%;" />

编辑页面中，选择我们之前添加好的告警渠道。配置默认的告警渠道

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261507552.png" alt="image-20230426150735438" style="zoom:80%;" />

### 添加告警规则

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261508268.png" alt="image-20230426150844153" style="zoom:80%;" />

告警规则填写：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292242926.png" alt="image-20230429224256820" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261509022.png" alt="image-20230426150907894" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261509980.png" alt="image-20230426150952858" style="zoom:80%;" />

完成后，在alert rules的grafana显示新增加的告警规则，如下图：

![image-20230429224604420](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292246530.png)

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261510865.png" alt="image-20230426151009773" style="zoom:80%;" />

### 测试

把nginx关闭，然后测试邮件和钉钉是否收到告警消息，钉钉收到测试和mysqldown的告警信息如下

```sh
docker stop nginx
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292247244.png" alt="image-20230429224758139" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304292248526.png" alt="image-20230429224832427" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261511632.png" alt="image-20230426151102485" style="zoom:67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261511410.png" alt="image-20230426151115303" style="zoom:80%;" />





# Alertmanager

> Alertmanager是一个告警管理组件，Prometheus发出告警分为两步，首先，Prometheus按告警规则向Alertmanager发送警告，所以告警规则是在Prometheus上定义的，然后，由Alertmanager负责管理这些告警，比如把告警去重、分组、聚合等操作后通过邮件等方式将告警通知给对应的负责人。

## 概述

告警能⼒在Prometheus的架构中被划分成两个独⽴的部分。如下所示，通过在Prometheus中定义AlertRule（告警规则），Prometheus会周期性的对告警规则进⾏计算，如果满⾜告警触发条件就会向Alertmanager发送告警信息。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304262012112.png" alt="image-20230426201212000" style="zoom:80%;" />

> Alertmanager作为⼀个独⽴的组件，负责接收并处理来⾃Prometheus Server(也可以是其它的客户端程序)的告警信息。Alertmanager可以对这些告警信息进⾏进⼀步的处理，⽐如当接收到⼤量重复告警时能够消除重复的告警信息，同时对告警信息进⾏分组并且路由到正确的通知⽅

> Prometheus内置了对邮件，Slack等多种通知⽅式的⽀持，同时还⽀持与Webhook的集成，以⽀持更多定制化的场景。例如，⽬前还不⽀持钉钉，那⽤户完全可以通过Webhook与钉钉机器⼈进⾏集成，从⽽通过钉钉接收告警信息。同时AlertManager还提供了静默和告警抑制机制来对告警通知⾏为进⾏优化。

Alertmanager除了提供基本的告警通知能⼒以外，还主要提供了如：分组、抑制以及静默等告警特性：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304262013328.png" alt="image-20230426201316214" style="zoom:80%;" />

### 分组

> 分组机制可以**将详细的告警信息合并成⼀个通知**。在某些情况下，⽐如由于系统宕机导致⼤量的告警被同时触发，在这种情况下分组机制可以将这些被触发的告警合并为⼀个告警通知，避免⼀次性接受⼤量的告警通知，⽽⽆法对问题进⾏快速定位。

> 例如，当集群中有数百个正在运⾏的服务实例，并且为每⼀个实例设置了告警规则。假如此时发⽣了⽹络故障，可能导致⼤量的服务实例⽆法连接到数据库，结果就会有数百个告警被发送到Alertmanager。⽽作为⽤户，可能只希望能够在⼀个通知中就能查看哪些服务实例收到影响。这时可以按照服务所在集群或者告警名称对告警进⾏分组，⽽将这些告警内聚在⼀起成为⼀个通知。告警分组，告警时间，以及告警的接受⽅式可以通过Alertmanager的配置⽂件进⾏配置

```yml
route:
  receiver: 'default-receiver'
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  group_by: [cluster, alertname]
  routes:
    - receiver: 'database-pager'
      group_wait: 10s
      match_re:
        service: mysql|cassandra
    - receiver: 'frontend-pager'
      group_by: [product, environment]
      match:
        team: frontend
```

> 默认情况下所有的告警都会发送给集群管理员default-receiver，因此在Alertmanager的配置⽂件的根路由中，对告警信息按照集群以及告警的名称对告警进⾏分组。

> 如果告警时来源于数据库服务如MySQL或者Cassandra，此时则需要将告警发送给相应的数据库管理员(database-pager)。这⾥定义了⼀个单独⼦路由，如果告警中包含service标签，并且service为MySQL或者Cassandra,则向database-pager发送告警通知，由于这⾥没有定义group_by等属性，这些属性的配置信息将从上级路由继承，database-pager将会接收到按cluster和alertname进⾏分组的告警通知。

> ⽽某些告警规则来源可能来源于开发团队的定义，这些告警中通过添加标签team来标示这些告警的创建者。在Alertmanager配置⽂件的告警路由下，定义单独⼦路由⽤于处理这⼀类的告警通知，如果匹配到告警中包含标签team，并且team的值为frontend，Alertmanager将会按照标签product和environment对告警进⾏分组。此时如果应⽤出现异常，开发团队就能清楚的知道哪⼀个环境(environment)中的哪⼀个应⽤程序出现了问题，可以快速对应⽤进⾏问题定位。

### 抑制

> 抑制是指**当某⼀告警发出后，可以停⽌重复发送由此告警引发的其它告警的机制**。例如，当集群不可访问时触发了⼀次告警，通过配置Alertmanager可以忽略与该集群有关的其它所有告警。这样可以避免接收到⼤量与实际问题⽆关的告警通知。抑制机制同样通过Alertmanager的配置⽂件进⾏设置。

### 配置文件

Alertmanager主要负责对Prometheus产⽣的告警进⾏统⼀处理，因此在Alertmanager配置中⼀般会包含以下⼏个部分

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304270933972.png" alt="image-20230427093330809" style="zoom:80%;" />

> 在全局配置中需要注意的是 resolve_timeout ，该参数定义了当Alertmanager持续多⻓时间未接收到告警后标记告警状态为resolved（已解决）。该参数的定义可能会影响到告警恢复通知的接收时间，读者可根据⾃⼰的实际场景进⾏定义，其默认值为5分钟。在接下来的部分，我们将已⼀些实际的例⼦解释Alertmanager的其它配置内容。

## 前置准备

> Prometheus把产⽣的告警发送给Alertmanager进⾏告警处理时，需要在Prometheus使⽤的配置⽂件中添加关联Alertmanager组件的对应配置内容。

### prometheus.yml

1）编辑prometheus.yml⽂件加⼊关联Alertmanager组件的访问地址，如下

```yml
# Alertmanager 配置
alerting:
  alertmanagers:
  - static_configs:
    - targets: ['alertmanager:9093']
```

2）设置rules文件位置

```yml
rule_files:
  - "rules/*.yml"
```

3）添加监控Alertmanager，让Prometheus去收集Alertmanager的监控指标。

```yml
  - job_name: 'alertmanager'
    # 覆盖全局默认值，每15秒从该作业中刮取⼀次⽬标
    scrape_interval: 15s
    static_configs:
    - targets: ['alertmanager:9093']
```

```sh
curl -X POST :9090/-/reload
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304270936316.png" alt="image-20230427093638145" style="zoom:80%;" />

### rules/linux.yml

```sh
# 进⼊到prometheus安装⽬录
cd /data/prometheus
vim prometheus/alert.yml
```

告警规则配置如下：

```yml
groups:
  - name: Prometheus alert
    rules:
      - alert: 服务告警
        expr: up{instance="node1:9100", job="linux监控"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "服务异常,实例:{{ $labels.instance }}"
          description: "{{ $labels.job }} 服务已关闭"
```

```sh
# 检查规则写的是否正确
cd /opt/module/prometheus-2.29.1
./promtool check rules rules/linux.yml
curl -X POST http://node1:9090/-/reload
curl -X POST http://node1:9093/-/reload 
```

在告警规则⽂件中，我们可以将⼀组相关的规则设置定义在⼀个group下。在每⼀个group中我们可以定义多个告警规则(rule)。⼀条告警规则主要由以下⼏部分组成：

```
alert：告警规则的名称。

expr：基于PromQL表达式告警触发条件，⽤于计算是否有时间序列满⾜该条件。

for：评估等待时间，可选参数。⽤于表示只有当触发条件持续⼀段时间后才发送告警。在等待期间新产⽣告警的状态为pending

labels：⾃定义标签，允许⽤户指定要附加到告警上的⼀组附加标签。

annotations：⽤于指定⼀组附加信息，⽐如⽤于描述告警详细信息的⽂字等，annotations的内容在告警产⽣时会⼀同作为参数发送到Alertmanager。
```

### 查看告警状态

> 重启Prometheus后，⽤户可以通过Prometheus WEB界⾯中的Alerts菜单查看当前Prometheus下的所有告警规则，以及其当前所处的活动状态。同时对于已经pending或者firing的告警，Prometheus也会将它们存储到时间序列ALERTS{}中。可以通过表达式，查询告警实例：

```
ALERTS{}
```

样本值为1表示当前告警处于活动状态（pending或者firing），当告警从活动状态转换为⾮活动状态时，样本值则为0

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301303197.png" alt="image-20230430130308026" style="zoom:80%;" />

### 测试告警规则

> 分别停止和启动node_exporter，这是监控linux系统的，查看状态

```sh
systemctl stop node_exporter
systemctl start node_exporter
```

停止node-exporter，查看状态

> Prometheus⾸次检测到满⾜触发条件后，由于告警规则中设置了1分钟（for: 1m）的等待时间，告警状态从 INACTIVE 变为 Pending ，如下图所示：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304270946529.png" alt="image-20230427094633367" style="zoom:80%;" />

如果1分钟后告警条件持续满⾜，告警状态从Penging变为FIRING，并且会把告警信息发送给alertmanager 。如下图

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304270946226.png" alt="image-20230427094658052" style="zoom:80%;" />

注：如果for: 0或者没有配置for，检测到满⾜触发条件，那告警状态从 INACTIVE 变为 FIRING ,把告警信息发送给 alertmanager，alertmanager接收到告警信息如下图：http://node1:9093/#/alerts

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304270947581.png" alt="image-20230427094728410" style="zoom:80%;" />

## 邮箱告警

### 配置邮箱服务

获取邮箱授权码并开启**smtp**服务，https://mail.163.com/ 登陆⾃⼰的163账号

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271005013.png" alt="image-20230427100506820" style="zoom:80%;" />

Pop3/smtp/imap服务，点开启。弹出来扫描⼆维码点框。⼿机扫描发送短信。获取授权码

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271005986.png" alt="image-20230427100525808" style="zoom:80%;" />

弹出来的框，复制授权码。就是⽤于第三⽅登录163邮箱的密码：MONBUFHOQZPBXHGD

### 修改alertmanager配置

```yml
global: # 全局配置，配置发送邮件的信息
  smtp_smarthost: smtp.163.com:25       # 腾讯邮箱服务器及端口
  smtp_from: 17315118673@163.com # 用于发送告警的邮箱
  smtp_auth_username: 17315118673@163.com # 登录的邮箱名
  smtp_auth_password: HUSBWQHLTSIVPKOC # 邮箱授权码，请登录用于发送的邮箱在设置→账户中开启
  smtp_require_tls: false # 不启用TLS

route: # 路由组配置
  group_by: ['alertname'] # 分组依据，可分多个组
  group_wait: 30s        # 第一次满足告警条件后等待多久发送邮件
  group_interval: 50s    # 出现新告警后等待多久发送邮件
  repeat_interval: 2h # 若已经成功发送邮件等待多久后再次发送
  receiver: 'email'      # 定义收件组名称
receivers: # 收件组配置
- name: 'email'
  email_configs:
  - to: 1597374863@qq.com # 收件人邮箱，可添加多个邮箱
  
inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'dev', 'instance']
```

```sh
# altermanager
curl -X POST http://node1:9093/-/reload  
```

检查：http://192.168.11.61:9093/#/status

### 配置触发器

查看现有触发器

```yml
cat prometheus/alert.yml
# 增加如下内容
groups:
  - name: Prometheus alert
    rules:
      - alert: 服务告警
        expr: up{instance="node1:9100", job="linux监控"} == 0
        for: 30s
        labels:
          severity: critical
        annotations:
          instance: "{{ $labels.instance }}"
          description: "{{ $labels.job }} 服务已关闭"
```

```sh
curl -X POST http://node1:9090/-/reload
```

访问告警模块的**web**⻚⾯：http://192.168.11.61:9090/alerts

> INACTIVE：活跃中，即表示正常⽆告警产⽣。
>
> PENDING：待触发，表示已经达到预设的阈值，但没达到预设的时间。
>
> FIRING：表示达到预设的阈值并超过预设的时间触发告警

### 测试告警是否正常

停⽌**node-exporter**

```sh
# docker环境
docker stop node-exporter

# ⼆进制安装环境
systemctl stop node_exporter
```

**prometheus**查看

浏览器打开prometheus web管理⻚⾯--点击 Alerts,

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271013738.png" alt="image-20230427101308564" style="zoom:80%;" />

检查**alertmanager**的**alerts**：http://192.168.11.61:9093/#/alerts

检查邮箱，登陆163邮箱查看邮件

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271013280.png" alt="image-20230427101345103" style="zoom:80%;" />

如果没收到钉钉消息，排查

```sh
docker logs -f alertmanager
```

### 使用模板(非必须)

看需求--不使⽤模版默认也⾏。

```sh
cd /opt/module/alertmanager-0.23.0
# 创建存放模版的⽬录
mkdir template
```

通过cat创建

```yaml
cat > template/email.tmpl <<EOF
{{ define "email.html" }}
{{- if gt (len .Alerts.Firing) 0 -}}{{ range .Alerts }}

<h2>@告警通知</h2>
告警程序: prometheus_alert <br>
告警级别: {{ .Labels.severity }} 级 <br>
告警类型: {{ .Labels.alertname }} <br>
故障主机: {{ .Labels.instance }} <br>
告警主题: {{ .Annotations.summary }} <br>
告警详情: {{ .Annotations.description }} <br>
触发时间: {{ .StartsAt.Local.Format "2006-01-02 15:04:05" }} <br>
{{ end }}{{ end -}}
{{- if gt (len .Alerts.Resolved) 0 -}}{{ range .Alerts }}

<h2>@告警恢复</h2>
告警程序: prometheus_alert <br>
故障主机: {{ .Labels.instance }}<br>
故障主题: {{ .Annotations.summary }}<br>
告警详情: {{ .Annotations.description }}<br>
告警时间: {{ .StartsAt.Local.Format "2006-01-02 15:04:05" }}<br>
恢复时间: {{ .EndsAt.Local.Format "2006-01-02 15:04:05" }}<br>
{{ end }}{{ end -}}
{{- end }}
EOF
```

```sh
# 检查看写的对不对
vim alertmanager/template/email.tmpl
# 修改alertmanager配置,增加html这⾏
vim alertmanager.yml
```

```yml
# 模版配置
templates:
  - '/opt/module/alertmanager-0.23.0/template/*.tmpl'

receivers:
  - name: 'email'
    # 收邮件的邮箱
    email_configs:
      - to: 'cdring@163.com'
        # 发送邮件的内容（调用模板文件中的）
        html: '{{ template "email.html" .}}'
```

```sh
# 重载配置
curl -X POST :9093/-/reload
# 检查
http://192.168.88.101:9093/#/status
```

163邮件报警

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301437789.png" alt="image-20230430143701687" style="zoom:80%;" />

修改前和修改后的区别如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271019992.png" alt="image-20230427101906816" style="zoom:80%;" />

## ⼿机电话+短信告警

### 安装步骤

睿象云（简称**CA**）安装步骤：https://www.aiops.com/

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261725852.png" alt="image-20230426172556728" style="zoom:80%;" />

注册成功后并登陆，点击智能告警平台

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261934056.png" alt="image-20230426193405912" style="zoom:80%;" />

### 创建应⽤

在点“集成”，然后找到“prometheus” 点下⾯的“+” 号

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261934570.png" alt="image-20230426193427432" style="zoom:80%;" />

填写应⽤名称，在点保持并获取key

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261934085.png" alt="image-20230426193445924" style="zoom:80%;" />

复制AppKey：2947c853c7c6430e8e87aa75f94304fa

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261936819.png" alt="image-20230426193606647" style="zoom:80%;" />

### 分派策略

1、点击“配置”---2、“分派策略”---3、“新建分派”--4、填写“分派策略名称”---5、选择“分派条件”---6、选择“分派⼈”—7、点击“保存” 如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261936282.png" alt="image-20230426193630130" style="zoom:80%;" />

### 配置通知策略

发⽣时：zabbix发⽣报警调⽤CA时触发，认领时：你收到短信后要回复认领时触发

关闭时：把收到的告警关闭时触发

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261936136.png" alt="image-20230426193658969" style="zoom:80%;" />

如果配置通知策略有问题 点操作列 修改或者删除

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261937534.png" alt="image-20230426193714382" style="zoom:80%;" />

### 集成prometheus

修改**alertmanager**的配置⽂件，cd0ffd35ec9a4ac88dc944dc470d603b

通过webhook⽅式通知Cloud Alert，编辑告警的配置⽂件，新增以下内容。

```yml
vim alertmanager.yml
route:
  # 全局报警组，这个参数是必选的
  receiver: ca
receivers:
- name: 'ca'
  webhook_configs:
  - url: 'http://api.aiops.com/alert/api/event/prometheus/2947c853c7c6430e8e87aa75f94304fa'
    send_resolved: true
```

```sh
# 重载alertmanager配置
curl -X POST :9093/-/reload
```

### 测试

```sh
# 关闭node-exporter
# docker环境
docker stop node-exporter
# ⼆进制安装环境
systemctl stop node_exporter
# 查看prometheus的alerts: http://192.168.11.61:9090/alerts
# 查看alertmanager的alerts：http://192.168.11.61:9093/#/alerts
# 如果没收到消息，排查
docker logs -f alertmanager
```

⼿机正常收到短信和电话报警信息如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261939621.png" alt="image-20230426193939447" style="zoom:80%;" />



## 企业钉钉告警

### 注册企业钉钉

浏览器打开[钉钉注册⻚⾯](https://oa.dingtalk.com/register_new.htm?source=CreateTeamPC&lwfrom=2019111111293551000#/) 填⼊⼿机号码，填⼊获取到的验证码，点注册

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261628750.png" alt="image-20230426162814592" style="zoom:80%;" />

填⼊企业资料并注册

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261628202.png" alt="image-20230426162845084" style="zoom:80%;" />

注册成功后，扫描⼆维码下载钉钉，如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261629865.png" alt="image-20230426162916755" style="zoom:80%;" />

### 添加钉钉机器⼈

因为机器⼈添加，只能是钉钉电脑版（⼿机版钉钉不能添加机器⼈）。“测试钉钉报警“ 这个企业只有我⼀个⼈，所以我就把报警消息发到默认的 ”测试钉钉报警 全员群“ ⾥⾯。实际使⽤时，请创建个运维群--添加对应的⼈员进来。

电脑钉钉登陆成功后----点击左下⻆的。。。---然后再点管理后台，如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261629199.png" alt="image-20230426162951081" style="zoom:80%;" />

点击之前创建的企业名

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261630909.png" alt="image-20230426163012802" style="zoom:80%;" />

点通讯录--组织架构--添加⼦部⻔

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261630847.png" alt="image-20230426163030739" style="zoom: 80%;" />

刷新后，把接收告警的员⼯调整到刚刚添加的部⻔

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261630616.png" alt="image-20230426163051507" style="zoom:80%;" />

勾选部⻔

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261631971.png" alt="image-20230426163109859" style="zoom:80%;" />

添加成功后，电脑钉钉消息窗⼝--会弹出⼀个测试告警的群--点击这个群---群设置--机器⼈

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261631196.png" alt="image-20230426163128076" style="zoom:80%;" />

添加机器⼈

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261631919.png" alt="image-20230426163151811" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261631133.png" alt="image-20230426163159028" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261632304.png" alt="image-20230426163212190" style="zoom:80%;" />

机器⼈名字：随意

勾选ip：填⼊alertmanager外⽹ip

如果在⾃⼰电脑上测试钉钉告警，获取Alertmanager外⽹ip地址的⽅法为浏览器打开http://ip138.com 您

的iP地址是：[xxx.xx.xx.xx]得到⾃⼰外⽹ip地址。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261634389.png" alt="image-20230426163409282" style="zoom:80%;" />

复制机器⼈**webhook**地址

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261634886.png" alt="image-20230426163432766" style="zoom:80%;" />

复制webhook的地址，如下：

https://oapi.dingtalk.com/robot/send?access_token=2a89e1b607ff295d3347baf140e4b5ada2733ea852f1c51f79782b864b697a5f

我们真实需要的是access_token=后⾯的，2a89e1b607ff295d3347baf140e4b5ada2733ea852f1c51f79782b864b697a5f

### 实现钉钉告警

https://github.com/timonwong/prometheus-webhook-dingtalk/releases

#### 二进制安装

```sh
#安装⼆进制安装包
wget https://github.com/timonwong/prometheus-webhook-dingtalk/releases/download/v2.1.0/prometheus-webhook-dingtalk-2.1.0.linux￾amd64.tar.gz
#解压
tar vxf prometheus-webhook-dingtalk-2.1.0.linux-amd64.tar.gz
ls -l
#移动并改名
mv prometheus-webhook-dingtalk-2.1.0.linux-amd64 /opt/prometheus-webhook-dingtalk
```

创建配置⽂件

```
cat > /opt/prometheus-webhook-dingtalk/config.yml <<"EOF"
targets:
  webhook1:
    url: https://oapi.dingtalk.com/robot/send?access_token=修改为⾃⼰的TOKEN
    secret: SEC000000000000000000000
EOF
```

创建⼀个 prometheus ⽤户：

```
useradd -M -s /usr/sbin/nologin prometheus
chown prometheus:prometheus -R /opt/prometheus-webhook-dingtalk
```

创建 systemd 服务

```sh
cat > /etc/systemd/system/prometheus-webhook-dingtalk.service << "EOF"
[Unit]
Description=prometheus-webhook-dingtalk
Documentation=https://github.com/timonwong/prometheus-webhook-dingtalk
[Service]
User=prometheus
Group=prometheus
Restart=on-failure
ExecStart=/opt/prometheus-webhook-dingtalk/prometheus-webhook-dingtalk \
 --config.file=/opt/prometheus-webhook-dingtalk/config.yml
[Install]
WantedBy=multi-user.target
EOF
```

```sh
# 启动 prometheus-webhook-dingtalk
systemctl daemon-reload
systemctl start prometheus-webhook-dingtalk.service
# 加⼊到开机⾃启动
systemctl enable prometheus-webhook-dingtalk.service
# 检查
systemctl status prometheus-webhook-dingtalk.service
# 查看 prometheus-webhook-dingtalk的⽇志以进⾏故障排除：
journalctl -u prometheus-webhook-dingtalk.service -f
```

#### **Docker**安装⭐

创建配置⽂件**config.yml**

```sh
# 创建数据⽬录
mkdir /data/docker-prometheus/prometheus-webhook-dingtalk/ -p
cat > /data/docker-prometheus/prometheus-webhook-dingtalk/config.yml <<"EOF"
targets:
  webhook1:
    url: https://oapi.dingtalk.com/robot/send?access_token=2a89e1b607ff295d3347baf140e4b5ada2733ea852f1c51f79782b864b697a5f
    secret: SEC000000000000000000000
EOF
```

**docker-compose.yaml**⽂件

注：我把prometheus-webhook-dingtalk安装在prometheus服务器上，如果安装在其他机器上也是可以的。

```yml
cd /data/docker-prometheus/prometheus-webhook-dingtalk/
cat > docker-compose.yaml << "EOF"
version: '3.3'
services:
  webhook:
    image: timonwong/prometheus-webhook-dingtalk:v2.1.0
    container_name: prometheus-webhook-dingtalk
    restart: "always"
    ports:
      - 8060:8060
    command:
      - '--config.file=/etc/prometheus-webhook-dingtalk/config.yml'
    volumes:
      - ./config.yml:/etc/prometheus-webhook-dingtalk/config.yml
      - /etc/localtime:/etc/localtime:ro
EOF
```

```sh
docker-compose up -d
docker ps
docker logs -f prometheus-webhook-dingtalk
```

### 访问地址

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261646628.png" alt="image-20230426164611530" style="zoom:80%;" />

### alertmanager配置

```sh
route: # 路由组配置
  group_by: ['alertname'] # 分组依据，可分多个组
  group_wait: 10s        # 第一次满足告警条件后等待多久发送邮件
  group_interval: 10s    # 出现新告警后等待多久发送邮件
  repeat_interval: 1h    # 若已经成功发送邮件等待多久后再次发送
  receiver: 'dingtalk'   # 修改成钉钉
  
receivers: # 收件组配置
- name: 'email'
  email_configs:
  - to: 1597374863@qq.com # 收件人邮箱，可添加多个邮箱
    # 发送邮件的内容（调用模板文件中的）
    html: '{{ template "email.html" .}}'
- name: 'dingtalk'
  webhook_configs:
  - url: 'http://192.168.88.101:8060/dingtalk/webhook1/send'
    send_resolved: true
```

```sh
# 重载alertmanager配置
curl -X POST :9093/-/reload
```

### 配置触发器

前置准备已配置，查看现有触发器，访问告警模块的**web**⻚⾯

http://192.168.11.61:9090/alerts

INACTIVE：活跃中，即表示正常⽆告警产⽣。

PENDING：待触发，表示已经达到预设的阈值，但没达到预设的时间。

FIRING：表示达到预设的阈值并超过预设的时间触发告警

### 测试钉钉

```sh
# 关闭node-exporter
# docker环境
docker stop node-exporter
# ⼆进制安装环境
systemctl stop node_exporter
# 查看prometheus的alerts: http://192.168.11.61:9090/alerts
# 查看alertmanager的alerts：http://192.168.11.61:9093/#/alerts
# 如果没收到钉钉消息，排查
docker logs -f alertmanager
```

钉钉正常收到报警信息如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301537542.png" alt="image-20230430153713389" style="zoom:80%;" />

### 可能的问题

由于配置名称错误导致不能发送报警信息给钉钉，如下图：解决方式：修改名称，使其配置正确

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261649896.png" alt="image-20230426164935718" style="zoom:80%;" />

## 企业微信告警

### 注册企业微信

浏览器打开https://work.weixin.qq.com/ 点击注册，如下填写资料

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261652311.png" alt="image-20230426165205193" style="zoom:80%;" />

### webhook告警（和微信应⽤告警⼆选⼀）⭐

添加群机器⼈，注册成功后，⼿机下载企业微信，登陆企业微信。在⼿机上，如下图操作：

> 注：因为我这个是测试企业微信，所以就在”企业全员群“，新建群机器⼈了。真实⼀般都是新创建个部⻔，然后把需要接受报警的⼈拉到这个部⻔⾥⾯，然后在这个部⻔群⾥⾯新建机器⼈。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261657210.png" alt="image-20230426165709046" style="zoom:80%;" />

复制机器⼈的**webhook**地址：https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=15957180-9e0c-4224-8c44-08cb09b7f90d

我在上图复制的到webhook地址如下：真实只需要⽤到key后⾯的

**docker安装webhook-wechat**

Prometheus服务器上安装

创建存放webhook-wechat的数据⽬录

```sh
mkdir /data/docker-prometheus/webhook-wechat -p
cd /data/docker-prometheus/webhook-wechat
```

使⽤cat创建新⽂件

```sh
cat > docker-compose.yaml <<"EOF"
version: "3"
services:
  prometheus-webhook-webchat:
    image: linge365/webhook-wechat:latest
    container_name: prometheus-webhook-webchat
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime
    ports:
      - "5000:5000"
    environment:
      ROBOT_TOKEN: "15957180-9e0c-4224-8c44-08cb09b7f90d"
EOF
```

```sh
docker-compose up -d
docker ps
docker logs -f prometheus-webhook-webchat
```

**修改alertmanager配置**

```sh
vim alertmanager.yml
#增加如下配置
route: # 路由组配置
  group_by: ['alertname'] # 分组依据，可分多个组
  group_wait: 10s        # 第一次满足告警条件后等待多久发送邮件
  group_interval: 10s    # 出现新告警后等待多久发送邮件
  repeat_interval: 1h # 若已经成功发送邮件等待多久后再次发送
  receiver: wechat
  
receivers: # 收件组配置
- name: 'wechat'
  webhook_configs:
  - url: 'http://192.168.88.101:5000'
    send_resolved: true
```

```sh
# 重载alertmanager配置
curl -X POST :9093/-/reload
```

### 微信应⽤告警（和**webhook**告警⼆选⼀）

> 必须有域名才能用这种方式，所以目前只能用webhook方式

企业微信应⽤需要添加ip⽩名单才能正常使⽤,浏览器打开企业微信[企业微信官⽹](https://work.weixin.qq.com/)

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261703615.png" alt="image-20230426170358443" style="zoom:80%;" />

⼿机下载“企业微信”，使⽤注册的⼿机登录。扫描⼆维码登录企业微信官⽹

短信验证

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261704438.png" alt="image-20230426170459298" style="zoom:80%;" />

创建应⽤

登录成功后，选择应⽤管理--创建应⽤

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261705612.png" alt="image-20230426170518466" style="zoom:80%;" />

上传logo，填写应⽤名称，选择可⻅范围

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261705672.png" alt="image-20230426170535541" style="zoom:80%;" />

获取**AgentID**

创建应⽤成功后，复制AgentId,和查看Secret--会发送Secret到⼿机企业微信中。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261705327.png" alt="image-20230426170553197" style="zoom:80%;" />

设置**ip**⽩名单

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261706923.png" alt="image-20230426170617796" style="zoom:80%;" />

设置可信域名

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261706979.png" alt="image-20230426170638855" style="zoom:80%;" />

获取**Secret**

⼿机下载“企业微信”app，并登录成功。”企业微信团队“发来⼀条新消息，点击查看Secret，复制Secret

-rg8Xtzchefy6w94O6G_qT5gOMhDZt7MsZmHSELAOZw

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261707154.png" alt="image-20230426170710011" style="zoom:80%;" />

获取部⻔**id**

注：获取⽤户名或者创建标签都可以

点击通讯录--选择企业名--点右边--查看部⻔id，如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261707227.png" alt="image-20230426170732114" style="zoom:80%;" />

获取**corp_id**

点击“我的企业”--复制企业id.ww75c7ff0bc812538c

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261707770.png" alt="image-20230426170751651" style="zoom:80%;" />

修改alertmanager配置

```sh
vim alertmanager/config.yml

route:
  receiver: wechat
receivers:
- name: 'wechat'
  wechat_configs:
  - send_resolved: true
    #to_user: '@all'
    #发送给企业微信⽤户的ID，@all是所有⼈
    #to_tag: '1' # 企业微信中创建的接收告警的标签
    to_party: '1' # 部⻔id
    agent_id: '1000002' #企业微信中创建的应⽤的ID
    corp_id: 'ww75c7ff0bc812538c' #企业微信中企业ID
    api_secret: '-rg8Xtzchefy6w94O6G_qT5gOMhDZt7MsZmHSELAOZw' # 企业微信中，应⽤的Secret
```

检查配置

```sh
# Docker安装⽅式，检查
docker exec -it alertmanager amtool check-config
/etc/alertmanager/config.yml
# ⼆进制安装⽅式，检查
/opt/alertmanager/alertmanager amtool check-config
/etc/alertmanager/config.yml
# 重载alertmanager配置
curl -X POST :9093/-/reload
```

### 测试微信告警

```sh
# 关闭node-exporter
# Docker环境
docker stop node-exporter
# ⼆进制安装环境
systemctl stop node_exporter
# 查看prometheus的alerts: http://192.168.11.61:9090/alerts
# 查看alertmanager的alerts：http://192.168.11.61:9093/#/alerts如果没收到钉钉消息，排查
docker logs -f alertmanager
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301555843.png" alt="image-20230430155557690" style="zoom: 50%;" />

微信正常收到报警信息如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261712343.png" alt="image-20230426171203189" style="zoom:80%;" />

### 使⽤模版(⾮必需，仅限微信应⽤告警)

> 看需求--不使⽤模版默认也⾏，**不适⽤webhook⽅式告警。**
>

**1**、创建模版⽂件（**prometheus**服务器操作）

```sh
cd /opt/module/alertmanager-0.23.0
# 创建存放模版的⽬录
mkdir template
```

通过cat创建

```sh
cat > template/wechat.tmpl <<"EOF" 
{{ define "wechat.html" }}
{{- if gt (len .Alerts.Firing) 0 -}}{{ range .Alerts }}
@告警通知
告警程序: prometheus_alert
告警级别: {{ .Labels.severity }}级别
告警类型: {{ .Labels.alertname }}
故障主机: {{ .Labels.instance }}
告警主题: {{ .Annotations.summary }}
告警详情: {{ .Annotations.description }}
触发时间: {{ .StartsAt.Local.Format "2006-01-02 15:04:05" }}
{{ end }}{{ end -}}
{{- if gt (len .Alerts.Resolved) 0 -}}{{ range .Alerts }}
@告警恢复
告警程序: prometheus_alert
故障主机: {{ .Labels.instance }}
故障主题: {{ .Annotations.summary }}
告警详情: {{ .Annotations.description }}
告警时间: {{ .StartsAt.Local.Format "2006-01-02 15:04:05" }}
恢复时间: {{ .EndsAt.Local.Format "2006-01-02 15:04:05" }}
{{ end }}{{ end -}}
{{- end }}
EOF
```

增加message这⾏

```yml
#模版配置
templates:
  - '/opt/module/alertmanager-0.23.0/template/*.tmpl'
....
receivers:
- name: 'wechat'
  wechat_configs:
  - send_resolved: true
    # 只增加这⾏配置
    message: '{{ template "wechat.html" . }}'
```

```sh
curl -X POST :9093/-/reload
```

检查：http://192.168.11.61:9093/#/status

## 抑制和静默

### 抑制机制

> Alertmanager的抑制机制可以避免当某种问题告警产⽣之后⽤户接收到⼤量由此问题导致的⼀系列的其它告警通知。例如当集群不可⽤时，⽤户可能只希望接收到⼀条告警，告诉他这时候集群出现了问题，⽽不是⼤量的如集群中的应⽤异常、中间件服务异常的告警通知。

> 在Alertmanager配置⽂件中，使⽤inhibit_rules定义⼀组告警的抑制规则

```
inhibit_rules:
  [ - <inhibit_rule> ... ]
```

每⼀条抑制规则的具体配置如下：

```sh
target_match:
  [ <labelname>: <labelvalue>, ... ]
target_match_re:
  [ <labelname>: <regex>, ... ]
source_match:
  [ <labelname>: <labelvalue>, ... ]
source_match_re:
  [ <labelname>: <regex>, ... ]
[ equal: '[' <labelname>, ... ']' ]
```

> 当已经发送的告警通知匹配到target_match和target_match_re规则，当有新的告警规则如果满⾜source_match或者定义的匹配规则，并且已发送的告警与新产⽣的告警中equal定义的标签完全相同，则启动抑制机制，新告警不会发送

```yml
inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'dev', 'instance']
```

在alertname、dev、instance 三个标签的值相同情况下，critaical 的报警会抑制 warning 级别的报警信息。

### 临时静默

> 静默提供了⼀个简单的机制可以快速根据标签对告警进⾏静默处理。如果接收到的告警符合静默的配置，
>
> Alertmanager则不会发送告警通知。静默设置需要在Alertmanager的Werb⻚⾯上进⾏设置。

> 除了基于抑制机制可以控制告警通知的⾏为以外，⽤户或者管理员还可以直接通过Alertmanager的UI临时屏蔽特定的告警通知。通过定义标签的匹配规则(字符串或者正则表达式)，如果新的告警通知满⾜静默规则的设置，则停⽌向receiver发送通知。⽤于停机维护，或者有⼀个不需要处理的告警信息

#### 创建静默规则

进⼊Alertmanager UI，点击"Silences"---在点右上⻆的"New Silence"显示如下内容：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304270953848.png" alt="image-20230427095309671" style="zoom:80%;" />

> 定义静默规则的开始时间以及持续时间和结束时间，通过Matchers部分可以设置多条匹配规则(字符串匹配或者正则匹配)。填写当前静默规则的创建者以及创建原因后，点击"Create"按钮即可。通过"Preview Alerts"可以查看预览当前匹配规则匹配到的告警信息。静默规则创建成功后，Alertmanager会开始加载该规则并且设置状态为Pending,当规则⽣效后则进⾏到Active状态。

#### 查看静默规则

点击”silences“在“Active”查看正在运⾏的静默规则

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304270953557.png" alt="image-20230427095346397" style="zoom:80%;" />

#### 匹配的告警信息失效

当静默规则⽣效以后，从Alertmanager的Alerts⻚⾯下⽤户将不会看到该规则匹配到的告警信息。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304270954848.png" alt="image-20230427095406696" style="zoom:80%;" />

#### 取消静默规则

对于已经⽣效的规则，⽤户可以通过⼿动点击”Expire“按钮使当前规则过期。

### 路由匹配

> 每⼀个告警都会从配置⽂件中顶级的route进⼊路由树，需要注意的是顶级的route必须匹配所有告警(即不能有任何的匹配设置match和match_re)，每⼀个路由都可以定义⾃⼰的接受⼈以及匹配规则。默认情况下，告警进⼊到顶级route后会遍历所有的⼦节点，直到找到最深的匹配route，并将告警发送到该route定义的receiver中。但如果route中设置**continue**的值为false，那么告警在匹配到第⼀个⼦节点之后就直接停⽌。如果**continue**为true，报警则会继续进⾏后续⼦节点的匹配。如果当前告警匹配不到任何的⼦节点，那该告警将会基于当前路由节点的接收器配置⽅式进⾏处理。

> 其中告警的匹配有两种⽅式可以选择。⼀种⽅式基于字符串验证，通过设置**match**规则判断当前告警中是否存在标签labelname并且其值等于labelvalue。第⼆种⽅式则基于正则表达式，通过设置**match_re**验证当前告警标签的值是否满⾜正则表达式的内容。如果警报已经成功发送通知, 如果想设置发送告警通知之前要等待时间，则可以通过**repeat_interval**参数进⾏设置。

```yml
route:
  group_by: ['alertname'] # 定义分组,根据label标签进⾏分组
  group_wait: 10s # 分组等待时间，也就是说在10秒内同⼀个组中有没有⼀起报警的，如果有则同时发出报警邮件，也就是有2个报警同时发在⼀个邮件
  group_interval: 10s # 告警时间间隔
  repeat_interval: 10m # 重复告警间隔，也就是触发的⼀个告警在10分钟内没有处理则再次发⼀封邮件。
  continue: false # 若路由上的continue字段的值为false，则遇到第⼀个匹配的路由分⽀后即终⽌。否则，将继续匹配后续的⼦节点;
  receiver: 'receiver-01' # 默认邮箱
  routes: # 启⽤⼀个⼦路由
    - receiver: 'receiver-dba'  # 接收者为receiver-dba
      group_wait: 10s # 分组等待时间
      match_re:  # 匹配⼀个正则
        service: mysql|db  # service标签包含mysql和db的统⼀发送给dba的邮箱
      continue: false # 若路由上的continue字段的值为false，则遇到第⼀个匹配的路由分⽀后即终⽌。否则，将继续匹配后续的⼦节点;
    - receiver: 'receiver-01'  # 接收者为receiver-01
      group_wait: 10s # 分组时间
      match:
        serverity: error # 将serverity标签值包含error的发送给yunwei的邮箱
      continue: false # 若路由上的continue字段的值为false，则遇到第⼀个匹配的路由分⽀后即终⽌。否则，将继续匹配后续的⼦节点;

receivers: # 定义接收者的邮箱
  - name: 'receiver-01' # 接收者名字，要和routes中的receiver对应
    email_configs:
      - to: '11111@qq.com' # receiver-01的邮箱地址
  - name: 'receiver-dba'  # 接收者名字，要和routes中的receiver对应
    email_configs:
      - to: '2222@qq.com' # receiver-dba的邮箱地址
```

```yml
route:
  group_by: ['instance'] # 根据 instance 标签分组
  continue: true # 为true则还需要去匹配⼦路由。
  receiver: 'receiver-01'
  routes:
    - receiver: 'receiver-01'
      match:
        alertname: 'InstanceDown' # 告警的名字是 InstanceDown 则发送给receiver-03
    - receiver: 'webchat'
      match_re:
        alertname: 'Cpu.*'  # 告警的名字以 Cpu开头的 则发送给 webchat
    - receiver: 'dingtalk'
      match:
        alertname: 'InstanceDown' # 告警的名字是 InstanceDown 则发送给 dingtalk

receivers:
  - name: 'receiver-01'
    email_configs:
      - to: '1111@qq.com'
  - name: 'webchat'
    webhook_configs:
      - url: 'http://192.168.11.61:5000'
        send_resolved: true
  - name: 'dingtalk'
    webhook_configs:
      - url: 'http://192.168.11.61:8060/dingtalk/webhook1/send'
        send_resolved: true
```

### 告警分组

> 在之前的部分有讲过，Alertmanager可以对告警通知进⾏分组，将多条告警合合并为⼀个通知。这⾥我们可以使⽤**group_by**来定义分组规则。基于告警中包含的标签，如果满⾜**group_by**中定义标签名称，那么这些告警将会合并为⼀个通知发送给接收器。

> 有的时候为了能够⼀次性收集和发送更多的相关信息时，可以通过**group_wait**参数设置等待时间，如果在等待时间内当前group接收到了新的告警，这些告警将会合并为⼀个通知向receiver发送。⽽**group_interval**配置，则⽤于定义相同的Group之间发送告警通知的时间间隔。例如，当使⽤Prometheus监控多个集群以及部署在集群中的应⽤和数据库服务，并且定义以下的告警处理路由规则来对集群中的异常进⾏通知。

```yml
route:
  receiver: 'default-receiver'
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  group_by: [cluster, alertname]
  
routes:
  - receiver: 'database-pager'
    group_wait: 10s
    match_re:
      service: mysql|cassandra
  - receiver: 'frontend-pager'
    group_by: [product, environment]
    match:
      team: frontend
```



## 告警总结⭐

### ⽣产建议

> 最好选2个告警通知。如果很重要的可以设置电话告警，因为微信，钉钉信息很多⼈不看。但是来电话了基本都看

### 配置总结

### 完整配置

```sh
vim alertmanager.yml
```

```yml
global:
  #163服务器
  smtp_smarthost: 'smtp.163.com:465'
  #发邮件的邮箱
  smtp_from: 'cdring@163.com'
  #发邮件的邮箱⽤户名，也就是你的邮箱　　　　　
  smtp_auth_username: 'cdring@163.com'
  #发邮件的邮箱密码
  smtp_auth_password: 'MONBUFHOQZPBXHGD'
  #进⾏tls验证
  smtp_require_tls: false

templates:
  - '/etc/alertmanager/template/*.tmpl'
  
  
route:
 group_by: ['alertname']
 # 当收到告警的时候，等待group_wait配置的时间，看是否还有告警，如果有就⼀起发出去
 group_wait: 10s
 # 如果上次告警信息发送成功，此时⼜来了⼀个新的告警数据，则需要等待group_interval配置的时间才可以发送出去
 group_interval: 10s
 # 如果上次告警信息发送成功，且问题没有解决，则等待 repeat_interval配置的时间再次发送告警数据
 repeat_interval: 10m
 # 全局报警组，这个参数是必选的
 receiver: email_dingtalk

receivers:
  - name: 'email_dingtalk'
    email_configs:
      - to: 'cdring@163.com'
        html: '{{ template "email.html" .}}'
        send_resolved: true
    webhook_configs:
      - url: 'http://192.168.11.61:8060/dingtalk/webhook1/send'
        send_resolved: true
  - name: 'wechat'
    webhook_configs:
      - url: 'http://192.168.11.61:5000'
        send_resolved: true
  - name: 'ca'
    webhook_configs:
      - url: 'http://api.aiops.com/alert/api/event/prometheus/cd0ffd35ec9a4ac88dc944dc470d603b'
        send_resolved: true
inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'dev', 'instance']
```

### 配置告警规则⭐

规则：https://github.com/samber/awesome-prometheus-alerts

该地址包含了大多数的告警规则，可以直接去复制就行

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301810104.png" alt="image-20230430181023946" style="zoom:80%;" />

https://samber.github.io/awesome-prometheus-alerts/rules#mysql

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301811525.png" alt="image-20230430181106320" style="zoom:80%;" />

# 服务发现

## 服务发现

> 接下来我们将学习 Prometheus 中是如何使⽤服务发现来查找和抓取⽬标的。我们知道在 Prometheus 配置⽂件中可以通过⼀个 static_configs 来配置静态的抓取任务，但是在云环境下，特别是容器环境下，抓取⽬标地址是经常变动的，所以⽤静态的⽅式就不能满⾜这些场景了，还有特别在很多服务器需要监控时。所以我们需要监控系统能够动态感知这个变化，不可能每次变动都去⼿动重新配置的，为了应对复杂的动态环境，Prometheus 也提供了与基础设施中的服务发现集成的功能。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271052768.png" alt="image-20230427105222560" style="zoom:67%;" />

Prometheus 已经⽀持多种内置的服务发现机制：

> 发现云服务商的 VM 虚拟机
>
> Kubernetes 上的⾃动发现
>
> 通⽤的服务查找，例如 DNS、Consul、Zookeeper 或⾃定义发现机制

我们都可以通过 Prometheus 配置⽂件中的 scrape_config 部分进⾏配置，Prometheus 会不断更新动态的抓取⽬标列表，⾃动停⽌抓取旧的实例，开始抓取新的实例，Prometheus 特别适合运⾏于Kubernetes 集群下⾯，可以⾃动发现监控⽬标。此外⼤部分服务发现机制还会提供⽬标的⼀些元数据，通常都是带有 __ 的前缀， ⽐如标签、注解、服务名等等，可以在 relabeling 阶段使⽤这些元数据来过滤修改⽬标，这些元信息标签在重新标记阶段后被删除。

## 基于文件的服务发现⭐

除了基于 Consul 的服务发现之外，Prometheus 也允许我们进⾏⾃定义的发现集成，可以通过 watch ⼀组本地⽂件来获取抓取⽬标以及标签信息，也就是我们常说的基于⽂件的服务发现⽅式。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271053172.png" alt="image-20230427105327949" style="zoom:67%;" />

> 基于⽂件的服务发现提供了⼀种更通⽤的⽅式来配置静态⽬标，并作为⼀个接⼝插⼊⾃定义服务发现机制。它读取⼀组包含零个或多个 <static_config> 列表的⽂件，对所有定义的⽂件的变更通过磁盘监视被检测到并⽴即应⽤，⽂件可以以 YAML 或 JSON 格式提供。⽂件必须包含⼀个静态配置的列表:当然该⽂件也可以使⽤ JSON 格式进⾏配置：

```json
[
   {
     "targets": [ "<host>", ... ],
     "labels": {
       "<labelname>": "<labelvalue>", ...
     }
   },
   ...
]
```

如果是 YAML ⽂件则格式为：

```yml
- targets:
  [ - '<host>' ]
  labels:
    [ <labelname>: <labelvalue> ... ]
```

⽂件内容也会在指定的刷新间隔时间内定期重新读取。

```yml
# Patterns for files from which target groups are extracted.
files:
  [ - <filename_pattern> ... ]
# Refresh interval to re-read the files.
[ refresh_interval: <duration> | default = 5m ]
```

其中 <filename*pattern> 可以是⼀个以 .json 、 .yml 或 .yaml 结尾的路径，最后⼀个路径段可以包含⼀个匹配任何字符序列的 * ，例如： my/path/tg_*.json 。

### 创建⽂件

接下来我们来创建⼀个⽤于服务发现的⽬标⽂件，在与 prometheus.yml ⽂件相同⽬录下⾯创建⼀个名为 targets.yml 的⽂件，内容如下所示：

```sh
cd /opt/module/prometheus-2.29.1
mkdir targets 
cd targets
```

targets.yml

```yml
- targets: ['localhost:9090']
  labels:
    job: prometheus

- targets: ['cadvisor:8080']
  labels:
    instance: Prometheus服务器
    job: cadvisor

- targets: ['192.168.88.101:8080']
  labels:
    instance: test服务器
    job: cadvisor

- targets: ['node_exporter:9100']
  labels:
    instance: Prometheus服务器
    job: node-exporter

- targets: ['192.168.88.101:9100']
  labels:
    instance: test服务器
    job: node-exporter

- targets: ['192.168.88.101:9113']
  labels:
    instance: test服务器
    job: nginx_exporter

- targets: ['192.168.88.101:9121']
  labels:
    instance: test服务器
    job: redis_exporter

- targets: ['192.168.88.101:9419']
  labels:
    instance: test服务器
    job: rabitmq_exporter

- targets: ['192.168.88.101:9216']
  labels:
    instance: test服务器
    job: mongodb_exporter

- targets: ['192.168.88.101:9104']
  labels:
    instance: test服务器
    job: mysqld_exporter

- targets: ['192.168.88.101:9256']
  labels:
    instance: test服务器
    job: process
```

springboot.yml

```yml
cat >springboot.yml<<"EOF"
- targets:
  - 192.168.88.101:8081
EOF
```

blackbox-exporter-http.yml

```yml
cat >blackbox-exporter-http.yml<<"EOF"
- targets: 
  - https://www.baidu.com
  - https://www.jd.com
EOF
```

blackbox-exporter-tcp.yml

```yml
cat >blackbox-exporter-tcp.yml<<"EOF"
- targets:
  - 192.168.88.101:22
  - 192.168.88.101:9090
EOF
```

blackbox-exporter-icmp.yml

```yml
cat >blackbox-exporter-icmp.yml<<"EOF"
- targets:
  - 192.168.88.101
  - 192.168.88.101
EOF
```

domain.yml

```yml
cat >domain.yml<<"EOF"
- targets:
  - qq.com
  - baidu.com
EOF
```

### 配置⽂件服务发现

⽤于发现的⽬标⽂件创建完成后，要让 Prometheus 能够从上⾯的 targets.yml ⽂件中⾃动读取抓取⽬标，需要在 prometheus.yml 配置⽂件中的 scrape_configs 部分添加如下所示的抓取配置：

```sh
# 备份⽂件，变成prometheus.yml.bak
cp -a prometheus.yml{,.bak}
# 修改prometheus.yml
vim prometheus.yml
```

```yml
# 全局配置
global:
  scrape_interval: 15s
  evaluation_interval: 15s

# Alertmanager 配置
alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']

# 报警(触发器)配置
rule_files:
  - "alert.yml"
  - "rules/*.yml"

# 搜刮配置
scrape_configs:
  - job_name: "file-sd-test"
    file_sd_configs:
      - refresh_interval: 10s
        files:
          - "targets/targets.yml"

  # Spring Boot 2.x 应⽤数据采集配置
  - job_name: 'file-springboot-demo'
    metrics_path: '/actuator/prometheus'
    file_sd_configs:
      - refresh_interval: 10s
        files:
          - targets/springboot.yml

  # HTTP 配置
  - job_name: "file-blackbox_http"
    metrics_path: /probe
    params:
      module: [http_2xx]
    file_sd_configs:
      - refresh_interval: 10s
        files:
          - targets/blackbox-exporter-http.yml
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 192.168.88.101:9115

  # TCP 检查配置
  - job_name: "file-blackbox_tcp"
    metrics_path: /probe
    params:
      module: [tcp_connect]
    file_sd_configs:
      - refresh_interval: 10s
        files:
          - targets/blackbox-exporter-tcp.yml
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 192.168.88.101:9115

  # ICMP 检查配置 (Ping)
  - job_name: "blackbox_icmp"
    metrics_path: /probe
    params:
      module: [icmp]
    file_sd_configs:
      - refresh_interval: 10s
        files:
          - targets/blackbox-exporter-http.yml
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 192.168.88.101:9115

  - job_name: domain
    scrape_interval: 15s
    metrics_path: /probe
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - target_label: __address__
        replacement: 192.168.88.101:9222 # domain_exporter address
    file_sd_configs:
      - refresh_interval: 10s
        files:
          - targets/domain.yml
```

```
curl -X POST :9090/-/reload
```

重新 reload 或者重启下 Prometheus 让其重新读取配置⽂件信息，然后同样前往 Prometheus UI 的targets ⻚⾯下⾯查看

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271102658.png" alt="image-20230427110206365" style="zoom:80%;" />

> 然后我们可以尝试改变 targets.yml 的内容，⽐如为 192.168.11.62:8080 实例增加⼀个 env: test的标签，不⽤重新加载 Prometheus 配置，Prometheus 将 watch 该⽂件，并⾃动接收任何变化。

> 注意：当在⽣产环境 Prometheus 服务器中改变 file_sd ⽬标⽂件时，确保改变是原⼦的，以避免重新加载出现错误，最好的⽅法是在⼀个单独的位置创建更新的⽂件，然后将其重命名为⽬标⽂件名（使⽤ mv 命令或 rename() 系统调⽤）。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271102933.png" alt="image-20230427110230671" style="zoom:80%;" />

> 这样我们就完成了基于⽂件的通⽤服务发现机制，**可以让我们动态地改变 Prometheus 的监控⽬标，⽽不需要重新启动或重新加载 Prometheus 服务**。

## 基于 Consul 的服务发现

> Consul 是由 HashiCorp 开发的⼀个⽀持多数据中⼼的分布式服务发现和键值对存储服务的开源软件，是⼀个通⽤的服务发现和注册中⼼⼯具，被⼤量应⽤于基于微服务的软件架构当中。我们通过api将exporter服务注册到 Consul，然后配置 Prometheus 从 Consul 中发现实例。

> 关于 Consul本身的使⽤可以查看官⽅⽂档 https://learn.hashicorp.com/consul 了解更多。

### 二进制安装配置（二选⼀）

在⻚⾯ https://www.consul.io/downloads 下载符合⾃⼰系统的安装⽂件，⽐如我们这⾥是 Linux 系统，

使⽤下⾯命令下载安装即可：

```sh
wget https://releases.hashicorp.com/consul/1.14.5/consul_1.14.5_linux_amd64.zip
apt install unzip -y
unzip consul_1.14.5_linux_amd64.zip
mv consul /usr/local/bin
consul version
```

启动**consul**：为了查看更多的⽇志信息，我们可以在 dev 模式下运⾏ Consul，如下所示：

```
consul agent -dev -client 0.0.0.0
```

启动命令后⾯使⽤ -client 参数指定了客户端绑定的 IP 地址，默认为 127.0.0.1

### Docker安装Consul（二选⼀）⭐

```sh
docker run -d --name consul -p 8500:8500 consul:1.14.5
docker ps
```

### 访问测试⭐

http://192.168.88.101:8500/ui/dc1/services

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304302024308.png" alt="image-20230430202454102" style="zoom:80%;" />

### 服务注册⭐

#### 使⽤命令⾏注册

```sh
curl -X PUT -d '{"id": "node1","name": "node_exporter","address":"node_exporter","port": 9100,"tags": ["exporter"],"meta": {"job":"node_exporter","instance": "Prometheus服务器"},"checks": [{"http":"http://192.168.88.101:9100/metrics", "interval": "5s"}]}' :8500/v1/agent/service/register
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304302030901.png" alt="image-20230430203051689" style="zoom:80%;" />

把json数据放在⽂件中，使⽤这个json⽂件注册

```sh
mkdir /data/consul
cd /data/consul
cat > node_exporter.json<<"EOF"
   {
     "id": "node2",
     "name": "node_exporter",
     "address": "192.168.88.101",
     "port": 9100,
     "tags": ["exporter"],
     "meta": {
        "job": "node_exporter",
        "instance": "test服务器"
   },
     "checks": [{
     "http": "http://192.168.88.101:9100/metrics",
     "interval": "10s"
   }]
 } 
EOF
```

#### 使⽤json⽂件注册

```sh
curl --request PUT --data @node_exporter.json :8500/v1/agent/service/register
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304302031150.png" alt="image-20230430203152947" style="zoom:80%;" />

除了我们注册的 2 个 demo 服务之外，Consul agent 还会将⾃⼰注册为⼀个名为 consul 的服务，我们可以在浏览器中访问 http://192.168.11.61:8500 查看注册的服务

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301837116.png" alt="image-20230430183708973" style="zoom:80%;" />

在 Consul UI ⻚⾯中可以看到有 consul 和 node_exporter 两个 Service 服务。

### 配置 **Prometheus**

上⾯我们通过 Consul 注册了 2 个 node_exporter 服务，接下来我们将配置 Prometheus 通过 Consul 来⾃动发现 node_porter服务。在 Prometheus 的配置⽂件 prometheus.yml ⽂件中的 scrape_configs 部分添加如下所示的抓取配置：

#### 备份源⽂件

```sh
cd /opt/module/prometheus-2.29.1
# 备份⽂件，变成prometheus.yml.bak
cp -a prometheus.yml{,.bak}
# 修改prometheus.yml
vim prometheus.yml
```

使⽤cat去掉之前的配置,使⽤下⾯的配置

```yml
# 全局配置
global:
  scrape_interval:     15s # 将搜刮间隔设置为每15秒一次。默认是每1分钟一次。
  evaluation_interval: 15s # 每15秒评估一次规则。默认是每1分钟一次。

# Alertmanager 配置
alerting:
  alertmanagers:
  - static_configs:
    - targets: ['alertmanager:9093']

# 报警(触发器)配置
rule_files:
  - "alert.yml"
  - "rules/*.yml"

# 搜刮配置
scrape_configs:
  - job_name: 'prometheus'
    # 覆盖全局默认值，每15秒从该作业中刮取一次目标
    scrape_interval: 15s
    static_configs:
    - targets: ['localhost:9090']
  - job_name: 'alertmanager'
    # 覆盖全局默认值，每15秒从该作业中刮取一次目标
    scrape_interval: 15s
    static_configs:
    - targets: ['alertmanager:9093']

  - job_name: 'consul_exporter'
    consul_sd_configs:
      - server: '192.168.88.101:8500'
        services: []
    relabel_configs:
      - source_labels: [__meta_consul_tags]
        regex: .*exporter.*
        action: keep
      - regex: __meta_consul_service_metadata_(.+)
        action: labelmap
#  Spring Boot 2.x 应用数据采集配置
  - job_name: 'consul_springboot_demo'
    metrics_path: '/actuator/prometheus'
    scrape_interval: 5s
    consul_sd_configs:
      - server: '192.168.88.101:8500'
        services: []
    relabel_configs:
      - source_labels: [__meta_consul_tags]
        regex: .*springboot.*
        action: keep
      - regex: __meta_consul_service_metadata_(.+)
        action: labelmap
#http配置
  - job_name: "consul-blackbox_http"
    metrics_path: /probe
    params:
      module: [http_2xx]
    consul_sd_configs:
      - server: '192.168.88.101:8500'
        services: []
    relabel_configs:
      - source_labels: [__meta_consul_tags]
        regex: .*blackbox_http.*
        action: keep
      - regex: __meta_consul_service_metadata_(.+)
        action: labelmap
      - source_labels: [__meta_consul_service_address]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 192.168.88.101:9115
#tcp检查配置
  - job_name: "consul_blackbox_tcp"
    metrics_path: /probe
    params:
      module: [tcp_connect]
    consul_sd_configs:
      - server: '192.168.88.101:8500'
        services: []
    relabel_configs:
      - source_labels: [__meta_consul_tags]
        regex: .*blackbox_tcp.*
        action: keep
      - regex: __meta_consul_service_metadata_(.+)
        action: labelmap
      - source_labels: [__meta_consul_service_address]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 192.168.88.101:9115

#icmp检查配置
  - job_name: "consul_blackbox_icmp"
    metrics_path: /probe
    params:
      module: [icmp]
    consul_sd_configs:
      - server: '192.168.88.101:8500'
        services: []
    relabel_configs:
      - source_labels: [__meta_consul_tags]
        regex: .*blackbox_icmp.*
        action: keep
      - regex: __meta_consul_service_metadata_(.+)
        action: labelmap
      - source_labels: [__meta_consul_service_address]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 192.168.88.101:9115

#域名检测
  - job_name: consul_domain_exporter
    scrape_interval: 10s
    metrics_path: /probe
    consul_sd_configs:
      - server: '192.168.88.101:8500'
        services: []
    relabel_configs:
      - source_labels: [__meta_consul_tags]
        regex: .*domain.*
        action: keep
      - regex: __meta_consul_service_metadata_(.+)
        action: labelmap
      - source_labels: [__meta_consul_service_address]
        target_label: __param_target
      - target_label: __address__
        replacement: 192.168.88.101:9222
```

通过 consul_sd_configs 配置⽤于⾃动发现的 Consul 服务地址，服务名为[]，我们通过relabel_configs的过滤规则只接收指定的exporter

```sh
curl -X POST :9090/-/reload
```

配置完成后重新启动 Prometheus，然后重新查看 Prometheus ⻚⾯上的 targets ⻚⾯，验证上⾯的配置是否存在：http://192.168.88.101:9090/targets

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301840239.png" alt="image-20230430184012096" style="zoom:67%;" />

### 创建添加脚本

使⽤预先准备好的脚本，⼀次添加多个targets:



```sh
cd /data/consul
cat > api.sh<<"EOF"
curl -X PUT -d '{"id": "node1","name": "node_exporter","address": "node_exporter","port": 9100,"tags": ["exporter"],"meta": {"job": "node_exporter","instance": "Prometheus服务器"},"checks": [{"http": "http://192.168.11.61:9100/metrics", "interval": "5s"}]}'  :8500/v1/agent/service/register

curl --request PUT --data @node_exporter.json :8500/v1/agent/service/register


#nginx
curl -X PUT -d '{"id": "nginx1","name": "nginx_exporter","address": "192.168.11.62","port": 9113,"tags": ["exporter"],"meta": {"job": "nginx_exporter","instance": "test服务器","env":"test"},"checks": [{"http": "http://192.168.11.62:9113/metrics", "interval": "5s"}]}'  :8500/v1/agent/service/register

#rabbitmq
curl -X PUT -d '{"id": "rabbitmq1","name": "rabbitmq_exporter","address": "192.168.11.62","port": 9419,"tags": ["exporter"],"meta": {"job": "rabbitmq_exporter","instance": "test服务器","env":"test"},"checks": [{"http": "http://192.168.11.62:9419/metrics", "interval": "5s"}]}'  :8500/v1/agent/service/register

#redis
curl -X PUT -d '{"id": "redis1","name": "redis_exporter","address": "192.168.11.62","port": 9121,"tags": ["exporter"],"meta": {"job": "redis_exporter","instance": "test服务器","env":"test"},"checks": [{"http": "http://192.168.11.62:9121/metrics", "interval": "5s"}]}'  :8500/v1/agent/service/register

#mongodb
curl -X PUT -d '{"id": "mongodb1","name": "mongodb_exporter","address": "192.168.11.62","port": 9216,"tags": ["exporter"],"meta": {"job": "mongodb_exporter","instance": "test服务器","env":"test"},"checks": [{"http": "http://192.168.11.62:9216/metrics", "interval": "5s"}]}'  :8500/v1/agent/service/register

#mysql
curl -X PUT -d '{"id": "mysql1","name": "mysqld_exporter","address": "192.168.11.62","port": 9104,"tags": ["exporter"],"meta": {"job": "mysqld_exporter","instance": "test服务器","env":"test"},"checks": [{"http": "http://192.168.11.62:9104/metrics", "interval": "5s"}]}'  :8500/v1/agent/service/register

#cadvisor
curl -X PUT -d '{"id": "cadvisor1","name": "cadvisor","address": "cadvisor","port": 8080,"tags": ["exporter"],"meta": {"job": "cadvisor","instance": "Prometheus服务器","env":"test"},"checks": [{"http": "http://192.168.11.61:8080/metrics", "interval": "5s"}]}'  :8500/v1/agent/service/register
curl -X PUT -d '{"id": "cadvisor2","name": "cadvisor","address": "192.168.11.62","port": 8080,"tags": ["exporter"],"meta": {"job": "cadvisor","instance": "test服务器","env":"test"},"checks": [{"http": "http://192.168.11.62:8080/metrics", "interval": "5s"}]}'  :8500/v1/agent/service/register

#springboot
curl -X PUT -d '{"id": "springboot1","name": "springboot","address": "192.168.11.62","port": 8081,"tags": ["springboot"],"meta": {"job": "springboot","instance": "test服务器","env":"test"},"checks": [{"http": "http://192.168.11.62:8081/actuator/prometheus", "interval": "5s"}]}'  :8500/v1/agent/service/register


#process_exporter
curl -X PUT -d '{"id": "process1","name": "process_exporter","address": "192.168.11.62","port": 9256,"tags": ["exporter"],"meta": {"job": "process_exporter","instance": "test服务器","env":"test"},"checks": [{"http": "http://192.168.11.62:9256/metrics", "interval": "5s"}]}'  :8500/v1/agent/service/register

#http
curl -X PUT -d '{"id": "http1","name": "blackbox_http","address": "https://www.jd.com","tags": ["blackbox_http"],"checks": [{"http": "http://192.168.11.62:9115", "interval": "5s"}]}'  :8500/v1/agent/service/register

#tcp
curl -X PUT -d '{"id": "tcp1","name": "blackbox_tcp","address": "192.168.11.61:9090","tags": ["blackbox_tcp"],"checks": [{"http": "http://192.168.11.62:9115", "interval": "5s"}]}'  :8500/v1/agent/service/register

#icmp
curl -X PUT -d '{"id": "icmp1","name": "blackbox_icmp","address": "192.168.11.62","tags": ["blackbox_icmp"],"checks": [{"http": "http://192.168.11.62:9115", "interval": "5s"}]}'  :8500/v1/agent/service/register


#domin
curl -X PUT -d '{"id": "domain1","name": "domain_exporter","address": "baidu.com","tags": ["domain"],"checks": [{"http": "http://192.168.11.62:9222", "interval": "5s"}]}'  :8500/v1/agent/service/register
EOF
```

```
bash api.sh
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304302046520.png" alt="image-20230430204601376" style="zoom:67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304302046363.png" alt="image-20230430204617137" style="zoom:67%;" />

### **consul**删除服务

```sh
# 注意ID是上面的sh文件对应的id，不是name
curl --request PUT http://127.0.0.1:8500/v1/agent/service/deregister/ID
curl --request PUT http://127.0.0.1:8500/v1/agent/service/deregister/nginx1
curl --request PUT http://127.0.0.1:8500/v1/agent/service/deregister/rabbitmq1
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304302049199.png" alt="image-20230430204923053" style="zoom:67%;" />

### 存在问题

consul健康检查失败如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301841335.png" alt="image-20230430184127205" style="zoom:80%;" />

原因：是因为并没有把8080映射出来（下图显示），导致consul监控检查不通过，所以报错。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301841564.png" alt="image-20230430184144453" style="zoom:80%;" />

解决：修改 docker-compose.yaml ⽂件把8080端⼝映射出来，就好了，如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301842245.png" alt="image-20230430184207075" style="zoom: 67%;" />

修改完成后，执⾏命令，docker-compose up -d

### ConsulManager

> 可以通过它进行可视化管理Consul，无需写命令了

https://gitee.com/starsl/ConsulManager

1、ConsulManager需要依赖 Consul ，请先完成Consul的部署。（暂时最⾼⽀持Consul v1.14.5）[部署说明](https://github.com/starsliao/ConsulManager/blob/main/docs/Consul%E9%83%A8%E7%BD%B2%E8%AF%B4%E6%98%8E.md)

2、使⽤ docker-compose 来部署ConsulManager下载： （仓库根⽬录下 docker-compose.yml ）

```
wget https://starsl.cn/static/img/docker-compose.yml 
vim docker-compose.yml
```

修改3个环境变量：

**consul_token** ：consul的登录token（[如何获取](https://github.com/starsliao/ConsulManager/blob/main/docs/Consul%E9%83%A8%E7%BD%B2%E8%AF%B4%E6%98%8E.md#%E8%8E%B7%E5%8F%96%E7%99%BB%E5%BD%95token%E8%AE%B0%E5%BD%95secretid%E5%8D%B3%E4%B8%BAconsul%E7%99%BB%E5%BD%95%E7%9A%84token)？）,当然也可以不获取token，这样consul使⽤⽆密码登录（不安全）。

**consul_url** ：consul的URL(http开头，/v1要保留)

**admin_passwd** ：登录ConsulManager Web的admin密码启动： docker-compose pull && docker-compose up -d

访问： http://{IP}:1026 ，使⽤配置的变量 **admin_passwd** 登录安装使⽤中遇到问题，请参考：[**FAQ**](https://github.com/starsliao/ConsulManager/blob/main/docs/FAQ.md)

## Relabeling机制

> 前⾯讲了Prometheus的⼏种服务发现机制。通过服务发现的⽅式，可以在不重启Prometheus服务的情况下动态的发现需要监控的Target实例信息。

> 基于consul服务发现。 如何加lable标签？Prometheus能够按照某些规则（⽐如标签）从服务发现注册中⼼返回的Target实例中有选择性的采集某些Exporter实例的监控数据。接下来，我们将学习如何通过Prometheus强⼤的Relabel机制来实现以上这些具体的⽬标。

### Relabeling机制

#### 什么是Relabeling机制？

> 在采集样本数据之前，对Target实例的标签(Metadata)进⾏重写的机制在Prometheus被称为Relabeling。Relabeling最基本的应⽤场景就是基于Target实例中包含的metadata标签，动态的添加或者覆盖标签。在采集任务设置中通过relabel_configs来添加⾃定义的Relabeling过程。如下图

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301846692.png" alt="image-20230430184608565" style="zoom:80%;" />

> 注：细⼼的同学可能发现了，在之前的课程中⿊盒、域名的监控也配置过relabel_configs因为要对Metadata标签进⾏重写，所以我们先来看下Metadata标签

#### 默认Metadata标签

> 在Prometheus所有的Target实例中，都包含⼀些默认的Metadata标签信息。可以通过Prometheus UI的Targets⻚⾯中查看这些实例的Metadata标签的内容：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301847218.png" alt="image-20230430184701080" style="zoom:80%;" />

默认情况下，当Prometheus加载Target实例完成后，这些Target时候都会包含⼀些默认的标签：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301847048.png" alt="image-20230430184719920" style="zoom: 67%;" />

不过这⾥有⼀些例外，例如，我们会发现所有通过Prometheus采集的样本数据中都会包含⼀个名为instance的标签，该标签的内容对应到Target实例的 __address__ 。 这⾥实际上是发⽣了⼀次标签的重写处理。

#### **Consul**动态发现的**metadata**标签

通过Consul动态发现的服务实例还会包含以下Metadata标签信息：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301848784.png" alt="image-20230430184800660" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301848169.png" alt="image-20230430184810038" style="zoom:80%;" />

如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301848527.png" alt="image-20230430184831359" style="zoom:80%;" />

### relabel_configs配置

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301849651.png" alt="image-20230430184909518" style="zoom: 67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301849622.png" alt="image-20230430184922495" style="zoom: 67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304301849284.png" style="zoom:80%;" />

relabel_configs的配置我们已经知道了是对源数据重写的配置，接下来我们就来看具体案例

#### 替换标签值

可以通过 replace 这个操作来完成，如果没有指定 action 字段，则默认就是 replace 。

注：源数据需要加 [] 以便区分。⽬标数据不需要加。

案例1

```
relabel_configs:
 - source_labels: [__meta_consul_service_address]
 target_label: __param_target
 - source_labels: [__param_target]
 target_label: instance
 - target_label: __address__
 replacement: 192.168.11.62:9115
```

```
源数据：__meta_consul_service_address="192.168.11.62"
会变成：target="192.168.11.62",instance="192.168.11.62",endpoint="192.168.11.62:9115/prod"
```

案例2

从Node Exporter实例采集上来的样本数据如下所示：

```
node_load1{instance="test服务器", job="node_exporter"} 0.04
```

我们希望能有⼀个额外的标签dc，可以表示该样本所属的数据中⼼：

```
node_load1{instance="test服务器", job="node_exporter",dc="dc1"} 0.04
```

relabel_config配置：

```
relabel_configs:
  - source_labels: ["__meta_consul_dc"]
    target_label: "dc"

源数据：__meta_consul_dc="dc1"会变成：dc="dc1"
```

#### 保留或丢弃对象

通过 keep 或 drop 这两个动作可以来完成

案例1

```yml
 relabel_configs: 
 - source_labels: [__meta_consul_tags]
 regex: .*exporter.*
 action: keep
 
源数据为：__meta_consul_tags=",exporter," 会保留。如果action: drop就相反
源数据为：__meta_consul_tags=",domain," 会丢弃，如果action: drop就相反
```

#### 标签集映射

把源标签的值映射到⼀组新的标签中去，使⽤ labelmap 这个动作完成

```yml
 relabel_configs: 
 - regex: __meta_consul_service_metadata_(.+)
 action: labelmap
 
源数据为：__meta_consul_service_metadata_job="test"会变成: job="test"
```

#### 保留或删除标签

使⽤ labelkeep 和 labeldrop 这两个操作

```yml
 relabel_configs:
 - regex: job
 action: labeldrop
 
数据：probe_success{instance="192.168.11.61:9090", job="consul_blackbox_tcp"}
变成：probe_success{instance="192.168.11.61:9090"} action: labelkeep 刚好相反
```

# 高可用

## thanos

> Prometheus在小规模的部署中，完全不需要依赖其他组件就可以达到监控的目的。但在应对大规模、大数据量的集群时，就存在缺少集群、数据可靠性保障的支持。Prometheus虽然支持联邦部署模式，但这个架构还是会有其他问题，如数据会被重复储存在两个地方，还有被拉取的Prometheus机器有可能发生超时现象。另外，监控数据分散在多台Prometheus监控节点，在变动或者长期存储时依赖本地磁盘，本地磁盘一般不是高可用的存储，监控数据就变得没有可靠性保障。为了解决上述问题，产生了多种解决方案，Thanos方案是最成熟、广泛使用的。

### thanos概述

> [Thanos](https://thanos.io/)是一个基于 Prometheus 实现的监控方案，其主要设计目的是解决原生 Prometheus 上的痛点，并且做进一步的提升，主要的特性有：**全局查询，高可用，动态拓展，长期存储**。

### thanos架构

Thanos 主要由如下几个特定功能的组件组成：

> 边车组件（Sidecar）：连接到 Prometheus，并把 Prometheus 暴露给查询网关（Querier/Query），以供实时查询，并且可以上传 Prometheus 数据到云存储，以供长期保存（和Receiver二选一）

> 查询网关（Querier）：实现 Prometheus API 以聚合来自底层组件（如边车组件 Sidecar，或是存储网关 Store Gateway）的数据
>
> 存储网关（Store Gateway）：将云存储中的数据内容暴露出来（可选）
>
> 压缩器（Compactor）：将云存储中的数据进行压缩和下采样和保留（可选）接收器（Receiver）：从 Prometheus 的远程写入 WAL 接收数据，将其暴露出去或者上传到云存储（和Sidecar二选一）

> 规则组件（Ruler）：根据 Thanos 中的数据评估记录和警报规则（可选）
>
> 查询前端：实现 Prometheus 的 API，将其代理给 Query，同时缓存响应（可选）
>
> 因为用到thanos Sidecar和thanos Querier接下来我们就来安装。

## Prometheus高可用

### 基本安装

> 三台机器分别安装docker和docker-compose，三台机器分别是node1,node2,node3，就使用最上面的安装即可

> node1和node2安装prometheus，就使用上面的docker版本安装即可

> 因为Thanos Querier需要调用Prometheus API 来查询数据，所以prometheus需要开启api功能，就在Gitee拉取的docker-compose.yml文件里，去掉注释即可，node1和node2都要配置

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011345763.png" alt="image-20230501134553675" style="zoom:67%;" />

```sh
cd /data/docker-prometheus
# 重新启动
docker-compose up -d
```

### Thanos安装

> node1和node2都要配置

```sh
cd /data/docker-prometheus
vim prometheus/prometheus.yml
```

增加如下配置：

```yml
global:
  # 与外部系统通信时对时间序列或者告警信息添加的标签
  external_labels:
    cluster: 'linge'
```

完成后重置prometheus

```
curl -X POST :9090/-/reload
```

安装Thanos Sidecar和 Thanos Querier

```sh
cd /data/docker-prometheus/
cp docker-compose.yaml{,.bak1}
vim docker-compose.yaml
```

```yml
  thanos-sidecar:
    image: thanosio/thanos:v0.31.0
    container_name: thanos-sidecar
    restart: always
    command:
      - sidecar
      - --http-address=0.0.0.0:19191
      - --grpc-address=0.0.0.0:19090
      - --tsdb.path=prometheus_data
      - --prometheus.url=http://192.168.88.101:9090 #192.168.11.60 node1上使用这个配置
      # - --prometheus.url=http://192.168.88.102:9090 #192.168.11.61 node2上使用这个配置
    ports:
      - '19090:19090'
      - '19191:19191'
  
  thanos-query:
    image: thanosio/thanos:v0.31.0
    container_name: thanos-query
    restart: always
    command:
      - query
      - --http-address=0.0.0.0:19192
      - --grpc-address=0.0.0.0:19092
      - --query.replica-label=prometheus_replica
      - --store=192.168.88.101:19090
      - --store=192.168.88.102:19090
    ports:
      - '19192:19192'
      - '19092:19092'
```

访问测试

http://192.168.88.101:19192/stores

http://192.168.88.102:19192/stores

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011410416.png" alt="image-20230501141036291" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011411329.png" alt="image-20230501141104209" style="zoom:80%;" />



### Grafana修改数据源

http://192.168.88.101:3000/ 用户admin 密码password

url地址填写： http://192.168.88.101:19192

http://192.168.88.102:3000/ 用户admin 密码password

url地址填写： http://192.168.88.102:19192

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011413796.png" alt="image-20230501141358654" style="zoom:67%;" />

添加dashboard： 1860，至此prometheus的高可用就完成了

### Thanos远程存储（可选）

默认prometheus的数据存储受 --storage.tsdb.retention.time=30d 控制，可以使用Thanos把prometheus的数据永久保存

https://thanos.io/tip/thanos/storage.md/

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011415180.png" alt="image-20230501141508050" style="zoom:67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011415979.png" alt="image-20230501141521859" style="zoom:80%;" />

> 要在生产环境使用最好使用 Stable 状态的，比如 S3 或者兼容 S3 的服务，比如 Ceph、Minio 等等。对于国内用户当然最方便的还是直接使用阿里云 OSS 或者腾讯云 COS 这样的服务，但是很多时候可能我们的服务并不是跑在公有云上面的，所以这里我们用 Minio 来部署一个兼容 S3 协议的对象存储服务。

thanos.yaml配置，minio配置

```
type: s3
  config:
    bucket: ""
    endpoint: ip:9000
    access_key: ""
    secret_key: ""
    insecure: true
```

阿里云oss配置：thanos.yaml

```tml
type: ALIYUNOSS
  config:
    endpoint: ""
    bucket: ""
    access_key_id: ""
    access_key_secret: ""
```

**thanos-sidecar配置远程存储**

Thanos远程存储是通过配置Sidecar读取Prometheus收集的数据，并写入到远程的对象存储中。所以在Sidecar中增加如下配置：注：配置远程存储后，需通过thanos Store Gateway来查看远程存储数据

```sh
--objstore.config-file=/etc/thanos/thanos.yaml
```

## alertmanager高可用

在上面我们已经在prometheus01和prometheus02上都安装了alertmanager。一共部署了2套alertmanager，那是不是就已经有高可用了？我们先来测试下：

模拟发送告警信息，2台机器上都执行，直接粘贴到命令行执行即可

```sh
#!/usr/bin/env bash

alerts1='[
    {
        "labels": {
            "alertname": "DiskRunningFull",
            "dev": "sda1",
            "instance": "example1",
            "severity": "critical"
        },
        "annotations": {
            "description": "The disk sda1 is running full",
            "summary": "please check the instance example1"
        }
    }
]'
curl -XPOST -d "$alerts1" :9093/api/v1/alerts
```

http://192.168.88.101:9093/#/alerts

http://192.168.88.102:9093/#/alerts

> 同一台告警信息，发送了2次。由于ALertmanager之间不存在并不了解彼此的存在，因此则会出现告警通知被不同的Alertmanager重复，发送多次的问题。

> 4为了解决这一问题，Alertmanager在集群配置中引入了Gossip机制，Gossip机制为多个Alertmanager之间提供了信息传递的机制。确保及时在多个Alertmanager分别接收到相同告警信息的情况下，也只有一个告警通知被发送给Receiver。

node1服务器

```sh
cd /data/docker-prometheus
vim docker-compose.yaml
```

增加如下配置，注意是在原alertmanager配置里增加

```yml
  alertmanager:
    command:
      - '--log.level=debug'
      - '--cluster.listen-address=0.0.0.0:8001'
    ports:
      - '8001:8001'
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011453957.png" alt="image-20230501145342841" style="zoom:80%;" />

如果是二进制安装的alertmanager，只需要增加一行配置: --cluster.listen-address=0.0.0.0:8001,应用配置

```
docker-compose up -d
```

node2服务器

```sh
cd /data/docker-prometheus
vim docker-compose.yaml
```

增加如下配置

```yml
  alertmanager:
    command:
      - '--log.level=debug'
      - '--cluster.listen-address=0.0.0.0:8002'
      - '--cluster.peer=192.168.88.101:8001'
    ports:
      - '8002:8002'
```

如果是二进制安装的alertmanager，只需要增加2行配置: --cluster.listen-address=0.0.0.0:8001 和 --

cluster.peer=192.168.11.60:8001

```
docker-compose up -d
```

http://192.168.88.101:9093/#/status

http://192.168.88.102:9093/#/status

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011429348.png" alt="image-20230501142954231" style="zoom:67%;" />

当集群配置完成后，会自带Gossip机制，接下来我们在测试下，同一台告警信息只发送了一次

## Prometheus和alertmanager集群整合

> 由于实现了Gossip机制，在Prometheus和Alertmanager实例之间不要使用任何负载均衡，需要确保Prometheus将告警发送到所有的Alertmanager实例中2台prometheus修改配置如下，2台都要操作。

```yml
# Alertmanager 配置
alerting:
  alertmanagers:
  - static_configs:
    - targets: ['192.168.88.101:9093', '192.168.88.102:9093']
```

```sh
curl -X POST :9090/-/reload
# 再次测试
docker stop node-exporter
```

## 停机测试

把prometheus01服务器关闭，打开thanos-query检查，如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011302652.png" alt="image-20230501130244553" style="zoom:80%;" />

grafana检查，图形都是正常的。告警通知也正常

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305011303470.png" alt="image-20230501130302336" style="zoom:80%;" />

> 通过安装Thanos Sidecar和Thanos Querier完成了prometheus的高可用。通过alertmanager的集群配置（自带Gossip机制）来解决告警重复发送问题。每次修改prometheus配置，添加grafana的Dashboard图形都需要在2台机器上都要操作。可以使用consul，dns等自动发现功能来减少配置带来的麻烦。









































