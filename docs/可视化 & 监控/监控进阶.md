



# 应用安装

## rabbitmq、nginx、mongo、redis

```sh
mkdir /data/docker-compose -p
cd /data/docker-compose
```

```yml
version: '3'
services:
  redis:
    image: redis:5
    container_name: redis
    command: redis-server --requirepass 123456 --maxmemory 512mb
    restart: always
    volumes:
      - /data/redis/data:/data
    ports:
      - 6379:6379

  nginx:
    image: nginx:1.21.6
    container_name: nginx
    restart: always
    volumes:
      - /data/nginx/conf.d:/etc/nginx/conf.d
      - /data/nginx/html:/usr/share/nginx/html
      - /data/nginx/log:/var/log/nginx
    ports:
      - 80:80

  rabbitmq:
    image: rabbitmq:3.7.15-management
    container_name: rabbitmq
    restart: always
    volumes:
      - /data/rabbitmq/data:/var/lib/rabbitmq
      - /data/rabbitmq/log:/var/log/rabbitmq
    ports:
      - 5672:5672
      - 15672:15672

  mongo:
    image: mongo:4.2.5
    container_name: mongo
    restart: always
    volumes:
      - /data/mongo/db:/data/db
    ports:
      - 27017:27017
    command: [--auth]
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: 123456
```

```sh
# 运⾏,STATUS列全部为up 为正常
docker-compose up -d
docker ps
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271548761.png" alt="image-20230427154851699" style="zoom:80%;" />

## MySQL

为了快速测试，我使⽤docker-compose安装mysql，当然也可以⾃⾏安装

```sh
mkdir -p /data/mysql 
cd /data/mysql
vim docker-compose.yml
```

```yml
version: '3.1'
services:
  db:
    image: mysql:8.0.23 # 指定MySQL 8.0.26版本
    restart: always
    container_name: mysql
    environment:
      TZ: Asia/Shanghai
      LANG: en_US.UTF-8
      MYSQL_ROOT_PASSWORD: 123456
      command:
        --default-authentication-plugin=mysql_native_password
        --character-set-server=utf8mb4
        --collation-server=utf8mb4_general_ci
        --lower_case_table_names=1
        --performance_schema=1
        --sql-mode=""
        --skip-log-bin
    volumes:
      - /data/mysql/conf:/etc/mysql/conf.d #配置⽂件挂载
      - /data/mysql/data:/var/lib/mysql #数据⽂件挂载
    ports:
      - 3306:3306
```

```sh
# 运⾏
docker-compose up -d
# 检查,STATUS列全部为up 为正常
docker ps
```

```sh
# 登陆mysql
docker exec -it mysql mysql -uroot -p
# 输⼊密码：123456，创建
CREATE USER 'exporter'@'%' IDENTIFIED BY 'password' WITH MAX_USER_CONNECTIONS 3;
GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO 'exporter'@'%';
# 验证
docker exec -it mysql mysql -uexporter -p
```

## 刷新配置

```sh
# 检查规则写的是否正确
cd /opt/module/prometheus-2.29.1
./promtool check rules rules/linux.yml
curl -X POST http://node1:9090/-/reload
curl -X POST http://node1:9093/-/reload 
```



# Linux

> 使用`node_explorer`可以暴露Linux系统的指标信息，然后Prometheus就可以通过定时扫描的方式获取并存储指标信息了。下载`node_explorer`的安装包，下载地址：https://prometheus.io/download/#node_exporter

## 二进制安装

这次我们直接把`node_explorer`安装到Linux服务器上（如果使用Docker容器安装，监控的会是Docker容器的指标信息）,将下载的安装包解压到指定目录，并修改文件夹名称：

### 下载解压改名

```sh
# 下载，解压，改名
wget https://github.com/prometheus/node_exporter/releases/download/v1.5.0/node_exporter-1.5.0.linux-amd64.tar.gz
tar -zxvf node_exporter-1.5.0.linux-amd64.tar.gz -C /opt/module
mv node_exporter-1.5.0.linux-amd64 node_exporter1.5.0
```

进入解压目录，使用如下命令运行`node_explorer`，服务将运行在`9100`端口上；

```sh
cd node_exporter
./node_exporter >log.file 2>&1 &
```

### 设置为开机自启

```sh
sudo vim /usr/lib/systemd/system/node_exporter.service
```

```sh
[Unit]
Description=node_export
Documentation=https://github.com/prometheus/node_exporter
After=network.target
[Service]
Type=simple
User=root
ExecStart= /opt/module/node_exporter1.5.0/node_exporter
Restart=on-failure
[Install]
WantedBy=multi-user.target
```

### 启动运行

```sh
systemctl daemon-reload
# 设为开机自启动（所有机器都执行）
sudo systemctl enable node_exporter.service
sudo systemctl start node_exporter.service
sudo systemctl stop node_exporter.service
```

使用访问获取指标信息接口，获取到信息表示运行成功；

访问：http://192.168.22.130:9100/metrics

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209090942448.png" alt="image-20220909094212400" style="zoom:80%;" />

## Docker安装⭐

```sh
mkdir /data/node_exporter -p
cd /data/node_exporter
```

```yml
cat > docker-compose.yaml <<"EOF"
version: '3.3'
services:
  node_exporter:
    image: prom/node-exporter:v1.5.0
    container_name: node-exporter
    restart: always
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc|rootfs/var/lib/docker)($$|/)'
    ports:
      - '9100:9100'
EOF
```

```
docker-compose up -d
docker ps
docker logs -f node-exporter
```

http://192.168.88.101:9100/metrics

## prometheus配置

接下来修改Prometheus的配置文件`prometheus.yml`，创建一个任务定时扫描`node_explorer`暴露的指标信息；上面配置过了，注意：要求prometheus是启动的

```yml
scrape_configs:
  - job_name: "prometheus"
    static_configs:
      - targets: ["localhost:9090"]
  - job_name: 'pushgateway'
    static_configs:
      - targets: ['localhost:9091']
  - job_name: 'linux监控' # targets可以监控多个目标，就算目标不存活也无所谓
    static_configs:
      - targets: ['node1:9100', 'node2:9100', 'node3:9100']
```

```sh
# 检查配置文件是否有问题
./promtool check config prometheus.yml
# 热更新配置文件
curl -X POST http://node1:9090/-/reload
```

prometheus：http://node1:9090

grafana：http://node1:3000

## 常用监控指标

### cpu采集

```sh
node_cpu_seconds_total
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271505538.png" alt="image-20230427150504480" style="zoom:80%;" />

### 内存采集

```sh
# /proc/meminfo⽂件
node_memory_
```

| 名称                           | 含义               | 备注                                        |
| ------------------------------ | ------------------ | ------------------------------------------- |
| node_memory_MemTotal_bytes     | 内存总大小         | 单位字节，/1024/1024=MB，/1024/1024/1024=GB |
| node_memory_MemAvailable_bytes | 空闲可使用内存大小 |                                             |
| node_memory_MemFree_bytes      | 空闲物理内存大小   |                                             |
| node_memory_SwapFree_bytes     | swap内存空闲大小   |                                             |
| node_memory_SwapTotal_bytes    | swap内存总大小     |                                             |

### 磁盘采集

```sh
node_disk_
```

### ⽂件系统采集

```
node_filesystem_
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271510056.png" alt="image-20230427151048992" style="zoom:80%;" />

### ⽹络采集

```sh
node_network_
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271511738.png" alt="image-20230427151112689" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271511113.png" alt="image-20230427151123065" style="zoom:80%;" />

## 触发器配置

prometheus.yml

```yml
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - localhost:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  - "rules/*.yml"
```

rules/linux.yml

```yml
groups:
- name: node-exporter
  rules:
  - alert: HostOutOfMemory
    expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "主机内存不足，实例: {{ $labels.instance }}"
      description: "内存可用率 < 10%，当前值：{{ $value }}"

  - alert: HostMemoryUnderMemoryPressure
    expr: rate(node_vmstat_pgmajfault[1m]) > 1000
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "内存压力不足，实例: {{ $labels.instance }}"
      description: "节点内存压力大。重大页面错误率高，当前值为：{{ $value }}"

  - alert: HostUnusualNetworkThroughputIn
    expr: sum by (instance) (rate(node_network_receive_bytes_total[2m])) / 1024 / 1024 > 100
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "异常流入网络吞吐量，实例: {{ $labels.instance }}"
      description: "网络流入流量 > 100 MB/s，当前值：{{ $value }}"

  - alert: HostUnusualNetworkThroughputOut
    expr: sum by (instance) (rate(node_network_transmit_bytes_total[2m])) / 1024 / 1024 > 100
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "异常流出网络吞吐量，实例: {{ $labels.instance }}"
      description: "网络流出流量 > 100 MB/s，当前值为：{{ $value }}"

  - alert: HostUnusualDiskReadRate
    expr: sum by (instance) (rate(node_disk_read_bytes_total[2m])) / 1024 / 1024 > 50
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "异常磁盘读取，实例: {{ $labels.instance }}"
      description: "磁盘读取 > 50 MB/s，当前值：{{ $value }}"

  - alert: HostUnusualDiskWriteRate
    expr: sum by (instance) (rate(node_disk_written_bytes_total[2m])) / 1024 / 1024 > 50
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "异常磁盘写入，实例: {{ $labels.instance }}"
      description: "磁盘写入 > 50 MB/s，当前值：{{ $value }}"

  - alert: HostOutOfDiskSpace
    expr: (node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) node_filesystem_readonly == 0
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "磁盘空间不足告警，实例: {{ $labels.instance }}"
      description: "剩余磁盘空间 < 10%，当前值：{{ $value }}"
  - alert: HostDiskWillFillIn24Hours
    expr: (node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and on (instance, device, mountpoint) predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs"}[1h], 24 * 3600) < 0 and on (instance, device, mountpoint) node_filesystem_readonly == 0
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "磁盘空间将在24小时内耗尽，实例: {{ $labels.instance }}"
      description: "以当前写入速率预计磁盘空间将在24小时内耗尽，当前值：{{ $value }}"

  - alert: HostOutOfInodes
    expr: node_filesystem_files_free{mountpoint="/"}/node_filesystem_files{mountpoint="/"} * 100 < 10 and on (instance, device, mountpoint) node_filesystem_readonly{mountpoint="/"} == 0
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "磁盘Inodes不足，实例: {{ $labels.instance }}"
      description: "剩余磁盘inodes < 10%，当前值：{{ $value }}"

  - alert: HostUnusualDiskReadLatency
    expr: rate(node_disk_read_time_seconds_total[1m])/rate(node_disk_reads_completed_total[1m]) > 0.1 and rate(node_disk_reads_completed_total[1m]) > 0
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "异常磁盘读取延迟，实例: {{ $labels.instance }}"
      description: "磁盘读取延迟 > 100ms，当前值：{{ $value }}"

  - alert: HostUnusualDiskWriteLatency
    expr: rate(node_disk_write_time_seconds_total[1m])/rate(node_disk_writes_completed_total[1m]) > 0.1 and rate(node_disk_writes_completed_total[1m]) > 0
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "异常磁盘写入延迟，实例: {{ $labels.instance }}"
      description: "磁盘写入延迟 > 100ms，当前值：{{ $value }}"

  - alert: high_load
    expr: node_load1 > 4
    for: 2m
    labels:
      severity: page
    annotations:
      summary: "CPU1分钟负载过高，实例: {{ $labels.instance }}"
      description: "CPU1分钟负载 > 4，已经持续2分钟。当前值为：{{ $value }}"

  - alert: HostCpuIsUnderUtilized
    expr: 100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[2m])) * 100) > 80
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: "CPU负载高，实例: {{ $labels.instance }}"
      description: "cpu负载> 80%，当前值：{{ $value }}"
  - alert: HostCpuStealNoisyNeighbor
    expr: avg by(instance) (rate(node_cpu_seconds_total{mode="steal"}[5m])) * 100 > 10
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: "CPU窃取率异常,实例:{{ $labels.instance }}"
      description: "CPU 窃取率 > 10%。 嘈杂的邻居正在扼杀 VM 性能，或者 Spot 实例可能失去信⽤，当前值：{{ $value }}"

  - alert: HostSwapIsFillingUp
    expr: (1 - (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes)) * 100 > 80
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "磁盘swap空间使⽤率异常,实例:{{ $labels.instance }}"
      description: "磁盘swap空间使⽤率>80%"

  - alert: HostNetworkReceiveErrors
    expr: rate(node_network_receive_errs_total[2m]) / rate(node_network_receive_packets_total[2m]) > 0.01
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "异常⽹络接收错误,实例:{{ $labels.instance }}"
      description: "⽹卡{{ $labels.device }}在过去2分钟接收{{ $value }}个错误"

  - alert: HostNetworkTransmitErrors
    expr: rate(node_network_transmit_errs_total[2m]) /   rate(node_network_transmit_packets_total[2m]) > 0.01
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "异常⽹络传输错误,实例:{{ $labels.instance }}"
      description: "⽹卡{{ $labels.device }}在过去2分钟传输{{ $value }}个错误"

  - alert: HostNetworkInterfaceSaturated
    expr: (rate(node_network_receive_bytes_total{device!~"^tap.*"}[1m]) +   rate(node_network_transmit_bytes_total{device!~"^tap.*"}[1m])) /   node_network_speed_bytes{device!~"^tap.*"} > 0.8 < 10000
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: "异常⽹络接⼝饱和,实例:{{ $labels.instance }}"
      description: "⽹卡{{ $labels.device }}正在超载，当前值{{ $value }}"

  - alert: HostConntrackLimit
    expr: node_nf_conntrack_entries / node_nf_conntrack_entries_limit > 0.8
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "异常连接数,实例:{{ $labels.instance }}"
      description: "连接数过⼤，当前连接数：{{ $value }}"

  - alert: HostClockSkew
    expr: (node_timex_offset_seconds > 0.05 and deriv(node_timex_offset_seconds[5m]) >= 0) or   (node_timex_offset_seconds < -0.05 and deriv(node_timex_offset_seconds[5m]) <= 0)
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "异常时钟偏差,实例:{{ $labels.instance }}"
      description: "检测到时钟偏差，时钟不同步。值为：{{ $value }}"
  - alert: HostClockNotSynchronising
    expr: min_over_time(node_timex_sync_status[1m]) == 0 and node_timex_maxerror_seconds >= 16
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "时钟不同步,实例:{{ $labels.instance }}"
      description: "时钟不同步"
```

```sh
# 检查规则写的是否正确
./promtool check rules rules/linux.yml
# 热更新配置文件
curl -X POST http://node1:9090/-/reload
```



<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271519334.png" alt="image-20230427151905258" style="zoom:80%;" />

## DashBoard

可以去Grafana的仪表盘市场下载一个Dashboard，市场地址：https://grafana.com/grafana/dashboards

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209082159052.png" alt="image-20220908215906930" style="zoom:80%;" />

这里选择了`Node Exporter Full`这个仪表盘，记住它的ID：https://grafana.com/grafana/dashboards/1860

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205181605390.png" alt="image-20220518160519337" style="zoom:80%;" />

选择导入Dashboard并输入ID，最后点击`Load`即可；

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205181605777.png" alt="image-20220518160530729" style="zoom:80%;" />

- 选择数据源为Prometheus，最后点击`Import`；

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205181605008.png" alt="image-20220518160543962" style="zoom:80%;" />

导入成功后就可以在Grafana中看到实时监控信息了，是不是够炫酷！

注意：`如果没数据，选择右上角的时间，Last  5 minutes，选择越小越容易显示数据`

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205181606337.png" alt="image-20220518160602272" style="zoom:80%;" />

如果之前就导入成功了，那么就直接进去看把

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271540030.png" alt="image-20230427154000949" style="zoom:80%;" />



# MySQL

下载地址：https://github.com/prometheus/mysqld_exporter/releases

## Docker安装⭐

**docker-compose**运⾏

```sh
mkdir /data/mysqld_exporter -p
cd /data/mysqld_exporter
```

> 注意：必须使用mysql新用户连接，不能使用root连接，root连接获取不到数据

```yml
version: '3.3'
services:
  mysqld-exporter:
    image: prom/mysqld-exporter
    container_name: mysqld-exporter
    restart: always
    command:
      - '--collect.info_schema.processlist'
      - '--collect.info_schema.innodb_metrics'
      - '--collect.info_schema.tablestats'
      - '--collect.info_schema.tables'
      - '--collect.info_schema.userstats'
      - '--collect.engine_innodb_status'
    environment:
      - DATA_SOURCE_NAME=exporter:password@(192.168.88.101:3306)/
    ports:
      - 9104:9104
```

```sh
# 启动和检查
docker-compose up -d
docker ps
docker exec -it  mysql mysql  -uroot -h192.168.31.70 -P3306 -p
```

访问：http://192.168.88.101:9104/metrics

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304272131379.png" alt="image-20230427213153290" style="zoom:80%;" />

## Prometheus配置

配置prometheus去采集（拉取）mysql_exporter的监控样本数据

```sh
cd /data/docker-prometheus

# 在scrape_configs(搜刮配置):下⾯增加如下配置：
cat >> prometheus/prometheus.yml << "EOF"
  - job_name: 'mysqld_exporter'
    static_configs:
    - targets: ['192.168.88.101:9104']
      labels:
        instance: test服务器
EOF
```

```sh
# 重新加载配置
curl -X POST :9090/-/reload
```

## 常⽤监控指标

```sh
mysql_up # 服务器是否在线
mysql_global_status_uptime # 运⾏时⻓，单位 s
delta(mysql_global_status_bytes_received[1m]) # ⽹络接收的 bytes
delta(mysql_global_status_bytes_sent[1m]) # ⽹络发送的 bytes
mysql_global_status_threads_connected # 当前的客户端连接数
mysql_global_variables_max_connections # 允许的最⼤连接数
mysql_global_status_threads_running # 正在执⾏命令的客户端连接数，即⾮ sleep 状态
delta(mysql_global_status_aborted_connects[1m]) # 客户端建⽴连接失败的连接数，⽐如登录失败
delta(mysql_global_status_aborted_clients[1m]) # 客户端连接之后，未正常关闭的连接数
delta(mysql_global_status_commands_total{command="xx"}[1m]) > 0 # 每分钟各种命令的次数
delta(mysql_global_status_handlers_total{handler="xx"}[1m]) > 0 # 每分钟各种操作的次数
delta(mysql_global_status_handlers_total{handler="commit"}[1m]) > 0 # 每分钟 commit 的次数
delta(mysql_global_status_table_locks_immediate[1m]) # 请求获取锁，且⽴即获得的请求数
delta(mysql_global_status_table_locks_waited[1m]) # 请求获取锁，但需要等待的请求数。该值越少越好
delta(mysql_global_status_queries[1m]) # 每分钟的查询数
delta(mysql_global_status_slow_queries[1m]) # 慢查询数。如果未启⽤慢查询⽇志，则为 0
mysql_global_status_innodb_page_size # innodb 数据⻚的⼤⼩，单位 bytes
mysql_global_variables_innodb_buffer_pool_size # innodb_buffer_pool 的限制体积
mysql_global_status_buffer_pool_pages{state="data"} # 包含数据的数据⻚数，包括洁⻚、脏⻚
mysql_global_status_buffer_pool_dirty_pages # 脏⻚数
```

## 触发器配置

```yml
# 报警(触发器)配置
rule_files:
  - "alert.yml" 
  - "rules/*.yml"
```

添加**mysql**触发器（告警规则）

```sh
cd /data/docker-prometheus
```

使⽤cat创建⽂件

```yml
groups:
- name: MySQL
  rules:
  - alert: MysqlDown
    expr: mysql_up == 0
    for: 30s
    labels:
      severity: critical
    annotations:
      summary: "MySQL Down,实例:{{ $labels.instance }}"
      description: "MySQL_exporter连不上MySQL了，当前状态为：{{ $value }}" 
  - alert: MysqlTooManyConnections
    expr: max_over_time(mysql_global_status_threads_connected[1m]) / mysql_global_variables_max_connections * 100 > 80
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Mysql连接数过多告警,实例:{{ $labels.instance }}"
      description: "MySQL连接数>80%,当前值：{{ $value }}"
  - alert: MysqlHighThreadsRunning
    expr: max_over_time(mysql_global_status_threads_running[1m]) > 20
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Mysql运行的线程过多,实例:{{ $labels.instance }}"
      description: "Mysql运行的线程 > 20，当前运行的线程：{{ $value }}" 
  - alert: MysqlSlowQueries
    expr: increase(mysql_global_status_slow_queries[2m]) > 0
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Mysql慢日志告警,实例:{{ $labels.instance }}"
      description: "MySQL在过去2分钟有新的{{ $value }}条慢查询"
  #MySQL innodb 日志写入停滞
  - alert: MysqlInnodbLogWaits
    expr: rate(mysql_global_status_innodb_log_waits[15m]) > 10
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: "MySQL innodb日志等待,实例:{{ $labels.instance }}"
      description: "MySQL innodb日志写入停滞，当前值： {{ $value }}"
  - alert: MysqlRestarted
    expr: mysql_global_status_uptime < 60
    for: 0m
    labels:
      severity: info
    annotations:
      summary: "MySQL 重启,实例:{{ $labels.instance }}"
      description: "不到一分钟前，MySQL重启过"
```

```sh
./promtool check config prometheus.yml
./promtool check rules rules/linux.yml
curl -X POST :9090/-/reload
```

## 访问测试

浏览器运行 http://192.168.88.101:9104/metrics，查看是否metrics数据输出，如果有输出内容监控就正常

> https://grafana.com/grafana/dashboards/7362
>
> https://github.com/percona/grafana-dashboards/tree/main/dashboards/MySQL

> 导入7362即可，数据源就是Prometheus，导入成功后，就可以浏览Top Process States和 Process States图形修改为如下：mysql_info_schema_threads 替换成：mysql_info_schema_processlist_threads

数据库表监控：https://grafana.com/grafana/dashboards/9625

注意：2个图表没有数据，是因为只⽀持percona server 和 mariadb

> MySQL Uptime如果不显示，点击时间Last 5 Minutes即可,或者进入prometheus界面进行查询，来修改
>
> mysql_global_status_uptime{instance="node1", job="mysqld_exporter"}，或者刷新几次，等会就行

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209091049454.png" alt="image-20220909104917327" style="zoom:80%;" />

# Nginx

## 前置准备

nginx开启stub_status

注 监控nginx需要with-http_stub_status_module，检查是否安装有with-http_stub_status_module模块，默认安装

```sh
docker exec -it nginx nginx -V 2>&1 | grep -o with-http_stub_status_module 
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271551555.png" alt="image-20230427155106487" style="zoom:80%;" />

nginx开启stub_status配置

```sh
cd /data/nginx/conf.d/
vim server.conf
```

> 注意：只有server模块，没有http等模块

```properties
server {
    listen 80;
    server_name localhost;
    location /stub_status {
       stub_status on;
       access_log off;
       #allow nginx_export的ip; 
       allow 0.0.0.0/0;
       deny all;
   }
    location / {
      root /usr/share/nginx/html;
      index index.html;
    }
}
```

```sh
# 重新加载配置⽂件
docker exec -it nginx nginx -t
docker exec -it nginx nginx -s reload
# 检查
curl http://192.168.88.101/stub_status
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271557300.png" alt="image-20230427155753223" style="zoom:80%;" />

## 二进制安装

nginx_exporter下载地址: https://github.com/nginxinc/nginx-prometheus-exporter/releases

```sh
# 下载⼆进制包解压并放⼊/opt⽬录
wget https://github.com/nginxinc/nginx-prometheus-exporter/releases/download/v0.11.0/nginx-prometheus-exporter_0.11.0_linux_amd64.tar.gz
mkdir -p /opt/module/nginx_exporter
tar -zxvf nginx-prometheus-exporter_0.11.0_linux_amd64.tar.gz -C /opt/module/nginx_exporter
```

创建系统服务，nginx_exporter.service

```sh
cat > /etc/systemd/system/nginx_exporter.service <<"EOF"
[Unit]
Description=nginx-prometheus-exporter
After=network.target
[Service]
Type=simple
User=root
Group=root
Restart=always
ExecStart=/opt/module/nginx_exporter/nginx-prometheus-exporter -nginx.scrape-uri=http://192.168.88.101/stub_status
[Install]
WantedBy=multi-user.target
EOF
```

```sh
# 启动 nginx_exporter
systemctl daemon-reload
systemctl start nginx_exporter.service
# 加⼊到开机⾃启动
systemctl enable nginx_exporter.service
# 检查
systemctl status nginx_exporter.service
# 启动不了检查⽇志
journalctl -u nginx_exporter.service -f
```

## Docker安装

```sh
mkdir -p /data/nginx/
cd /data/nginx/
```

```yml
cat >docker-compose.yaml <<EOF
version: '3.3'
services:
  nginx_exporter:
    image: nginx/nginx-prometheus-exporter:0.11
    container_name: nginx_exporter
    hostname: nginx_exporter
    command:
      - '-nginx.scrape-uri=http://192.168.88.101/stub_status'
    restart: always
    ports:
      - "9113:9113"
EOF
```

```sh
docker-compose up -d
docker ps
docker logs -f nginx_exporter
```

## Prometheus配置

配置prometheus去采集（拉取）nginx_exporter的监控样本数据

```sh
#在scrape_configs(搜刮配置):下⾯增加如下配置：
cat >> prometheus/prometheus.yml << "EOF"
  - job_name: 'nginx_exporter'
    static_configs:
    - targets: ['192.168.88.101:9113']
      labels:
        instance: test服务器
EOF
```

```sh
# 重新加载配置
curl -X POST :9090/-/reload
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271043442.png" alt="image-20230427104302235" style="zoom:80%;" />

## 常⽤监控指标

```
nginx_connections_accepted 接收请求数

nginx_connections_active 活动连接数nginx_connections_handled 成功处理请求数

nginx_connections_reding 正在进⾏读操作的请求数

nginx_connections_waiting 正在等待的请求数

nginx_connections_writing 正在进⾏写操作的请求数

nginx_connections_requests 总请求数
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271043909.png" alt="image-20230427104355703" style="zoom:80%;" />

## 添加触发器

nginx.yml

```yml
groups:
- name: Prometheus alert
  rules:
  - alert: NginxDown
    expr: nginx_up == 0
    for: 30s
    labels:
      severity: critical
    annotations:
      summary: "nginx异常,实例:{{ $labels.instance }}"
      description: "{{ $labels.job }} nginx已关闭"
```

```sh
# 检查规则写的是否正确
./promtool check config /etc/prometheus/prometheus.yml
./promtool check rules rules/nginx.yml
# 热更新配置文件
curl -X POST http://node1:9090/-/reload

# 检查
http://192.168.11.61:9090/alerts?search=
http://192.168.11.61:9090/rules
```

## dashboard

grafana展示prometheus从nginx_exporter收集到的的数据

https://grafana.com/grafana/dashboards/12708

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271612008.png" alt="image-20230427161204878" style="zoom:80%;" />

# Redis

redis_exporter：https://github.com/oliver006/redis_exporter

## 安装访问

### Redis安装

docker-compose.yaml

```yml
version: '3'
services:
  redis:
    image: redis
    container_name: redis
    command: redis-server /usr/local/etc/redis/redis.conf
    restart: always
    volumes:
      - /data/redis/data:/data
      - /data/redis/redis.conf:/usr/local/etc/redis/redis.conf
    ports:
      - 6379:6379
```

redis.conf

```properties
# Redis 配置文件示例
# 绑定的 IP 地址，默认为本地回环地址 127.0.0.1
bind 0.0.0.0

# 监听的端口，默认为 6379
port 6379

# 设置密码，将密码修改为你想要的密码
# 如果不需要密码，可以注释掉或删除这一行
requirepass 123456

# 数据库文件存放的路径，默认为当前目录下的 `dump.rdb`
# 可以根据需要修改为其他路径和文件名
# dbfilename dump.rdb

# 日志文件存放的路径，默认为标准输出
# 可以根据需要修改为其他路径和文件名
# logfile ""

# 其他配置项可以根据需要进行修改和添加
```

```sh
docker-compose up -d
docker ps
```

### 二进制安装

```sh
wget https://github.com/oliver006/redis_exporter/releases/download/v1.48.0/redis_exporter-v1.48.0.linux-amd64.tar.gz
tar -xzvf redis_exporter-v1.48.0.linux-amd64.tar.gz
mkdir /opt/prometheus/
mv redis_exporter-v1.48.0.linux-amd64 /opt/prometheus/redis_exporter
```

```sh
# 创建用户并更改权限
useradd -M -s /usr/sbin/nologin prometheus
chown prometheus:prometheus -R /opt/prometheus
```

**创建** **systemd** **服务**：redis_exporter.service

```sh
cat > /etc/systemd/system/redis_exporter.service <<"EOF"
[Unit]
Description=Prometheus Redis Exporter
After=network.target
[Service]
Type=simple
User=prometheus
Group=prometheus
Restart=always
ExecStart=/opt/prometheus/redis_exporter/redis_exporter \
-redis.addr localhost:6379 \
-redis.password 123456
[Install]
WantedBy=multi-user.target
EOF
```

```sh
systemctl daemon-reload
systemctl start redis_exporter
systemctl enable redis_exporter
systemctl status nredis_exporter
journalctl -u redis_exporter -f
```

### Docker安装

```sh
# 如果reidis有密码，后面再跟上 --redis.password '123456'，这边不能设置成node1，不然会出错
docker run -d --name redis_exporter -p 9121:9121 oliver006/redis_exporter --redis.addr=redis://172.17.0.1:6379 --redis.password '123456'
```

### Docker-compose安装

```yml
cat >docker-compose.yaml <<EOF
version: '3.3'
services:
  redis_exporter:
    image: oliver006/redis_exporter
    container_name: redis_exporter
    restart: always
    environment:
      REDIS_ADDR: "192.168.88.101:6379"
      REDIS_PASSWORD: 123456
    ports:
      - "9121:9121"
EOF    
```

```sh
docker-compose up -d
docker ps
docker logs -f redis_exporter
```

访问测试：http://node1:9121/metrics

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304251553200.png" alt="image-20230425155321076" style="zoom:80%;" />

> 注意：此时如果redis_up=0说明没有监控到redis，则上面的命令有误，看下是不是连接和密码的问题

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304251703385.png" alt="image-20230425170331284" style="zoom:80%;" />



## 配置prometheus

prometheus.yml

```sh
- job_name: 'redis'
    static_configs:
      - targets: ["node1:9121"]
```

```sh
# 热更新配置文件
curl -X POST http://node1:9090/-/reload
```

http://node1:9090/targets#pool-redis

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304251604242.png" alt="image-20230425160409145" style="zoom:67%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304251606934.png" alt="image-20230425160623830" style="zoom:80%;" />

## 常用监控指标

```sh
redis_up # 服务器是否在线
redis_uptime_in_seconds # 运⾏时⻓，单位 s
rate(redis_cpu_sys_seconds_total[1m]) + rate(redis_cpu_user_seconds_total[1m]) # CPU使用率
redis_memory_used_bytes # 占⽤内存量
redis_memory_max_bytes # 限制的最⼤内存，如果没限制则为 0
delta(redis_net_input_bytes_total[1m]) # ⽹络接收的 bytes
delta(redis_net_output_bytes_total[1m]) # ⽹络发送的 bytes
redis_connected_clients # 客户端连接数
redis_connected_clients / redis_config_maxclients # 连接数使⽤率
redis_rejected_connections_total # 拒绝的客户端连接数
redis_connected_slaves # slave 连接数
```

> - Uptime：Redis从启动到当前运行的时间。
> - Clients: 当前连接到Redis服务器的客户端数，用于掌握连接情况，判断是否需要调整集群数量或者连接数。
> - Memory Usage：Redis节点的内存使用率，用于资源消耗评估。
> - Commands Executed/sec：每秒成功执行的命令数。
> - Hits/Misses Per Sec:每秒服务器中键命中/非命中的比率，这个值可以用来评估设计是否合理。
> - Network I/O:网络I/O流量情况，可以用于评估带宽压力。
> - Expiring vs Not-Expiring Keys：过期的Keys的数量和未过期的Keys数量

## 配置告警规则

> 在prometheus文件夹下的rules文件夹，新建redis.yml，写入以下内容

```yml
groups:
  - name: redis
    rules:
      - alert: RedisDown
        expr: redis_up == 0
        for: 0m
        labels:
          severity: critical
        annotations:
          summary: 'Redis Down,实例:{{ $labels.instance }}'
          description: "Redis实例 is down"
      - alert: RedisMissingBackup
        expr: time() - redis_rdb_last_save_timestamp_seconds > 60 * 60 * 24
        for: 0m
        labels:
          severity: critical
        annotations:
          summary: "Redis备份丢失,实例:{{ $labels.instance }}"
          description: "Redis 24⼩时未备份"
      - alert: RedisOutOfConfiguredMaxmemory
        expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 > 90
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Redis超出配置的最大内存,实例:{{ $labels.instance }}"
          description: "Redis内存使用超过配置最大内存的90%"
      - alert: RedisTooManyConnections
        expr: redis_connected_clients > 100
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Redis连接数过多,实例:{{ $labels.instance }}"
          description: "Redis当前连接数为： {{ $value }}"
      - alert: RedisNotEnoughConnections
        expr: redis_connected_clients < 1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Redis没有⾜够的连接,实例:{{ $labels.instance }}"
          description: "Redis当前连接数为： {{ $value }}"
      - alert: RedisRejectedConnections
        expr: increase(redis_rejected_connections_total[1m]) > 0
        for: 0m
        labels:
          severity: critical
        annotations:
          summary: "Redis有拒绝连接,实例:{{ $labels.instance }}"
          description: "与Redis 的某些连接被拒绝{{ $value }}"
```

```sh
# 检查配置文件并热更新
./promtool check rules rules/redis.yml
curl -X POST http://node1:9090/-/reload
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271632179.png" alt="image-20230427163205101" style="zoom:80%;" />

## 配置仪表盘

https://grafana.com/grafana/dashboards/11835

https://grafana.com/grafana/dashboards/17507

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304251701764.png" alt="image-20230425170157644" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304251631313.png" alt="image-20230425163122211" style="zoom:67%;" />

修改Memory Usage显示无穷大的问题

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304251700272.png" alt="image-20230425170022191" style="zoom:80%;" />

> 100 * (redis_memory_used_bytes{instance=~"$instance"}  / 104857600)

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304251701882.png" alt="image-20230425170104728" style="zoom:80%;" />

> https://grafana.com/grafana/dashboards/17507
>
> 关于CPU使用率不显示的问题，修改如下，即可正常显示

```sh
100 * (rate(redis_cpu_sys_seconds_total[1m]) + rate(redis_cpu_user_seconds_total[1m])) / 60
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271654463.png" alt="image-20230427165402381" style="zoom:80%;" />

# ES

官网：https://github.com/prometheus-community/elasticsearch_exporter

## docker-compose配置

```yml
elasticsearch_exporter:
    image: quay.io/prometheuscommunity/elasticsearch-exporter:latest
    command:
    - '--es.uri=http://192.168.22.130:9200'
    restart: always
    ports:
    - "9114:9114"
```

```apl
docker-compose up -d 
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209091826366.png" alt="image-20220909182640313" style="zoom:80%;" />

访问：http://192.168.22.130:9114/metrics

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209091825528.png" alt="image-20220909182522306" style="zoom:80%;" />

修改：/mydata/prometheus/prometheus.yml

```yml
- job_name: "elasticsearch"
    static_configs:
      - targets: ["192.168.22.130:9114"]
```

```apl
docker restart prometheus 
```

访问：http://192.168.22.130:9090/targets

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209091829909.png" alt="image-20220909182958852" style="zoom:80%;" />

## 访问Grafana测试

访问：http://192.168.22.130:3000/

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209091835304.png" alt="image-20220909183534237" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202209091834634.png" alt="image-20220909183450527" style="zoom:80%;" />

# SpringBoot

> 监控SpringBoot应用需要依靠`actuator`及`micrometer`，通过暴露`actuator`的端点，Prometheus可以定时获取并存储指标信息。

## SpringBoot配置

修改项目的`pom.xml`文件，添加`actuator`及`micrometer`依赖；

```xml
<dependencies>
    <!-- spring-boot-actuator依赖 -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-actuator</artifactId>
    </dependency>
    <!-- prometheus依赖 -->
    <dependency>
        <groupId>io.micrometer</groupId>
        <artifactId>micrometer-registry-prometheus</artifactId>
    </dependency>
</dependencies>
```

修改应用配置文件`application.yml`，通过`actuator`暴露监控端口`/actuator/prometheus`；

出于安全考虑，默认情况下除了/health和/info之外的所有actuator都是关闭的

```yml
management:
  endpoints:
    web:
      exposure:
        # 暴露端点`/actuator/prometheus`
        include: prometheus,health
  metrics:
    tags:
      application: ${spring.application.name}
```

在监控SpringBoot应用之前，我们需要先运行一个SpringBoot应用，使用如下命令运行即可；注意：可以直接在本地启动项目，上面连接写本机就行,

```sh
docker run -d --restart=always -p 8081:8080 --name springboot-demo linge365/springboot-demo
http://192.168.11.62:8081/actuator/prometheus
```

## Prometheus配置

prometheus配置采集springboot2.x的应⽤target提供的数据

```sh
cd /data/docker-prometheus
# 在scrape_configs(搜刮配置):下⾯增加如下配置：
```

```yml
cat >> prometheus/prometheus.yml << "EOF"
# Spring Boot 2.x 应⽤数据采集配置
- job_name: 'springboot-demo'
  metrics_path: '/actuator/prometheus'
  scrape_interval: 5s
  static_configs:
    - targets: ['192.168.11.62:8081']
EOF
```

```sh
curl -X POST :9090/-/reload
http://192.168.11.61:9090/targets?search=
```

## 监控指标

```sh
process_files_max_files # 最⼤⽂件处理数量
tomcat_sessions_active_current_sessions # Tomcat 当前活跃 session 数量
tomcat_sessions_alive_max_seconds # Tomcat session 最⼤存活时间
jvm_buffer_total_capacity_bytes # 预估的池中缓冲区的总容量
jvm_threads_daemon_threads # 当前守护进程的线程数量
tomcat_global_request_max_seconds{name="http-nio-8080",} # 全局最⻓⼀次请求的时间
tomcat_sessions_active_max_sessions # 最⼤活跃 session 数量
system_cpu_usage # CPU 利⽤率
jvm_buffer_memory_used_bytes # 预估 Java 虚拟机⽤于此缓冲池的内存
jvm_classes_loaded_classes # 当前在 Java 虚拟机中加载的类的数量
jvm_memory_committed_bytes # 为 Java 虚拟机提交的内存量（以字节为单位）
jvm_threads_live_threads # 当前线程数，包括守护进程和⾮守护进程的线程
tomcat_threads_config_max_threads # 配置的 Tomcat 的最⼤线程数
tomcat_global_received_bytes_total # Tomcat 接收到的数据量
tomcat_global_sent_bytes_total # Tomcat 发送的数据量
tomcat_threads_current_threads # Tomcat 当前的线程数
tomcat_sessions_created_sessions_total # Tomcat 创建的 session 数
system_load_average_1m # 在⼀段时间内，排队到可⽤处理器的可运⾏实体数量和可⽤处理器上运⾏的可运⾏实体数量的总和的平均值
tomcat_sessions_expired_sessions_total # 过期的 session 数量
jvm_buffer_count_buffers # 预估的池中的缓冲区数量
jvm_memory_used_bytes# JVM 内存使⽤量
process_uptime_seconds # Java 虚拟机的正常运⾏时间
jvm_gc_memory_allocated_bytes_total # 增加⼀个 GC 到下⼀个 GC 之后年轻代内存池的⼤⼩增加
jvm_gc_pause_seconds_count # GC暂停耗时数量和总时间
jvm_gc_pause_seconds_sum
jvm_gc_pause_seconds_max
tomcat_sessions_rejected_sessions_total # 被拒绝的 session 总数
jvm_gc_live_data_size_bytes# Full GC 后的⽼年代内存池的⼤⼩
tomcat_threads_busy_threads # Tomcat 繁忙线程数
jvm_threads_peak_threads # ⾃ Java 虚拟机启动或峰值重置以来的最⾼活动线程数
jvm_threads_states_threads # 当前具有 NEW 状态的线程数
jvm_gc_max_data_size_bytes # jvm_gc内存池的最⼤⼤⼩
http_server_requests_seconds_count #某个接⼝的请求数量和请求总时间
http_server_requests_seconds_sum
http_server_requests_seconds_max
jvm_gc_memory_promoted_bytes_total # GC之前到GC之后的⽼年代内存池⼤⼩的正增加计数

# ⽇志按级别计数
logback_events_total{application="prometheus-demo",level="info",} 7.0
logback_events_total{application="prometheus-demo",level="trace",} 0.0
logback_events_total{application="prometheus-demo",level="warn",} 0.0
logback_events_total{application="prometheus-demo",level="debug",} 0.0
logback_events_total{application="prometheus-demo",level="error",} 0.0

process_start_time_seconds # 启动时间
process_files_open_files # 打开⽂件描述符的数量
tomcat_global_error_total # 异常数量
jvm_memory_max_bytes # 可⽤于内存管理的最⼤内存量（以字节为单位）
process_cpu_usage # 最近的 CPU 利⽤率
jvm_classes_unloaded_classes_total # ⾃ Java 虚拟机开始执⾏以来卸载的类总数
system_cpu_count # CPU 核数
tomcat_global_request_seconds_count # 全局请求总数和总耗时
tomcat_global_request_seconds_sum
```

## 触发器

```sh
# 进⼊到prometheus安装⽬录
cd /data/docker-prometheus
```

添加触发器（告警规则）

```yml
cat >> prometheus/rules/springboot.yml <<"EOF"
groups:
  - name: SprinBoot
    rules:
      - alert: SprinBooErrorEvents
        expr: increase(logback_events_total{level="error"}[2m]) > 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Springboot错误事件 容器: $labels.instance"
          description: "在过去2分钟有新的{{ $value }}个错误事件"
EOF
```

```sh
# 重新加载配置,检查
./promtool check rules rules/spring.yml
curl -X POST http://node1:9090/-/reload

http://192.168.11.61:9090/alerts?search=
http://192.168.11.61:9090/rules
```

## Dashboard

grafana将prometheus作为数据源进⾏可视化展示

### JVM监控

https://grafana.com/grafana/dashboards/12856-jvm-micrometer/

https://grafana.com/grafana/dashboards/4701-jvm-micrometer/

### 应用监控⭐

https://grafana.com/grafana/dashboards/10280

https://grafana.com/grafana/dashboards/14370

### 数据库连接池监控

hikari连接池：https://grafana.com/grafana/dashboards/6083

druid连接池：https://grafana.com/grafana/dashboards/11157

导入成功后就可以在Grafana中看到SpringBoot实时监控信息了，果然够炫酷！

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.5.13/202205181608186.png" alt="image-20220518160850123" style="zoom:80%;" />

# RabbitMQ

## 二进制安装

```sh
wget https://github.com/kbudde/rabbitmq_exporter/releases/download/v1.0.0-RC19/rabbitmq_exporter_1.0.0-RC19_linux_amd64.tar.gz
mkdir /opt/prometheus/rabbitmq_exporter -p
tar -xzvf rabbitmq_exporter_1.0.0-RC19_linux_amd64.tar.gz -C
/opt/prometheus/rabbitmq_exporter
```

```sh
# 创建用户并更改exporter⽂件夹权限
useradd -M -s /usr/sbin/nologin prometheus
chown prometheus:prometheus -R /opt/prometheus
```

创建 **systemd** 服务，使⽤cat创建

```sh
cat > /etc/systemd/system/rabbitmq_exporter.service <<"EOF"
[Unit]
Description=prometheus rabbitmq exporter
After=network.target
[Service]
Environment=RABBIT_USER=guest
Environment=RABBIT_PASSWORD=guest
Environment=RABBIT_URL=:15672
OUTPUT_FORMAT=JSON
Type=simple
User=prometheus
Group=prometheus
Restart=always
ExecStart=/opt/prometheus/rabbitmq_exporter/rabbitmq_exporter
[Install]
WantedBy=multi-user.target
EOF
```

```sh
systemctl daemon-reload
systemctl start rabbitmq_exporter
systemctl enable rabbitmq_exporter
systemctl status rabbitmq_exporter
journalctl -u rabbitmq_exporter.service -f
```

## Docker安装

> 方式一：直接Docker安装

```sh
docker run -d --restart=always -p 9419:9419 --name rabbitmq_exporter -e RABBIT_URL=http://192.168.88.101:15672 -e RABBIT_USER=guest -e RABBIT_PASSWORD=guest kbudde/rabbitmq-exporter
```

> 方式二：Docker-compose安装

```yml
version: '3.3'
services:
  rabbitmq_exporter:
    image: kbudde/rabbitmq-exporter
    container_name: rabbitmq_exporter
    restart: always
    environment:
      RABBIT_URL: "http://192.168.11.62:15672"
      RABBIT_USER: "guest"
      RABBIT_PASSWORD: "guest"
      PUBLISH_PORT: "9419"
      OUTPUT_FORMAT: "JSON"
      ports:
        - "9419:9419"
```

```sh
docker ps
docker logs -f rabbitmq_exporter
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271658779.png" alt="image-20230427165855704" style="zoom:80%;" />

## Prometheus配置

prometheus.yml配置

```yml
  - job_name: 'rabbitmq_exporter'
    static_configs:
      - targets: ['192.168.88.101:9419']
        labels:
          instance: test服务器
```

```
curl -X POST :9090/-/reload
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271701589.png" alt="image-20230427170143519" style="zoom:80%;" />

## 常用监控指标

> rabbitmq_queue_messages_unacknowledged_global 队列中有未确认的消息总数（未被消费的消息）
>
> rabbitmq*_node_disk_free_limit* 使⽤磁盘⼤⼩
>
> *rabbitmq_node_disk_*free 磁盘总⼤⼩
>
> rabbitmq*_node_mem_used* *使⽤内存⼤⼩*
>
> *rabbitmq_node_mem_*limit 内存总⼤⼩
>
> rabbitmq*_sockets_used* *使⽤**sockets**的数量*
>
> *rabbitmq_sockets_*available 可⽤的sockets总数
>
> rabbitmq*_fd_used* 使⽤⽂件描述符的数量
>
> *rabbitmq_fd_*available 可⽤的⽂件描述符总数

## 触发器配置

Prometheus配置

```yml
# 报警(触发器)配置
rule_files:
  - "alert.yml" 
  - "rules/*.yml"
```

```yml
groups:
  - name: Rabbitmq
    rules:
      - alert: RabbitMQDown
        expr: rabbitmq_up != 1
        labels:
          severity: High
        annotations:
          summary: "Rabbitmq Down,实例:{{ $labels.instance }}"
          description: "Rabbitmq_exporter连不上RabbitMQ! ! !"
      - alert: RabbitMQ有未确认消息
        expr: rabbitmq_queue_messages_unacknowledged_global > 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "RabbitMQ有未确认消息,实例:{{ $labels.instance }}"
          description: 'RabbitMQ未确认消息>0,当前值为：{{ $value }}'
      - alert: RabbitMQ可⽤磁盘空间不⾜告警
        expr: rabbitmq_node_disk_free_alarm != 0
        for: 0m
        labels:
          severity: critical
        annotations:
          summary: "RabbitMQ可⽤磁盘空间不⾜,实例:{{ $labels.instance }}"
          description: "RabbitMQ可⽤磁盘空间不⾜，请检查"
      - alert: RabbitMQ可⽤内存不⾜告警
        expr: rabbitmq_node_mem_alarm != 0
        for: 0m
        labels:
          severity: critical
        annotations:
          summary: "RabbitMQ可⽤内存不⾜,实例:{{ $labels.instance }}"
          description: "RabbitMQ可⽤内存不⾜，请检查"
      - alert: RabbitMQ_socket连接数使⽤过⾼告警
        expr: rabbitmq_sockets_used / rabbitmq_sockets_available * 100 > 60
        for: 0m
        labels:
          severity: critical
        annotations:
          summary: "RabbitMQ_socket连接数使⽤过⾼,实例:{{ $labels.instance }}"
          description: 'RabbitMQ_sockets使⽤>60%,当前值为：{{ $value }}'
      - alert: RabbitMQ⽂件描述符使⽤过⾼告警
        expr: rabbitmq_fd_used / rabbitmq_fd_available * 100 > 60
        for: 0m
        labels:
          severity: critical
        annotations:
          summary: "RabbitMQ⽂件描述符使⽤过⾼,实例:{{ $labels.instance }}"
          description: 'RabbitMQ⽂件描述符使⽤>60%,当前值为：{{ $value }}'
```

```sh
./promtool check rules rules/nginx.yml
# 热更新配置文件
curl -X POST http://node1:9090/-/reload
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271706657.png" alt="image-20230427170652584" style="zoom:80%;" />

## dashboard

grafana展示prometheus从rabbitmq_exporter收集到的的数据

https://grafana.com/grafana/dashboards/4279-rabbitmq-monitoring/

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271711636.png" alt="image-20230427171125457" style="zoom:80%;" />

# mongodb

## 创建监控⽤户

登陆mongodb创建监控⽤户，权限为“readAnyDatabase”，如果是cluster环境，需要有权限“clusterMonitor”

```sh
# 登录mongodb（docker安装的mongo）
docker exec -it mongo mongo admin
# 登录mongodb（yum和apt安装的mongo）
mongo admin
```

```sql
# 登录root用户
db.auth('root','123456')
# 创建监控⽤户
db.createUser({ 
              user:'exporter',
              pwd:'password',
              roles:[ 
                  { 
                     role:'readAnyDatabase', 
                     db:'admin'
                  },
                  {
                  role: "clusterMonitor", 
                  db: "admin" 
                  }
              ]
      }
);
```

```sh
# 测试 使⽤上⾯创建的⽤户信息进⾏连接
db.auth('exporter', 'password')
exit
```

## mongodb_exporter

地址:https://github.com/percona/mongodb_exporter/releases

或：https://github.com/prometheus/mysqld_exporter/releases

### 二进制安装

下载⼆进制包解压并放⼊**/opt**⽬录

```sh
wget https://github.com/percona/mongodb_exporter/releases/download/v0.37.0/mongodb_exporter-0.37.0.linux-amd64.tar.gz
tar -xzvf mongodb_exporter-0.37.0.linux-amd64.tar.gz
mv mongodb_exporter-0.37.0.linux-amd64 mongodb_exporter
```

创建systemd服务

mongodb_exporter.service

```sh
cat <<EOF >/usr/lib/systemd/system/mongodb_exporter.service
[Unit]
Description=mongodb_exporter
Documentation=https://github.com/percona/mongodb_exporter
After=network.target
[Service]
Type=simple
User=root
Environment="MONGODB_URI=mongodb://exporter:password@localhost:27017/admin"
ExecStart=/opt/module/mongodb_exporter/mongodb_exporter --log.level=error --collect-all --compatible-mode
Restart=on-failure
[Install]
WantedBy=multi-user.target
EOF
```

启动 **mongodb_exporter**

```sh
systemctl daemon-reload
systemctl start mongodb_exporter.service
# 加⼊到开机⾃启动
systemctl enable mongodb_exporter.service
# 检查
systemctl status mongodb_exporter.service
# 启动不了检查⽇志
journalctl -u mongodb_exporter.service -f
```

### **docker**安装

```sh
docker run -d --restart=always -p 9216:9216 -p 17001:17001 --restart=always --name=mongodb-exporter bitnami/mongodb-exporter:latest --collect-all --compatible-mode --mongodb.uri=mongodb://exporter:password@192.168.88.101:27017/admin?ssl=false
```

**docker-compose**⽅式

```sh
cat >docker-compose.yaml <<EOF
version: '3.3'
services:
  mongodb_exporter:
    image: bitnami/mongodb-exporter:latest
    container_name: mongodb_exporter
    restart: always
    environment:
      MONGODB_URI: "mongodb://exporter:password@192.168.11.62:27017/admin?ssl=false"
    command:
      - '--collect-all'
      - '--compatible-mode'
    ports:
      - "9216:9216"
EOF
```

```sh
docker-compose up -d
docker ps
docker logs -f mongodb_exporter
```

### 参数解释

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304252138882.png" alt="image-20230425213854775" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304252139294.png" alt="image-20230425213918190" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304252139419.png" alt="image-20230425213937324" style="zoom:80%;" />

### metrics地址

注：安装好Exporter后会暴露⼀个 http://ip:端⼝/metrics 的HTTP服务

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304252140985.png" alt="image-20230425214003923" style="zoom:80%;" />

## Prometheus配置

配置prometheus去采集（拉取）mongodb_exporter的监控样本数据

```yml
cd /data/docker-prometheus
# 在scrape_configs(搜刮配置):下⾯增加如下配置：
cat >> prometheus/prometheus.yml << "EOF"
  - job_name: 'mongodb_exporter'
    static_configs:
    - targets: ['192.168.88.101:9216']
      labels:
        instance: test服务器
EOF
```

```sh
# 重新加载配置
curl -X POST :9090/-/reload
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304252141102.png" alt="image-20230425214144001" style="zoom:67%;" />

### 常⽤的监控指标

```sh
mongodb_ss_connections{conn_type="available"} # 可⽤的连接总数
mongodb_ss_mem_virtual
mongodb_ss_mem_resident
# 关于 server status
mongodb_up # 服务器是否在线
mongodb_ss_ok{cl_id="", cl_role="mongod", rs_state="0"} # 服务器是否正常运⾏，取值为 1、0 。标签中记录
了 Cluster、ReplicaSet 的信息
mongodb_ss_uptime # 服务器的运⾏时⻓，单位为秒
mongodb_ss_connections{conn_type="current"} # 客户端连接数
# 关于主机
mongodb_sys_cpu_num_cpus # 主机的 CPU 核数
# 关于 collection
mongodb_collstats_storageStats_count{database="xx", collection="xx"} # collection 全部⽂档的数量
mongodb_collstats_storageStats_size # collection 全部⽂档的体积，单位 bytes
mongodb_collstats_storageStats_storageSize # collection 全部⽂档占⽤的磁盘空间，默认会压缩
delta(mongodb_collstats_latencyStats_reads_ops[1m]) # collection 读操作的数量（每分钟）
delta(mongodb_collstats_latencyStats_reads_latency[1m]) # collection 读操作的延迟（每分钟），单位为微秒
mongodb_collstats_latencyStats_write_ops
mongodb_collstats_latencyStats_write_latency
# 关于 index
mongodb_collstats_storageStats_nindexes # collection 的 index 数量
mongodb_collstats_storageStats_totalIndexSize # collection 的 index 占⽤的磁盘空间
delta(mongodb_indexstats_accesses_ops[1m]) # index 被访问次数
# 关于操作
delta(mongodb_ss_opcounters[1m]) # 执⾏各种操作的数量
delta(mongodb_ss_opLatencies_latency[1m]) # 执⾏各种操作的延迟，单位为微秒
delta(mongodb_ss_metrics_document[1m]) # 各种⽂档的变化数量
# 关于锁
delta(mongodb_ss_locks_acquireCount{lock_mode="w"}[1m]) # 新加锁的数量。R 表示共享锁，W 表示独占锁，r表示意向共享锁，w 表示意向独占锁
mongodb_ss_globalLock_currentQueue{count_type="total"} # 被锁阻塞的操作数
```

### 触发器配置

Prometheus配置

```sh
# 报警(触发器)配置
rule_files:
  - "alert.yml" 
  - "rules/*.yml"
```

**mongodb**触发器（告警规则）

因mongo单点，所以未配置复制触发器

```yml
groups:
- name: PerconaMongodbExporter
  rules:
    - alert: MongodbDown
      expr: 'mongodb_up == 0'
      for: 0m
      labels:
        severity: critical
      annotations:
        summary: "MongoDB Down 容器: $labels.instance"
        description: "MongoDB 容器 is down, 当前值:{{ $value }}"
    - alert: MongodbNumberCursorsOpen
      expr: 'mongodb_ss_metrics_cursor_open{csr_type="total"} > 10 * 1000'
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "MongoDB 数字有标打开告警 容器: $labels.instance"
        description: "MongoDB 为客户端打开的游标过多 > 10k, 当前值:{{ $value }}"
    - alert: MongodbCursorsTimeouts
      expr: 'increase(mongodb_ss_metrics_cursor_timedOut[1m]) > 100'
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "MongoDB 游标超时 容器: $labels.instance"
        description: "太多游标超时, 当前值:{{ $value }}"
    - alert: MongodbTooManyConnections
      expr: 'avg by(instance) (rate(mongodb_ss_connections{conn_type="current"}[1m])) / avg by(instance) (sum (mongodb_ss_connections) by (instance)) * 100 > 80'
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "MongoDB 太多连接 容器: $labels.instance"
        description: "MongoDB 连接数 > 80%, 当前值:{{ $value }}"
    - alert: MongodbVirtualMemoryUsage
      expr: '(sum(mongodb_ss_mem_virtual) BY (instance) / sum(mongodb_ss_mem_resident) BY (instance)) > 3'
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "MongoDB虚拟内存使⽤告警 容器: $labels.instance"
        description: "虚拟内存使⽤过⾼, 当前值:{{ $value }}"
```

```sh
curl -X POST :9090/-/reload
```

检查：http://192.168.11.61:9090/alerts?search=

或：http://192.168.11.61:9090/rules

## dashboard

grafana展示prometheus从mongodb_exporter收集到的的数据

https://github.com/percona/grafana-dashboards/tree/main/dashboards/MongoDB

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271734110.png" alt="image-20230427173421002" style="zoom:80%;" />



# 域名监控

域名的监控通过 domain_exporter 来完成，域名过期时间监控

domain_exporter：https://github.com/caarlos0/domain_exporter/releases

## 二进制安装

https://prometheus.io/download/

```sh
wget https://github.com/caarlos0/domain_exporter/releases/download/v1.20.0/domain
_exporter_1.20.0_linux_amd64.tar.gz

tar -zxvf domain_exporter_1.20.0_linux_amd64.tar.gz
mkdir /opt/prometheus -p
mv domain_exporter_1.20.0_linux_amd64 /opt/prometheus/domain_exporter
```

```sh
useradd -M -s /usr/sbin/nologin prometheus
chown prometheus:prometheus -R /opt/prometheus
```

```sh
cat <<"EOF" >/etc/systemd/system/domain_exporter.service
[Unit]
Description=domain_exporter 
After=network.target
[Service]
Type=simple
User=prometheus
Group=prometheus
ExecStart=/opt/prometheus/domain_exporter/domain_exporter 
Restart=on-failure
[Install]
WantedBy=multi-user.target
EOF
```

```sh
systemctl daemon-reload
systemctl start domain_exporter
systemctl enable domain_exporter
systemctl status domain_exporter
journalctl -u domain_exporter -f
```

## Docker安装⭐

```sh
docker run -d --restart=always --name domain_exporter -p 9222:9222 caarlos0/domain_exporter
```

## Prometheus设置

```yml
  - job_name: domain
    scrape_interval: 15s
    metrics_path: /probe
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - target_label: __address__
        replacement: 192.168.88.101:9222 # domain_exporter address
    static_configs:
    - targets:
        - qq.com
        - baidu.cn
```

```sh
# 重新加载配置
curl -X POST :9090/-/reload
# 检查
http://192.168.11.61:9090/targets?search=
http://192.168.11.62:9222/
```

## 常⽤监控项⽬

```
domain_expiry_days 域名到期时间

domain_probe_success 域名检测状态
```

## 触发器

Prometheus配置

```yml
# 报警(触发器)配置
rule_files:
  - "alert.yml" 
  - "rules/*.yml"
```

添加**domain**触发器（告警规则）

```sh
groups:
- name: domain
  rules:
  - alert: 域名检测失败
    expr: domain_probe_success == 0
    for: 2h
    labels:
      severity: warning
    annotations:
      summary: '{{ $labels.instance }}'
      description: '{{ $labels.domain }}域名检测失败'
  - alert: 域名过期
    expr: domain_expiry_days < 30
    for: 2h
    labels:
      severity: warning
    annotations:
      summary: '{{ $labels.instance }}'
      description: '{{ $labels.domain }}将在30天后过期'
  - alert: 域名过期
    expr: domain_expiry_days < 5
    for: 2h
    labels:
      severity: page
    annotations:
      summary: '{{ $labels.instance }}'
      description: '{{ $labels.domain }}将在5天后过期'
```

```sh
# 重新加载配置
./promtool check rules rules/linux.yml
curl -X POST :9090/-/reload
# 检查
http://192.168.11.61:9090/alerts?search=
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304281516932.png" alt="image-20230428151616853" style="zoom:80%;" />

## Doshboard

https://grafana.com/grafana/dashboards/14605

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261425484.png" alt="image-20230426142556412" style="zoom:80%;" />

找到右边的Column Styles，在找到“域名”这列，把 instance 修改为 domain 如下图

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304281520778.png" alt="image-20230428152027695" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261426381.png" alt="image-20230426142626295" style="zoom: 80%;" />



# Docker监控

## Docker命令

为了能够获取到Docker容器的运⾏状态，⽤户可以通过Docker的stats命令获取到当前主机上运⾏容器的统计信息，可以查看容器的CPU利⽤率、内存使⽤量、⽹络IO总量以及磁盘IO总量等信息。

```sh
docker stats
```

除了使⽤命令以外，⽤户还可以通过Docker提供的HTTP API查看容器详细的监控统计信息。

## CAdvisor

CAdvisor是Google开源的⼀款⽤于展示和分析容器运⾏状态的可视化⼯具。通过在主机上运⾏CAdvisor⽤户可以轻松的获取到当前主机上容器的运⾏统计信息，并以图表的形式向⽤户展示。

### Docker版安装⭐

```sh
docker run -d \
 --restart=always \
 --volume=/:/rootfs:ro \
 --volume=/var/run:/var/run:rw \
 --volume=/sys:/sys:ro \
 --volume=/var/lib/docker/:/var/lib/docker:ro \
 --publish=8080:8080 \
 --name=cadvisor \
 google/cadvisor:latest
```

### Docker-compose版安装

```sh
mkdir /data/cadvisor
cd /data/cadvisor
```

```sh
# 通过cat新建docker-compose.yaml⽂件
cat > docker-compose.yaml <<"EOF"
version: '3.3'
  cadvisor:
    image: google/cadvisor:latest
    container_name: cadvisor
    restart: always
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    ports:
      - 8080:8080
```

```sh
docker-compose up -d
docker ps
```

访问：:8080可以查看，当前主机上容器的运⾏状态，如下所示

访问：:8080/metrics即可获取到标准的Prometheus监控样本输出

## Prometheus配置

配置prometheus去采集（拉取）cAdvisor的监控样本数据

```sh
cd /data/docker-prometheus
# 在scrape_configs(搜刮配置):下⾯增加如下配置：
cat >> prometheus/prometheus.yml << "EOF"
  - job_name: 'cadvisor'
    static_configs:
    - targets: ['192.168.88.101:8080']
      labels:
        instance: node1
EOF
```

```sh
# 重新加载配置
curl -X POST :9090/-/reload
```

启动完成后，可以在Prometheus UI中查看到当前所有的Target状态：http://192.168.88.101:9090/targets?search=

## 常⽤监控指标

下⾯表格中列举了⼀些CAdvisor中获取到的典型监控指标：container_

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261448453.png" alt="image-20230426144837352" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261448444.png" alt="image-20230426144853374" style="zoom:80%;" />

## 触发器配置

Prometheus配置

```sh
# 报警(触发器)配置
rule_files:
  - "alert.yml" 
  - "rules/*.yml"
```

添加**docker**触发器（告警规则）

```yml
groups:
- name: DockerContainers
  rules:
  - alert: ContainerKilled
    expr: time() - container_last_seen > 60
    for: 0m
    labels:
      severity: warning
    annotations:
      isummary: "Docker容器被杀死 容器: $labels.instance"
      description: "{{ $value }}个容器消失了"
  # This rule can be very noisy in dynamic infra with legitimate container start/stop/deployment.
  - alert: ContainerAbsent
    expr: absent(container_last_seen)
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "无容器 容器: $labels.instance"
      description: "5分钟检查容器不存在，值为：{{ $value }}"
  - alert: ContainerCpuUsage
    expr: (sum(rate(container_cpu_usage_seconds_total{name!=""}[3m])) BY (instance, name) * 100) > 300
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "容器cpu使用率告警 容器: $labels.instance"
      description: "容器cpu使用率超过300%，当前值为：{{ $value }}"
  - alert: ContainerMemoryUsage
    expr: (sum(container_memory_working_set_bytes{name!=""}) BY (instance, name) / sum(container_spec_memory_limit_bytes > 0) BY (instance, name) * 100) > 80
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "容器内存使用率告警 容器: $labels.instance"
      description: "容器内存使用率超过80%，当前值为：{{ $value }}"
  - alert: ContainerVolumeIoUsage
    expr: (sum(container_fs_io_current{name!=""}) BY (instance, name) * 100) > 80
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "容器存储io使用率告警 容器: $labels.instance"
      description: "容器存储io使用率超过 80%，当前值为：{{ $value }}"
  - alert: ContainerHighThrottleRate
    expr: rate(container_cpu_cfs_throttled_seconds_total[3m]) > 1
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "容器限制告警 容器: $labels.instance"
      description: "容器被限制，当前值为：{{ $value }}"
```

```sh
# 重新加载配置
./promtool check rules rules/linux.yml
curl -X POST :9090/-/reload
curl -X POST http://node1:9093/-/reload 
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304281527085.png" alt="image-20230428152723984" style="zoom:80%;" />

## dashboard

grafana展示prometheus收集到的cadvisor的数据192.168.88.101:3000

https://grafana.com/grafana/dashboards/11600-docker-container/

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304281532189.png" alt="image-20230428153214022" style="zoom:80%;" />



# etcd监控

使⽤kube-prometheus-stack安装好prometheus，并对整个K8S集群做好监控。

### 获取etcd证书

**etcd** 证书

对于 etcd 集群⼀般情况下，为了安全都会开启 https 证书认证的⽅式，所以要想让 Prometheus 访问到

etcd 集群的监控数据，就需要提供相应的证书校验

证书路径：

```sh
vim /etc/kubernetes/manifests/kube-apiserver.yaml
```

得到

```sh
- --etcd-cafile=/etc/ssl/etcd/ssl/ca.pem
- --etcd-certfile=/etc/ssl/etcd/ssl/node-k8s.pem
- --etcd-keyfile=/etc/ssl/etcd/ssl/node-k8s-key.pem
- --etcd-servers=https://192.168.11.65:2379
```

可以看到是跟计算机名有关系的。通过curl检查

```sh
curl -k --cacert /etc/ssl/etcd/ssl/ca.pem --cert /etc/ssl/etcd/ssl/node-k8s.pem --key /etc/ssl/etcd/ssl/node-k8s-key.pem

https://localhost:2379/metrics
```

说明etcd ⾃带metrics（监控样本数据）

### 创建**secret**（保密字典）

pem ⽂件根据实际修改

```sh
kubectl -n monitoring create secret generic etcd-certs \
--from-file=/etc/ssl/etcd/ssl/ca.pem \
--from-file=/etc/ssl/etcd/ssl/node-k8s.pem \
--from-file=/etc/ssl/etcd/ssl/node-k8s-key.pem
```

```
kubectl -n monitoring get secret etcd-certs -oyaml
```

### kube-prometheus-stack开启etcd监控

修改配置⽂件，开启etcd监控

```sh
vim kube-prometheus-stack/values.yaml
```

修改如下：

```yml
kubeEtcd:
  enabled: true
  endpoints:
  #因为我们的etcd安装到宿主机上的，所以要指定宿主机ip，ip根据实际修改。
  - 192.168.11.65
  service:
    enabled: true
    #注，我的etcd端⼝为2379，根据实际修改
    port: 2379
    targetPort: 2379
 
  serviceMonitor:
    enabled: true
    #https请求
    scheme: https
    insecureSkipVerify: true
    serverName: ""
    #指定证路径
    caFile: "/etc/prometheus/secrets/etcd-certs/ca.pem"
    certFile: "/etc/prometheus/secrets/etcd-certs/node-k8s.pem"
    keyFile: "/etc/prometheus/secrets/etcd-certs/node-k8s-key.pem"
 
  prometheusSpec:
   # 把secret挂载到prometheus的pod⾥⾯
    volumes:
    - name: cert-vol
      secret:
        secretName: etcd-certs
    volumeMounts:
    - name: cert-vol
      mountPath: "/etc/prometheus/secrets/etcd-certs"
      readOnly: true
```

```sh
# 更新配置，删除服务prometheus-kube-prometheus-kube-etcd
kubectl delete svc prometheus-kube-prometheus-kube-etcd -n kube-system
# 在执⾏更新
helm upgrade prometheus -n monitoring kube-prometheus-stack
# 更新完成后，在 Prometheus 的 Pod 中检查 etcd 证书是否挂载成功
get pod -n monitoring
# 进⼊pod，检查
# 进⼊pod
kubectl exec -it prometheus-prometheus-kube-prometheus-prometheus-0 -n monitoring -- sh
# 查看
ls /etc/prometheus/secrets/etcd-certs/
```

### 配置访问地址

因为prometheus重启过，所以之前的9090映射关闭了

```sh
kubectl port-forward --address=0.0.0.0 svc/prometheus-kube-prometheus-prometheus -n monitoring 9090:9090 &
kubectl port-forward --address=0.0.0.0 svc/prometheus-grafana -n monitoring 3000:80 &
```

### 检查

http://192.168.11.65:9090/targets?search=

http://192.168.11.65:3000/dashboards

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261438000.png" alt="image-20230426143806911" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304261438891.png" alt="image-20230426143826814" style="zoom:80%;" />

```sh
# 更新配置时报错如下：
helm upgrade prometheus -n monitoring kube-prometheus-stack

# 解决：删除报错的service
kubectl delete svc prometheus-kube-prometheus-kube-etcd -n kube-system
```

# 黑盒监控

## ⽩盒监控和⿊盒监控

> "⽩盒监控"--需要把对应的Exporter程序安装到被监控的⽬标主机上，从⽽实现对主机各种资源及其状态的数据采集⼯作。但是由于某些情况下操作技术或其他原因，不是所有的Exporter都能部署到被监控的主机环境中，最典型的例⼦是监控全国⽹络质量的稳定性，通常的⽅法是使⽤ping操作，对选取的节点进⾏ICMP测试

> 此时不可能在他⼈应⽤环境中部署相关的Exporter程序。针对这样的应⽤的场景，Prometheus社区提供了⿊盒解决⽅案，Blackbox Exporter⽆须安装在被监控的⽬标环境中，⽤户只需要将其安装在与Prometheus和被监控⽬标互通的环境中，通过HTTP、HTTPS、DNS、TCP、ICMP等⽅式对⽹络进⾏探测监控，还可以探测SSL证书过期时间。

blackbox_exporter:Prometheus 官⽅提供的 exporter 之⼀，可以提供 http、dns、tcp、icmp 的监控数据采集

## 二进制安装（⼆选⼀）

https://prometheus.io/download/

```sh
wget https://github.com/prometheus/blackbox_exporter/releases/download/v0.23.0/blackbox_exporter-0.23.0.linux-amd64.tar.gztar zxvf blackbox_exporter-0.23.0.linux-amd64.tar.gz 

mkdir /opt/prometheus -p
mv blackbox_exporter-0.23.0.linux-amd64 /opt/prometheus/blackbox_exporter

# 创建用户
useradd -M -s /usr/sbin/nologin prometheus
# 更改exporter⽂件夹权限
chown prometheus:prometheus -R /opt/prometheus
```

```sh
# 配置开机自启动
cat <<"EOF" >/etc/systemd/system/blackbox_exporter.service
[Unit]
Description=blackbox_exporter
After=network.target

[Service]
Type=simple
User=prometheus
Group=prometheus
ExecStart=/opt/prometheus/blackbox_exporter/blackbox_exporter \
   --config.file "/opt/prometheus/blackbox_exporter/blackbox.yml" \
   --web.listen-address ":9115"
Restart=on-failure

[Install]
WantedBy=multi-user.target
EOF
```

```sh
systemctl daemon-reload
systemctl start blackbox_exporter
systemctl enable blackbox_exporter
systemctl status blackbox_exporter
journalctl -u blackbox_exporter -f
```

## Docker安装（二选⼀）⭐

```sh
mkdir /data/blackbox_exporter/
cd /data/blackbox_exporter/
```

```yml
modules:
  http_2xx:
    prober: http
    http:
      method: GET
  http_post_2xx:
    prober: http
    http:
      method: POST
  tcp_connect:
    prober: tcp
  pop3s_banner:
    prober: tcp
    tcp:
      query_response:
        - expect: "^+OK"
      tls: true
      tls_config:
        insecure_skip_verify: false
  ssh_banner:
    prober: tcp
    tcp:
      query_response:
        - expect: "^SSH-2.0-"
        - send: "SSH-2.0-blackbox-ssh-check"
  irc_banner:
    prober: tcp
    tcp:
      query_response:
        - send: "NICK prober"
        - send: "USER prober prober prober :prober"
        - expect: "PING :([^ ]+)"
          send: "PONG ${1}"
        - expect: "^:[^ ]+ 001"
  icmp:
    prober: icmp
```

**docker**直接运⾏

```sh
sudo docker run -d --restart=always --name blackbox-exporter -p 9115:9115 -v /data/blackbox_exporter:/etc/blackbox_exporter prom/blackbox-exporter:v0.19.0 --config.file=/etc/blackbox_exporter/config.yml
```

运行：http://192.168.88.101:9115/metrics

**docker-compose**⽅式⭐

为了⽅便省事，我mongodb⽤的管理员账号，⽣产不建议使⽤

```yml
cd /data/blackbox_exporter/
cat >docker-compose.yaml <<"EOF"
version: '3.3'
services:
  blackbox_exporter:
    image: prom/blackbox-exporter
    container_name: blackbox_exporter
    restart: always
    volumes:
      - /data/blackbox_exporter:/etc/blackbox_exporter
    ports:
      - 9115:9115
EOF
```

```sh
docker-compose up -d
docker ps
docker logs -f blackbox_exporter
```

## Prometheus配置

配置prometheus去采集（拉取）blackbox_exporter的监控样本数据

```yml
#http配置
  - job_name: "blackbox_http"
    metrics_path: /probe
    params:
      module: [http_2xx]
    static_configs:
      - targets:
        - https://www.baidu.com
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 192.168.88.101:9115

#tcp检查配置
  - job_name: "blackbox_tcp"
    metrics_path: /probe
    params:
      module: [tcp_connect]
    static_configs:
      - targets: 
        - 192.168.88.101:22
        - 192.168.88.101:9090
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 192.168.88.101:9115

#icmp检查配置 ping
  - job_name: "blackbox_icmp"
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets: 
        - 192.168.88.101
        - 192.168.88.101
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 192.168.88.101:9115
```

```sh
# 重新加载配置
curl -X POST :9090/-/reload
# 检查
http://192.168.11.62:9115/probe?target=https://www.baidu.com&module=http_2xx
http://192.168.11.62:9115
http://192.168.11.61:9090/targets?search=
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304262104114.png" alt="image-20230426210408988" style="zoom:80%;" />

## 监控项

```sh
# 关于探测
probe_
probe_success # 是否探测成功（取值 1、0 分别表示成功、失败）
probe_duration_seconds # 探测的耗时

# 关于 DNS
probe_dns_lookup_time_seconds # DNS 解析的耗时
probe_ip_protocol # IP 协议，取值为 4、6
probe_ip_addr_hash # IP 地址的哈希值，⽤于判断 IP 是否变化

# 关于 HTTP
probe_http_status_code # HTTP 响应的状态码。如果发⽣重定向，则取决于最后⼀次响应
probe_http_content_length # HTTP 响应的 body ⻓度，单位 bytes
probe_http_version # HTTP 响应的协议版本，⽐如 1.1
probe_http_ssl # HTTP 响应是否采⽤ SSL ，取值为 1、0
probe_ssl_earliest_cert_expiry # SSL 证书的过期时间，为 Unix 时间戳
```

## 触发器配置

Prometheus配置

\# 报警(触发器)配置

```yml
rule_files:
  - "alert.yml" 
  - "rules/*.yml"
```

添加blackbox_exporter触发器（告警规则）

```sh
cd /data/docker-prometheus
```

```yml
groups:
- name: Blackbox
  rules:
  - alert: 黑盒子探测失败告警
    expr: probe_success == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "黑盒子探测失败{{ $labels.instance }}"
      description: "黑盒子检测失败，当前值：{{ $value }}"
  - alert: 请求慢告警
    expr: avg_over_time(probe_duration_seconds[1m]) > 1
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "请求慢{{ $labels.instance }}"
      description: "请求时间超过1秒，值为：{{ $value }}"
  - alert: http状态码检测失败
    expr: probe_http_status_code <= 199 OR probe_http_status_code >= 400
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "http状态码检测失败{{ $labels.instance }}"
      description: "HTTP状态码非 200-399，当前状态码为：{{ $value }}"
  - alert: ssl证书即将到期
    expr: probe_ssl_earliest_cert_expiry - time() < 86400 * 30
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: "证书即将到期{{ $labels.instance }}"
      description: "SSL 证书在 30 天后到期，值：{{ $value }}"

  - alert: ssl证书即将到期
    expr: probe_ssl_earliest_cert_expiry - time() < 86400 * 3
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "证书即将到期{{ $labels.instance }}"
      description: "SSL 证书在 3 天后到期，值：{{ $value }}"

  - alert: ssl证书已过期
    expr: probe_ssl_earliest_cert_expiry - time() <= 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "证书已过期{{ $labels.instance }}"
      description: "SSL 证书已经过期，请确认是否在使用"
```

```sh
# 重新加载配置
./promtool check rules rules/linux.yml
curl -X POST :9090/-/reload

# 网站查询
http://192.168.11.61:9090/alerts?search=
http://192.168.11.61:9090/rules
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304281504973.png" alt="image-20230428150436866" style="zoom:80%;" />

## Dashboard

grafana上添加图⾏。图⾏展示⿊盒监控数据

https://grafana.com/grafana/dashboards/9965

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304281506287.png" alt="image-20230428150619152" style="zoom:80%;" />

问题：检测总耗时这个图⾏，名称显示异常。如下图：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304262104253.png" alt="image-20230426210447114" style="zoom:80%;" />

解决：检测总耗时这个图⾏点编辑---找到 Options --把Legend⾥⾯的值从 {{env}}_{{name}} 修改为{{instance}} 

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304262105769.png" alt="image-20230426210509634" style="zoom:80%;" />

其他的图⾏也是类似的⽅法

# 进程监控

> 如果想要对主机的进程进⾏监控，例如chronyd，sshd等服务进程以及⾃定义脚本程序运⾏状态监控。我们使⽤node exporter就不能实现需求了，此时就需要使⽤process exporter来做进程状态的监控。

项⽬地址：https://github.com/ncabatoff/process-exporter

## 二进制安装（⼆选⼀）

```sh
wget https://github.com/ncabatoff/process-exporter/releases/download/v0.7.10/process-exporter-0.7.10.linux-amd64.tar.gz
tar -xzvf process-exporter-0.7.10.linux-amd64.tar.gz
mkdir /opt/prometheus -p
mv process-exporter-0.7.10.linux-amd64 /opt/prometheus/process_exporter
```

创建配置⽂件，监控所有进程

```yml
cat >>/opt/prometheus/process_exporter/process.yml<<"EOF"
process_names:
  - name: "{{.Comm}}" # 匹配模板
    cmdline:
    - '.+' # 匹配名称
EOF
```

创建**systemd**

```sh
cat <<"EOF" >/etc/systemd/system/process_exporter.service
[Unit]
Description=process_exporter
After=network.target
[Service]
Type=simple
User=prometheus
Group=prometheus
ExecStart=/opt/prometheus/process_exporter/process-exporter -
config.path=/opt/prometheus/process_exporter/process.yml
Restart=on-failure
[Install]
WantedBy=multi-user.target
EOF
```

```sh
# 启动
systemctl daemon-reload
systemctl start process_exporter
# 加⼊到开机⾃启动
systemctl enable process_exporter
# 检查
systemctl status process_exporter
# 启动不了检查⽇志
journalctl -u process_exporter -f
```

## Docker安装⭐

### 创建数据⽬录

```sh
mkdir -p /data/process_exporter 
cd /data/process_exporter
```

### 创建配置⽂件

> 就在当前目录/data/process_exporter即可

监控所有进程

```sh
cat >>process.yml <<"EOF"
process_names:
  - name: "{{.Comm}}" # 匹配模板
    cmdline:
    - '.+' # 匹配所有名称，即监控所有进程
EOF
```

监控指定进程

```yml
process_names:
  - name: "{{.Matches}}"
    cmdline:
      - 'nginx' #唯⼀标识
  - name: "{{.Matches}}"
    cmdline:
      - 'mongod'
  - name: "{{.Matches}}"
    cmdline:
      - 'mysqld'
  - name: "{{.Matches}}"
    cmdline:
      - 'redis-server'
```

### Docker运⾏

```sh
docker run -d --rm -p 9256:9256 --privileged -v /proc:/host/proc -v `pwd`:/config --name process-exporter ncabatoff/process-exporter --procfs /host/proc -config.path /config/process.yml
```

检查：http://192.168.88.101:9256/metrics

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271413266.png" alt="image-20230427141351001" style="zoom:80%;" />

## Prometheus设置

```sh
cd /opt/module/prometheus-2.29.1
```

prometheus.yml

```yml
  - job_name: 'process'
    scrape_interval: 30s
    scrape_timeout: 15s
    static_configs:
      - targets: ['192.168.88.101:9256']
```

```sh
# 重新加载配置,检查
curl -X POST :9090/-/reload
http://192.168.11.61:9090/targets?search=
```

## 监控指标

```sh
namedprocess_
namedprocess_namegroup_states{state="Zombie"} 查看僵⼫
# 上下⽂切换数量
# Counter
namedprocess_namegroup_context_switches_total
# CPU user/system 时间（秒）
# Counter
namedprocess_namegroup_cpu_seconds_total
# 主要⻚缺失次数
# Counter
namedprocess_namegroup_major_page_faults_total
# 次要⻚缺失次数
# Counter
namedprocess_namegroup_minor_page_faults_total
# 内存占⽤（byte）
# Gauge
namedprocess_namegroup_memory_bytes
# 同名进程数量
# Gauge
namedprocess_namegroup_num_procs
# 同名进程状态分布
# Gauge
namedprocess_namegroup_states
# 线程数量
# Gauge
namedprocess_namegroup_num_threads
# 启动时间戳
# Gauge
namedprocess_namegroup_oldest_start_time_seconds
# 打开⽂件描述符数量
# Gauge
namedprocess_namegroup_open_filedesc
# 打开⽂件数 / 允许打开⽂件数
# Gauge
namedprocess_namegroup_worst_fd_ratio
# 读数据量（byte）
# Counter
namedprocess_namegroup_read_bytes_total
# 写数据量（byte）
# Counter
namedprocess_namegroup_write_bytes_total
# 内核wchan等待线程数量
# Gauge
namedprocess_namegroup_threads_wchan
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271416493.png" alt="image-20230427141605237" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271416641.png" alt="image-20230427141617384" style="zoom:80%;" />

## 触发器

prometheus.yml

```yml
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - localhost:9093
# 报警(触发器)配置
rule_files:
  - "alert.yml" 
  - "rules/*.yml"
scrape_configs:
  - job_name: 'alertmanager'
    static_configs:
      - targets: ["localhost:9093"]
```

linux.yml

```yml
groups:
- name: process
  rules:
  - alert: 进程数多告警
    expr: sum(namedprocess_namegroup_states) by (instance) > 1000
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: "进程数超过1000"
      description: "服务器当前有{{ $value }}个进程"
  - alert: 僵尸进程数告警
    expr: sum by(instance, groupname) (namedprocess_namegroup_states{state="Zombie"}) > 0
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: "有僵尸进程数"
      description: "进程{{ $labels.groupname }}有{{ $value }}个僵尸进程"
  - alert: 进程重启告警
    expr: ceil(time() - max by(instance, groupname) (namedprocess_namegroup_oldest_start_time_seconds)) < 60
    for: 15s
    labels:
      severity: warning
    annotations:
      summary: "进程重启"
      description: "进程{{ $labels.groupname }}在{{ $value }}秒前重启过"
  - alert: 进程退出告警
    expr: max by(instance, groupname) (delta(namedprocess_namegroup_oldest_start_time_seconds{groupname=~"^java.*|^nginx.*"}[1d])) < 0
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: "进程退出"
      description: "进程{{ $labels.groupname }}退出了"
```

```sh
# 重新加载配置
./promtool check rules rules/linux.yml
curl -X POST :9090/-/reload
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304280923377.png" alt="image-20230428092352282" style="zoom:80%;" />

## Doshboard

### 显示效果

https://grafana.com/grafana/dashboards/8378-system-processes-metrics/

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304280927109.png" alt="image-20230428092756977" style="zoom:80%;" />

### 问题分析

问题下⾯2个图形显示不正常

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271419920.png" alt="image-20230427141909658" style="zoom:80%;" />

process-exporter 升级到 0.5.0后 , 

```sh
namedprocess_namegroup_cpu_user_seconds_total 和
namedprocess_namegroup_cpu_system_seconds_total 合为⼀个指标名

namedprocess_namegroup_cpu_seconds_total
namedprocess_namegroup_cpu_user_seconds_total变成
namedprocess_namegroup_cpu_seconds_total{mode="system"}
namedprocess_namegroup_cpu_system_seconds_total 变成
namedprocess_namegroup_cpu_seconds_total{mode="user"}
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271419688.png" alt="image-20230427141931411" style="zoom: 50%;" />

### 解决方法

Top processes by System CPU cores used图形修改如下：

```sh
topk(5,rate(namedprocess_namegroup_cpu_seconds_total{mode="system",groupname=~"$processes",instance=~"$host"}[$interval])
or 
(irate(namedprocess_namegroup_cpu_seconds_total{mode="system",groupname=~"$processes",instance=~"$host"}[5m])))
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304280932499.png" alt="image-20230428093211388" style="zoom:80%;" />

Top processes by Total CPU cores used图形修改如下

```sh
topk(5,sum by (groupname,instance) (rate(namedprocess_namegroup_cpu_seconds_total{groupname=~"$processes",instance=~"$host"}[$interval]))
or
sum by (groupname,instance) (irate(namedprocess_namegroup_cpu_seconds_total{groupname=~"$processes",instance=~"$host"}[5m])))
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304280931601.png" alt="image-20230428093118493" style="zoom:80%;" />

或图形改名为 Top processes by User CPU cores used ⽤户进程cpu使⽤率排名

```sh
topk(5,rate(namedprocess_namegroup_cpu_seconds_total{mode="user",groupname=~"$processes",instance=~"$host"}[$interval])
or 
(irate(namedprocess_namegroup_cpu_seconds_total{mode="user",groupname=~"$processes",instance=~"$host"}[5m])))
```

修改完成后，图⾏正常

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271421134.png" alt="image-20230427142112837" style="zoom:80%;" />

# 自定义监控

## Pushgateway 简介

> Pushgateway 是 Prometheus ⽣态中⼀个重要⼯具，使⽤它的原因主要是：Prometheus 采⽤ pull 模式，可能由于不在⼀个⼦⽹或者防⽕墙原因，导致 Prometheus ⽆法直接拉取各个 target 数据。在监控业务数据的时候，需要将不同数据汇总, 由 Prometheus 统⼀收集。当exporter不能满⾜需要时，也可以通过⾃定义（python、shell、java）监控我们想要的数据。

> 由于以上原因，不得不使⽤ pushgateway，但在使⽤之前，有必要了解⼀下它的⼀些弊端：将多个节点数据汇总到 pushgateway, 如果 pushgateway 挂了，受影响⽐多个 target ⼤。Prometheus 拉取状态 up 只针对 pushgateway, ⽆法做到对每个节点有效。Pushgateway 可以持久化推送给它的所有监控数据。因此，即使你的监控已经下线，prometheus 还会拉取到旧的监控数据，需要⼿动清理 pushgateway 不要的数据。

## 安装配置

### 二进制安装

官⽹下载地址https://prometheus.io/download/

```sh
wget https://github.com/prometheus/pushgateway/releases/download/v1.5.1/pushgateway-1.5.1.linux-amd64.tar.gz
tar -xzvf pushgateway-1.5.1.linux-amd64.tar.gz
mv pushgateway-1.5.1.linux-amd64 /opt/pushgateway
```

更改 pushgateway ⽂件夹权限：

```sh
chown prometheus:prometheus -R /opt/pushgateway
```

创建 systemd 服务

```sh
cat >/etc/systemd/system/pushgateway.service << "EOF"
[Unit]
Description=Prometheus Push Gateway
After=network.target
[Service]
Type=simple
User=prometheus
Group=prometheus
ExecStart=/opt/pushgateway/pushgateway
[Install]
WantedBy=multi-user.target
EOF
```

```sh
# 启动
systemctl daemon-reload
systemctl start pushgateway.service
# 加⼊到开机⾃启动
systemctl enable pushgateway.service
# 检查
systemctl status pushgateway.service
# 检查⽇志
journalctl -u pushgateway.service -f
```

### Docker安装⭐

docker命令⾏运⾏

```sh
docker run -d -p 9091:9091 --restart=always --name pushgateway prom/pushgateway
```

docker-compose运⾏

```yml
version: '3.3'
services:
  pushgateway:
    image: prom/pushgateway
    container_name: pushgateway
    restart: always
    expose:
      - 9091
    ports:
      - "9091:9091"
```

```sh
# 启动检查
docker-compose up -d
docker ps
```

### Prometheus配置

```sh
# 去pull拉取pushgateway收集到的数据
# 进⼊到prometheus安装⽬录
cd /opt/module/prometheus-2.29.1
# 通过cat在prometheus.yml⽂件末尾添加
```

```yml
  - job_name: pushgateway
    honor_labels: true
    static_configs:
    - targets: ['192.168.88.101:9091']
      labels:
        instance: pushgateway
```

```sh
# 重载配置
curl -X POST :9090/-/reload
# 检查
http://192.168.11.61:9090/targets?search=
```

## 推送监控数据

### 使⽤curl

> 正常情况我们会使⽤ Client SDK 推送数据到 pushgateway, 但是我们还可以curl调⽤ API 来管理, 例如：向 {job="some_job"} 添加单条数据：

```sh
echo "some_metric 3.14" | curl --data-binary @- http://192.168.88.101:9091/metrics/job/hello
echo "some_metric 3.14" | curl --data-binary @- http://192.168.88.101:9091/metrics/job/hello
```

添加更多更复杂数据，通常数据会带上 instance（some_instance为instance名）, 表示来源位置：

```sh
cat <<EOF | curl --data-binary @- http://192.168.88.101:9091/metrics/job/some_job/instance/some_instance
some_metric{label="val1"} 42
another_metric 2398.283
EOF
```

```sh
# 删除某个组下的某实例的所有数据：
curl -X DELETE http://192.168.88.101:9091/metrics/job/some_job/instance/some_instance
# 删除某个组下的所有数据
curl -X DELETE http://192.168.88.101:9091/metrics/job/some_job
```

http://192.168.88.101:9090/graph

http://192.168.88.101:9091/metrics

> 刚刚传上来的两条数据

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304302224684.png" alt="image-20230430222437575" style="zoom:80%;" />

### 使⽤python

文档：https://github.com/prometheus/client_python#exporting-to-a-pushgateway

```sh
# 安装prometheus_client模块
# 安装pip
yum install python3-pip
apt install python3-pip
# 通过pip安装prometheus_client
pip3 install prometheus_client
```

```python
cat >p1.py<<"EOF"
from prometheus_client import CollectorRegistry, Gauge, push_to_gateway
registry = CollectorRegistry()
g = Gauge('job_last_success_unixtime', 'Last time a batch job successfully finished',registry=registry)
g.set_to_current_time()
push_to_gateway('localhost:9091', job='batchA', registry=registry)
EOF
```

```
python3 p1.py
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304302229843.png" alt="image-20230430222901732" style="zoom:80%;" />

## 监控data数据⽬录下的⽂件数量（需求）

### **shell**脚本

```sh
cat >/opt/file_num.sh<<"EOF"
#!/bin/sh
FILENUM=`ls -l /data |sed 1d| wc -l`
echo "data_file_num ${FILENUM}" | curl --data-binary @- http://192.168.88.101:9091/metrics/job/test_job/instance/test
EOF
```

### 定时任务

直接复制到定时任务文件即可

```sh
crontab -e
*/1 * * * * /bin/sh /opt/file_num.sh >/dev/null 2>&1
```

### **python**脚本

```python
cat >/opt/file_num.py<<"EOF"
from prometheus_client import CollectorRegistry, Gauge, push_to_gateway
import os
path = '/data' # 输⼊⽂件夹地址
files = os.listdir(path) # 读⼊⽂件夹
num_png = len(files) # 统计⽂件夹中的⽂件个数
registry = CollectorRegistry()
g = Gauge('python_data_file_num', 'data file num', ['instance'],registry=registry)

g.labels('test').set(num_png)
push_to_gateway('192.168.88.101:9091', job='test_job', registry=registry)
EOF
```

### EOF定时任务

```sh
crontab -e
*/1 * * * * /usr/bin/python3 /opt/file_num.py >/dev/null 2>&1
```

### 配置告警规则

例如：当data⽬录下的⽂件数量超过5，报警出来

```sh
groups:
- name: pushgateway
  rules:
  - alert: DataFileNum
    expr: data_file_num > 5
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: 'data数据⽬录⽂件数过多'
      description: "data数据⽬录⽂件数>5,当前数量:{{ $value }}"
```

```sh
# 重载配置
curl -X POST :9090/-/reload
# 检查
http://192.168.11.61:9090/alerts?search=
```

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304302237120.png" alt="image-20230430223747010" style="zoom:67%;" />

## grafana添加图形

当然上⾯只是个举例：,你也可以监控任何你想要监控的数据



# 监控综述

## 监控流程

> 1、需要在被监控的服务器上安装xx_exporter来收集数据
>
> 2、添加Prometheus配置，去收集（xx_exporter）提供的监控样本数据
>
> 3、配置触发器（告警规则）
>
> 4、Grafana添加dashboard，图形的展示

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271118201.png" alt="image-20230427111852963" style="zoom:80%;" />

> 注：因为prometheus要去exporter去拉取（pull）数据，所以安装exporter的服务器防⽕墙要开放对应的端⼝给prometheus服务器⿊盒监控和⽩盒监控

## exporter

https://prometheus.io/docs/instrumenting/exporters/

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271404899.png" alt="image-20230427140457631" style="zoom:80%;" />

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202304271405264.png" alt="image-20230427140513015" style="zoom:80%;" />

# 运维监控工具

https://github.com/tianshiyeben/wgcloud/blob/master/README_cn.md

> 给大家介绍一款Linux运维监控工具 ——wgcloud，功能非常强大，完全开源！wgcloud支持显示CPU利用率、CPU温度、内存利用率、磁盘容量、磁盘IO、硬盘智能健康状态、系统负载、连接数、网卡流量、硬件系统信息等。支持进程应用、文件、端口、服务器上的日志、docker容器、数据库、数据表等资源。

> 支持监控服务接口API、数据通讯设备（如交换机、路由器、打印机等）自动生成网络拓扑图、大屏可视化、web SSH（堡垒机）、统计分析图表、命令下发、批量执行、告警信息推送（如邮箱、钉钉、微信、短信等）

### 演示截图

![图片](https://mmbiz.qpic.cn/mmbiz_png/JfTPiahTHJhpYAHmxLWodw8K9fbib3AKYhnSDCfkuBcatLQRF2uHQZ7hic2v8BZbv7eU0LScd6wSztMIAf5EslIiag/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_png/JfTPiahTHJhpYAHmxLWodw8K9fbib3AKYh8kEibq6QCStZSlQ2qsicVEQuO0VtS1W8Wu4FptxdaIDxz75tF7k5YXRQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_png/JfTPiahTHJhpYAHmxLWodw8K9fbib3AKYh16lKOyEuicEnOILSeBVJ2pTXFiaPd1bd8ZiaAekAFq4LCibzAxddLQx09g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_png/JfTPiahTHJhpYAHmxLWodw8K9fbib3AKYhwdYq5TsqTAZDmmzjOP2ibHM2BNRkAM7KoXYcvzuGN1I2IfPn67ibiaVXQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_png/JfTPiahTHJhpYAHmxLWodw8K9fbib3AKYhdB40bvQibpvm6Tfia5XkxMFqhlVmzwb2zhC8hK6EsATRNsWa0TCexLpQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_png/JfTPiahTHJhpYAHmxLWodw8K9fbib3AKYhyHzB0UicuER1DzFA9LYyLYCL11ZnRGk6t1pQb2OhI6Cu6I3OaX7cE8w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_png/JfTPiahTHJhpYAHmxLWodw8K9fbib3AKYhPYbqbmJ8JezXRL9xqXRZKeSIGWMqZn2yQriaaoKBlauFKhic16QRwX5w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_png/JfTPiahTHJhpYAHmxLWodw8K9fbib3AKYhibASbTjEQtqfV0AIwA3JJhkf656BXEBMiaWq7Q6AjdPlGJonnTKDOyKQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_png/JfTPiahTHJhpYAHmxLWodw8K9fbib3AKYhs9zPN52hj9Y38a2KAevuTVx41e8tm4gYmSGkjcMk4r8piaibAHiaiak2WQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_png/JfTPiahTHJhpYAHmxLWodw8K9fbib3AKYhibV41ybvIBmygsh0uudqjyYxaZTjIAqic7icbIElia5fRFDeJibw6k6612w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

### 支持操作系统平台

支持监控linux系列：Debian、RedHat、CentOS、Ubuntu .....

支持监控windows系列：Windows Server 2008 R2 2012 , 2016 , 2019, Windows 7, Windows 8, windows 10 ,windows 11

支持监控UNIX系列：Solaris、FreeBSD、OpenBSD……

支持监控Mac OS系列：Mac OS AMD64

> 开源地址：https://github.com/tianshiyeben/wgcloud













































